{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afceffe-b9a0-46d1-b30b-c0fcebf7c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations \n",
    "\n",
    "import os \n",
    "import sys \n",
    "import json \n",
    "import time \n",
    "import random \n",
    "import platform \n",
    "import logging \n",
    "from pathlib import Path \n",
    "from typing import Dict ,Any ,Optional ,Tuple ,List \n",
    "import joblib \n",
    "import csv \n",
    "import glob \n",
    "import math \n",
    "import re \n",
    "import shutil \n",
    "import uuid \n",
    "import warnings \n",
    "from datetime import datetime \n",
    "from sklearn .model_selection import train_test_split \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "SEED =42 \n",
    "\n",
    "def set_global_seed (seed :int =42 )->None :\n",
    "    \"\"\"Best-effort determinism across python/numpy/(optional torch).\"\"\"\n",
    "    os .environ [\"PYTHONHASHSEED\"]=str (seed )\n",
    "    random .seed (seed )\n",
    "    np .random .seed (seed )\n",
    "\n",
    "    try :\n",
    "        import torch \n",
    "        torch .manual_seed (seed )\n",
    "        if torch .cuda .is_available ():\n",
    "            torch .cuda .manual_seed_all (seed )\n",
    "        torch .backends .cudnn .deterministic =True \n",
    "        torch .backends .cudnn .benchmark =False \n",
    "    except Exception :\n",
    "        pass \n",
    "\n",
    "def detect_project_root ()->Path :\n",
    "    \"\"\"\n",
    "    Robust: wenn Notebook in project_root/notebooks liegt -> root = parent,\n",
    "    sonst root = aktuelles Arbeitsverzeichnis.\n",
    "    \"\"\"\n",
    "    cwd =Path .cwd ().resolve ()\n",
    "    if cwd .name .lower ()==\"notebooks\":\n",
    "        return cwd .parent \n",
    "    return cwd \n",
    "\n",
    "def ensure_project_structure (root :Path )->Dict [str ,Path ]:\n",
    "    paths ={\n",
    "    \"project_root\":root ,\n",
    "    \"data_raw\":root /\"data\"/\"raw\",\n",
    "    \"data_processed\":root /\"data\"/\"processed\",\n",
    "    \"data_features\":root /\"data\"/\"features\",\n",
    "    \"models\":root /\"models\",\n",
    "    \"reports\":root /\"reports\",\n",
    "    \"figs\":root /\"figs\",\n",
    "    \"notebooks\":root /\"notebooks\",\n",
    "    }\n",
    "    for p in paths .values ():\n",
    "        p .mkdir (parents =True ,exist_ok =True )\n",
    "    return paths \n",
    "\n",
    "def setup_logging (log_path :Path )->logging .Logger :\n",
    "    logger =logging .getLogger (\"airline_rating_project\")\n",
    "    logger .setLevel (logging .INFO )\n",
    "    logger .handlers .clear ()\n",
    "\n",
    "    fmt =logging .Formatter (\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "\n",
    "    fh =logging .FileHandler (log_path ,encoding =\"utf-8\")\n",
    "    fh .setFormatter (fmt )\n",
    "    fh .setLevel (logging .INFO )\n",
    "\n",
    "    sh =logging .StreamHandler (sys .stdout )\n",
    "    sh .setFormatter (fmt )\n",
    "    sh .setLevel (logging .INFO )\n",
    "\n",
    "    logger .addHandler (fh )\n",
    "    logger .addHandler (sh )\n",
    "    logger .propagate =False \n",
    "    return logger \n",
    "\n",
    "def capture_environment ()->Dict [str ,Any ]:\n",
    "    env ={\n",
    "    \"python_version\":sys .version .replace (\"\\n\",\" \"),\n",
    "    \"platform\":platform .platform (),\n",
    "    \"machine\":platform .machine (),\n",
    "    \"processor\":platform .processor (),\n",
    "    \"executable\":sys .executable ,\n",
    "    \"cwd\":str (Path .cwd ().resolve ()),\n",
    "    \"time_utc\":time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ()),\n",
    "    \"packages\":{\n",
    "    \"numpy\":getattr (np ,\"__version__\",None ),\n",
    "    \"pandas\":getattr (pd ,\"__version__\",None ),\n",
    "    },\n",
    "    }\n",
    "    optional ={\n",
    "    \"scipy\":\"scipy\",\n",
    "    \"sklearn\":\"sklearn\",\n",
    "    \"matplotlib\":\"matplotlib\",\n",
    "    \"sentence_transformers\":\"sentence_transformers\",\n",
    "    \"transformers\":\"transformers\",\n",
    "    \"torch\":\"torch\",\n",
    "    \"datasets\":\"datasets\",\n",
    "    \"accelerate\":\"accelerate\",\n",
    "    \"jsonschema\":\"jsonschema\",\n",
    "    \"requests\":\"requests\",\n",
    "    \"pyarrow\":\"pyarrow\",\n",
    "    }\n",
    "    for k ,mod in optional .items ():\n",
    "        try :\n",
    "            m =__import__ (mod )\n",
    "            env [\"packages\"][k ]=getattr (m ,\"__version__\",\"unknown\")\n",
    "        except Exception :\n",
    "            env [\"packages\"][k ]=None \n",
    "\n",
    "    try :\n",
    "        import torch \n",
    "        env [\"torch\"]={\n",
    "        \"cuda_available\":torch .cuda .is_available (),\n",
    "        \"mps_available\":hasattr (torch .backends ,\"mps\")and torch .backends .mps .is_available (),\n",
    "        \"device_count_cuda\":torch .cuda .device_count ()if torch .cuda .is_available ()else 0 ,\n",
    "        }\n",
    "    except Exception :\n",
    "        env [\"torch\"]=None \n",
    "\n",
    "    return env \n",
    "\n",
    "def check_ollama (base_url :str =\"http://localhost:11434\")->Dict [str ,Any ]:\n",
    "    \"\"\"\n",
    "    Non-fatal Check: prüft, ob Ollama erreichbar ist und welche Modelle gelistet werden.\n",
    "    \"\"\"\n",
    "    out ={\"reachable\":False ,\"base_url\":base_url ,\"models\":None ,\"error\":None }\n",
    "    try :\n",
    "        import requests \n",
    "        r =requests .get (f\"{base_url}/api/tags\",timeout =2 )\n",
    "        if r .status_code ==200 :\n",
    "            out [\"reachable\"]=True \n",
    "            data =r .json ()\n",
    "            out [\"models\"]=[m .get (\"name\")for m in data .get (\"models\",[])]\n",
    "        else :\n",
    "            out [\"error\"]=f\"HTTP {r.status_code}\"\n",
    "    except Exception as e :\n",
    "        out [\"error\"]=repr (e )\n",
    "    return out \n",
    "\n",
    "set_global_seed (SEED )\n",
    "\n",
    "PATHS =ensure_project_structure (detect_project_root ())\n",
    "LOG_PATH =PATHS [\"reports\"]/\"run.log\"\n",
    "LOGGER =setup_logging (LOG_PATH )\n",
    "\n",
    "RUN_ID =time .strftime (\"%Y%m%d_%H%M%S\",time .gmtime ())\n",
    "RUN_TAG =\"default\"\n",
    "LOGGER .info (f\"RUN_ID={RUN_ID} RUN_TAG={RUN_TAG}\")\n",
    "\n",
    "CONFIG ={\n",
    "\"seed\":SEED ,\n",
    "\"llm_subset_size\":800 ,\n",
    "\"rating_bins_default\":[[1 ,3 ],[4 ,7 ],[8 ,10 ]],\n",
    "\"ollama_model\":\"phi3:mini\",\n",
    "\"ollama_base_url\":\"http://localhost:11434\",\n",
    "\"created_utc\":time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ()),\n",
    "}\n",
    "\n",
    "ENV =capture_environment ()\n",
    "OLLAMA =check_ollama (CONFIG [\"ollama_base_url\"])\n",
    "\n",
    "config_path =PATHS [\"reports\"]/\"config.json\"\n",
    "env_path =PATHS [\"reports\"]/\"environment.json\"\n",
    "with open (config_path ,\"w\",encoding =\"utf-8\")as f :\n",
    "    json .dump (CONFIG ,f ,indent =2 ,ensure_ascii =False )\n",
    "with open (env_path ,\"w\",encoding =\"utf-8\")as f :\n",
    "    json .dump (ENV ,f ,indent =2 ,ensure_ascii =False )\n",
    "\n",
    "if OLLAMA [\"reachable\"]:\n",
    "    print (\"Ollama models (first 10):\",(OLLAMA [\"models\"]or [])[:10 ])\n",
    "else :\n",
    "    print (\"Ollama check error:\",OLLAMA [\"error\"])\n",
    "\n",
    "\n",
    "with open (PATHS [\"reports\"]/\"config.json\",\"r\",encoding =\"utf-8\")as f :\n",
    "    _cfg =json .load (f )\n",
    "with open (PATHS [\"reports\"]/\"environment.json\",\"r\",encoding =\"utf-8\")as f :\n",
    "    _env =json .load (f )\n",
    "\n",
    "CSV_CANDIDATES =[]\n",
    "_env =os .getenv (\"AIRLINE_CSV_PATH\")\n",
    "if _env :\n",
    "    CSV_CANDIDATES .append (Path (_env ).expanduser ())\n",
    "\n",
    "CSV_CANDIDATES +=[\n",
    "PATHS [\"data_raw\"]/\"BA_AirlineReviews.csv\",\n",
    "PATHS [\"project_root\"]/\"BA_AirlineReviews.csv\",\n",
    "Path (\"BA_AirlineReviews.csv\"),\n",
    "Path (\"/Users/jackgilbert/Desktop/ML_Praktikum/BA_AirlineReviews.csv\").expanduser (),\n",
    "]\n",
    "\n",
    "CSV_PATH =None \n",
    "for _p in CSV_CANDIDATES :\n",
    "    try :\n",
    "        _pp =_p .expanduser ().resolve ()\n",
    "    except Exception :\n",
    "        _pp =_p \n",
    "    if Path (_pp ).exists ():\n",
    "        CSV_PATH =Path (_pp )\n",
    "        break \n",
    "\n",
    "if CSV_PATH is None :\n",
    "    raise FileNotFoundError (\n",
    "    \"CSV nicht gefunden. Setze AIRLINE_CSV_PATH oder lege die Datei unter data/raw/BA_AirlineReviews.csv ab.\\n\"\n",
    "    f\"Geprüfte Pfade: {[str(p) for p in CSV_CANDIDATES]}\"\n",
    "    )\n",
    "\n",
    "def sniff_csv_format (path :Path ,bytes_to_read :int =50_000 )->Dict [str ,Any ]:\n",
    "    \"\"\"Snifft delimiter & quoting heuristisch.\"\"\"\n",
    "    with open (path ,\"rb\")as f :\n",
    "        raw =f .read (bytes_to_read )\n",
    "    try :\n",
    "        sample =raw .decode (\"utf-8\")\n",
    "        enc =\"utf-8\"\n",
    "    except UnicodeDecodeError :\n",
    "        sample =raw .decode (\"latin-1\",errors =\"replace\")\n",
    "        enc =\"latin-1\"\n",
    "\n",
    "    sniffer =csv .Sniffer ()\n",
    "    try :\n",
    "        dialect =sniffer .sniff (sample )\n",
    "        delim =dialect .delimiter \n",
    "        quotechar =dialect .quotechar \n",
    "    except Exception :\n",
    "        first_line =sample .splitlines ()[0 ]if sample .splitlines ()else sample \n",
    "        candidates =[\",\",\";\",\"\\t\",\"|\"]\n",
    "        delim =max (candidates ,key =lambda d :first_line .count (d ))if first_line else \",\"\n",
    "        quotechar ='\"'\n",
    "    return {\"encoding_guess\":enc ,\"delimiter\":delim ,\"quotechar\":quotechar }\n",
    "\n",
    "def read_csv_robust (path :Path )->Tuple [pd .DataFrame ,Dict [str ,Any ]]:\n",
    "    info =sniff_csv_format (path )\n",
    "    delim =info [\"delimiter\"]\n",
    "\n",
    "    last_err =None \n",
    "    for enc in [\"utf-8\",\"utf-8-sig\",\"latin-1\"]:\n",
    "        try :\n",
    "            df =pd .read_csv (\n",
    "            path ,\n",
    "            sep =delim if delim else None ,\n",
    "            engine =\"python\",\n",
    "            encoding =enc ,\n",
    "            on_bad_lines =\"skip\",\n",
    "            )\n",
    "            info [\"encoding_used\"]=enc \n",
    "            info [\"rows_loaded\"]=len (df )\n",
    "            return df ,info \n",
    "        except Exception as e :\n",
    "            last_err =e \n",
    "    raise RuntimeError (f\"Konnte CSV nicht lesen. Letzter Fehler: {last_err}\")\n",
    "\n",
    "df_raw ,csv_info =read_csv_robust (CSV_PATH )\n",
    "\n",
    "unnamed_cols =[c for c in df_raw .columns if str (c ).startswith ('Unnamed')]\n",
    "if unnamed_cols :\n",
    "    df_raw =df_raw .drop (columns =unnamed_cols )\n",
    "\n",
    "raw_copy_path =PATHS [\"data_raw\"]/CSV_PATH .name \n",
    "try :\n",
    "    _src =CSV_PATH .resolve ()\n",
    "    _dst =raw_copy_path .resolve ()\n",
    "except Exception :\n",
    "    _src ,_dst =CSV_PATH ,raw_copy_path \n",
    "\n",
    "if _src !=_dst :\n",
    "    if not raw_copy_path .exists ():\n",
    "        shutil .copy2 (CSV_PATH ,raw_copy_path )\n",
    "\n",
    "def norm_col (c :str )->str :\n",
    "    return re .sub (r\"[^a-z0-9]+\",\"\",str (c ).strip ().lower ())\n",
    "\n",
    "def coerce_rating_series (s :pd .Series )->pd .Series :\n",
    "    \"\"\"\n",
    "    Robust: macht aus '9', '9.0', '9/10', 'Rating: 9' -> 9.0\n",
    "    Gibt float-Serie zurück (NaN wenn unparsebar).\n",
    "    \"\"\"\n",
    "    if pd .api .types .is_numeric_dtype (s ):\n",
    "        return pd .to_numeric (s ,errors =\"coerce\").astype (float )\n",
    "\n",
    "    s2 =s .astype (str ).str .strip ()\n",
    "    extracted =s2 .str .extract (r\"(-?\\d+(?:\\.\\d+)?)\",expand =False )\n",
    "    return pd .to_numeric (extracted ,errors =\"coerce\").astype (float )\n",
    "\n",
    "def pick_best_target (df :pd .DataFrame )->Tuple [str ,pd .Series ,Dict [str ,Any ]]:\n",
    "    \"\"\"\n",
    "    Wählt bestes Target-Feld:\n",
    "    - priorisierte Namensmatches\n",
    "    - hohe Parse-Rate\n",
    "    - Wertebereich plausibel (0..10 oder 1..10)\n",
    "    \"\"\"\n",
    "    cols =list (df .columns )\n",
    "    ncols ={c :norm_col (c )for c in cols }\n",
    "\n",
    "    priority =[\n",
    "    \"overall_rating\",\"overallrating\",\"overall\",\"rating\",\"score\",\n",
    "    \"overallscore\",\"overallrate\",\"overallstars\",\"stars\"\n",
    "    ]\n",
    "\n",
    "    ordered =[]\n",
    "    for p in priority :\n",
    "        ordered +=[c for c in cols if ncols [c ]==p ]\n",
    "    ordered +=[c for c in cols if any (k in ncols [c ]for k in [\"overall\",\"rating\",\"score\",\"stars\"])]\n",
    "    seen =set ()\n",
    "    ordered =[c for c in ordered if not (c in seen or seen .add (c ))]\n",
    "\n",
    "    if not ordered :\n",
    "        ordered =cols [:]\n",
    "\n",
    "    best =None \n",
    "    best_meta =None \n",
    "    best_series =None \n",
    "\n",
    "    for c in ordered :\n",
    "        s =coerce_rating_series (df [c ])\n",
    "        valid =s .notna ().mean ()\n",
    "        if valid <0.2 :\n",
    "            continue \n",
    "\n",
    "        q01 ,q99 =s .quantile (0.01 ),s .quantile (0.99 )\n",
    "        range_score =0.0 \n",
    "        if (q01 >=-0.5 )and (q99 <=10.5 ):\n",
    "            range_score =1.0 \n",
    "        if (q01 >=0.5 )and (q99 <=10.5 ):\n",
    "            range_score =1.2 \n",
    "\n",
    "        score =valid *range_score \n",
    "        meta ={\"col\":c ,\"valid_rate\":float (valid ),\"q01\":float (q01 ),\"q99\":float (q99 ),\"score\":float (score )}\n",
    "        if (best is None )or (score >best_meta [\"score\"]):\n",
    "            best =c \n",
    "            best_meta =meta \n",
    "            best_series =s \n",
    "\n",
    "    if best is None :\n",
    "        raise RuntimeError (\"Konnte kein plausibles Target-Feld identifizieren (zu wenig parsebare Werte).\")\n",
    "\n",
    "    return best ,best_series ,best_meta \n",
    "\n",
    "def pick_text_columns (df :pd .DataFrame )->Tuple [Optional [str ],str ,Dict [str ,Any ]]:\n",
    "    \"\"\"\n",
    "    Findet review_title + review_text robust.\n",
    "    Title ist optional; review_text ist required.\n",
    "    \n",
    "    NOTE (Setup-Fix): Wenn Spalten 'ReviewHeader' und 'ReviewBody' existieren,\n",
    "    erzwingen wir: title=ReviewHeader, text=ReviewBody (Paper-Definition: Title+Body).\n",
    "    \"\"\"\n",
    "    cols =list (df .columns )\n",
    "    ncols ={c :norm_col (c )for c in cols }\n",
    "\n",
    "    has_header =any (ncols [c ]==\"reviewheader\"for c in cols )\n",
    "    has_body =any (ncols [c ]==\"reviewbody\"for c in cols )\n",
    "    if has_header and has_body :\n",
    "        title_col =next (c for c in cols if ncols [c ]==\"reviewheader\")\n",
    "        text_col =next (c for c in cols if ncols [c ]==\"reviewbody\")\n",
    "        meta ={\"title_col\":title_col ,\"text_col\":text_col ,\"forced\":\"ReviewHeader+ReviewBody\"}\n",
    "        return title_col ,text_col ,meta \n",
    "\n",
    "    title_priority =[\"review_title\",\"reviewtitle\",\"title\",\"summary\",\"headline\"]\n",
    "    text_priority =[\"review_text\",\"reviewtext\",\"review\",\"text\",\"content\",\"body\",\"comment\",\"comments\",\"reviewbody\"]\n",
    "\n",
    "    title_col =None \n",
    "    for p in title_priority :\n",
    "        for c in cols :\n",
    "            if ncols [c ]==p :\n",
    "                title_col =c \n",
    "                break \n",
    "        if title_col :\n",
    "            break \n",
    "\n",
    "    text_col =None \n",
    "    for p in text_priority :\n",
    "        for c in cols :\n",
    "            if ncols [c ]==p :\n",
    "                text_col =c \n",
    "                break \n",
    "        if text_col :\n",
    "            break \n",
    "\n",
    "    obj_cols =[c for c in cols if df [c ].dtype ==\"object\"or str (df [c ].dtype ).startswith (\"string\")]\n",
    "    if text_col is None :\n",
    "        if not obj_cols :\n",
    "            raise RuntimeError (\"Keine Textspalten (object/string) gefunden. Kann review_text nicht bestimmen.\")\n",
    "        lengths =[]\n",
    "        for c in obj_cols :\n",
    "            s =df [c ].astype (str )\n",
    "            lengths .append ((c ,float (s .str .len ().replace ({np .inf :np .nan }).fillna (0 ).mean ())))\n",
    "        lengths .sort (key =lambda x :x [1 ],reverse =True )\n",
    "        text_col =lengths [0 ][0 ]\n",
    "        if title_col is None and len (lengths )>1 :\n",
    "            title_candidate =lengths [1 ][0 ]\n",
    "            title_col =title_candidate if lengths [1 ][1 ]<lengths [0 ][1 ]else None \n",
    "\n",
    "    meta ={\"title_col\":title_col ,\"text_col\":text_col }\n",
    "    return title_col ,text_col ,meta \n",
    "\n",
    "target_col ,target_s ,target_meta =pick_best_target (df_raw )\n",
    "title_col ,text_col ,text_meta =pick_text_columns (df_raw )\n",
    "\n",
    "LOGGER .info (f\"Target gewählt: {target_col} | meta={target_meta}\")\n",
    "LOGGER .info (f\"Text gewählt: title={title_col} | text={text_col}\")\n",
    "\n",
    "df =df_raw .copy ()\n",
    "\n",
    "title_part =df [title_col ].astype (str )if title_col is not None else \"\"\n",
    "text_part =df [text_col ].astype (str )\n",
    "\n",
    "def clean_str_series (s :pd .Series )->pd .Series :\n",
    "    s =s .fillna (\"\").astype (str )\n",
    "    s =s .str .replace (r\"\\s+\",\" \",regex =True ).str .strip ()\n",
    "    s =s .replace ({\"nan\":\"\",\"None\":\"\",\"null\":\"\",\"NULL\":\"\",\"NaN\":\"\"})\n",
    "    return s \n",
    "\n",
    "title_part =clean_str_series (title_part )if isinstance (title_part ,pd .Series )else title_part \n",
    "text_part =clean_str_series (text_part )\n",
    "\n",
    "df [\"text\"]=(\n",
    "(title_part +\"\\n\\n\"+text_part )if isinstance (title_part ,pd .Series )\n",
    "else text_part \n",
    ").str .strip ()\n",
    "\n",
    "_sample =df [[c for c in [title_col ,text_col ]if c is not None ]+[\"text\"]].head (3 ).copy ()\n",
    "if title_col is not None and text_col is not None :\n",
    "    for _i ,_r in _sample .iterrows ():\n",
    "        _t =str (_r .get (title_col ,\"\"))\n",
    "        _b =str (_r .get (text_col ,\"\"))\n",
    "        _x =str (_r .get (\"text\",\"\"))\n",
    "\n",
    "df [\"target_raw\"]=df [target_col ]\n",
    "df [\"target\"]=coerce_rating_series (df [target_col ])\n",
    "\n",
    "before =len (df )\n",
    "\n",
    "df [\"text_len\"]=df [\"text\"].fillna (\"\").astype (str ).str .len ()\n",
    "df =df [df [\"text_len\"]>0 ].copy ()\n",
    "\n",
    "df =df [df [\"target\"].notna ()].copy ()\n",
    "\n",
    "n_zero =int ((df [\"target\"]==0 ).sum ())\n",
    "if n_zero :\n",
    "    LOGGER .warning (f\"Found {n_zero} rows with target==0; dropping them to enforce 1..10.\")\n",
    "df =df [(df [\"target\"]>=1 )&(df [\"target\"]<=10 )].copy ()\n",
    "\n",
    "after =len (df )\n",
    "dropped =before -after \n",
    "\n",
    "processed_path_parquet =PATHS [\"data_processed\"]/\"reviews_processed.parquet\"\n",
    "processed_path_csv =PATHS [\"data_processed\"]/\"reviews_processed.csv\"\n",
    "schema_path =PATHS [\"reports\"]/\"data_schema.json\"\n",
    "\n",
    "df .reset_index (drop =True ,inplace =True )\n",
    "df .to_parquet (processed_path_parquet ,index =False )\n",
    "df .to_csv (processed_path_csv ,index =False )\n",
    "\n",
    "schema ={\n",
    "\"created_utc\":datetime .utcnow ().isoformat ()+\"Z\",\n",
    "\"raw_csv\":str (raw_copy_path ),\n",
    "\"raw_shape\":list (df_raw .shape ),\n",
    "\"processed_shape\":list (df .shape ),\n",
    "\"chosen_columns\":{\n",
    "\"title_col\":title_col ,\n",
    "\"text_col\":text_col ,\n",
    "\"target_col\":target_col ,\n",
    "},\n",
    "\"target_meta\":target_meta ,\n",
    "\"cleaning\":{\n",
    "\"dropped_rows\":int (dropped ),\n",
    "\"rules\":[\n",
    "\"drop empty text\",\n",
    "\"drop missing target\",\n",
    "\"keep 1 <= target <= 10\",\n",
    "],\n",
    "},\n",
    "\"columns\":{c :str (df [c ].dtype )for c in df .columns },\n",
    "}\n",
    "\n",
    "with open (schema_path ,\"w\",encoding =\"utf-8\")as f :\n",
    "    json .dump (schema ,f ,indent =2 ,ensure_ascii =False )\n",
    "\n",
    "bins =pd .cut (df [\"target\"],bins =[-0.1 ,3 ,7 ,10.1 ],labels =[\"1-3\",\"4-7\",\"8-10\"])\n",
    "dist =bins .value_counts (dropna =False ).sort_index ()\n",
    "\n",
    "sample_i =0 \n",
    "\n",
    "bins =pd .cut (df [\"target\"],bins =[-0.1 ,3 ,7 ,10.1 ],labels =[\"1-3\",\"4-7\",\"8-10\"])\n",
    "dist =bins .value_counts (dropna =False ).sort_index ()\n",
    "\n",
    "sample_i =0 \n",
    "\n",
    "processed_path_parquet =PATHS [\"data_processed\"]/\"reviews_processed.parquet\"\n",
    "\n",
    "df_all =pd .read_parquet (processed_path_parquet ).copy ()\n",
    "\n",
    "if \"row_id\"not in df_all .columns :\n",
    "    df_all .insert (0 ,\"row_id\",np .arange (len (df_all ),dtype =np .int64 ))\n",
    "else :\n",
    "    df_all [\"row_id\"]=pd .to_numeric (df_all [\"row_id\"],errors =\"coerce\").astype (\"Int64\")\n",
    "\n",
    "BIN_EDGES =[-0.1 ,3 ,7 ,10.1 ]\n",
    "BIN_LABELS =[\"1-3\",\"4-7\",\"8-10\"]\n",
    "\n",
    "df_all [\"rating_bin\"]=pd .cut (df_all [\"target\"],bins =BIN_EDGES ,labels =BIN_LABELS ,include_lowest =True ,right =True )\n",
    "\n",
    "split_dir =PATHS [\"data_processed\"]/\"splits\"\n",
    "split_dir .mkdir (parents =True ,exist_ok =True )\n",
    "\n",
    "train_path =split_dir /\"train.parquet\"\n",
    "val_path =split_dir /\"val.parquet\"\n",
    "test_path =split_dir /\"test.parquet\"\n",
    "\n",
    "splits_meta_path =PATHS [\"reports\"]/\"splits_meta.json\"\n",
    "\n",
    "def make_splits (df :pd .DataFrame ,seed :int =42 ,\n",
    "test_size :float =0.20 ,val_size_of_trainval :float =0.20 ):\n",
    "    \"\"\"\n",
    "    1) split: trainval vs test (stratified)\n",
    "    2) split: train vs val innerhalb trainval (stratified)\n",
    "    Default => test=20%, val=16% overall (20% von 80%), train=64%.\n",
    "    \"\"\"\n",
    "    trainval ,test =train_test_split (\n",
    "    df ,test_size =test_size ,random_state =seed ,stratify =df [\"rating_bin\"]\n",
    "    )\n",
    "    train ,val =train_test_split (\n",
    "    trainval ,test_size =val_size_of_trainval ,random_state =seed ,stratify =trainval [\"rating_bin\"]\n",
    "    )\n",
    "    return train .reset_index (drop =True ),val .reset_index (drop =True ),test .reset_index (drop =True )\n",
    "\n",
    "def save_split (df_split :pd .DataFrame ,path :Path )->None :\n",
    "    df_split .to_parquet (path ,index =False )\n",
    "\n",
    "def load_split (path :Path )->pd .DataFrame :\n",
    "    return pd .read_parquet (path )\n",
    "\n",
    "if train_path .exists ()and val_path .exists ()and test_path .exists ():\n",
    "    df_train =load_split (train_path )\n",
    "    df_val =load_split (val_path )\n",
    "    df_test =load_split (test_path )\n",
    "else :\n",
    "    df_train ,df_val ,df_test =make_splits (df_all ,seed =SEED )\n",
    "    save_split (df_train ,train_path )\n",
    "    save_split (df_val ,val_path )\n",
    "    save_split (df_test ,test_path )\n",
    "\n",
    "def _relpath (p :Path )->str :\n",
    "    try :\n",
    "        return str (Path (p ).resolve ().relative_to (PATHS [\"project_root\"].resolve ()))\n",
    "    except Exception :\n",
    "        return str (p )\n",
    "\n",
    "meta ={\n",
    "\n",
    "\"seed\":SEED ,\n",
    "\"bin_edges\":BIN_EDGES ,\n",
    "\"bin_labels\":BIN_LABELS ,\n",
    "\"rating_bin_cut\":{\n",
    "\"bins\":BIN_EDGES ,\n",
    "\"labels\":BIN_LABELS ,\n",
    "\"right\":True ,\n",
    "\"include_lowest\":True ,\n",
    "\"boundary_note\":\"3→low, 7→mid\",\n",
    "},\n",
    "\"train_test_split\":{\n",
    "\"shuffle\":True ,\n",
    "\"stratify_on\":\"rating_bin\",\n",
    "\"random_state\":SEED ,\n",
    "},\n",
    "\"split_scheme\":{\"test_size\":0.20 ,\"val_size_of_trainval\":0.20 },\n",
    "\"sizes\":{\"all\":int (len (df_all )),\"train\":int (len (df_train )),\"val\":int (len (df_val )),\"test\":int (len (df_test ))},\n",
    "\"paths\":{\"train\":_relpath (train_path ),\"val\":_relpath (val_path ),\"test\":_relpath (test_path )},\n",
    "}\n",
    "with open (splits_meta_path ,\"w\",encoding =\"utf-8\")as f :\n",
    "    json .dump (meta ,f ,indent =2 ,ensure_ascii =False )\n",
    "\n",
    "subset_path =split_dir /\"subset_S.parquet\"\n",
    "subset_meta_path =PATHS [\"reports\"]/\"subset_S_meta.json\"\n",
    "\n",
    "def balanced_stratified_sample (df :pd .DataFrame ,n :int ,seed :int =42 ,strata_col :str =\"rating_bin\")->pd .DataFrame :\n",
    "    \"\"\"\n",
    "    Balanciert so gut wie möglich über Strata:\n",
    "    - Ziel: ~n/num_bins pro Bin\n",
    "    - Wenn ein Bin zu wenig hat, wird Rest auf andere Bins umverteilt.\n",
    "    \"\"\"\n",
    "    rng =np .random .default_rng (seed )\n",
    "    bins =list (df [strata_col ].astype (str ).unique ())\n",
    "    bins =[b for b in BIN_LABELS if b in bins ]\n",
    "\n",
    "    groups ={b :df [df [strata_col ].astype (str )==b ]for b in bins }\n",
    "\n",
    "    k =len (bins )\n",
    "    base =n //k \n",
    "    remainder =n %k \n",
    "    alloc ={b :base for b in bins }\n",
    "    for i in range (remainder ):\n",
    "        alloc [bins [i ]]+=1 \n",
    "\n",
    "    available ={b :len (groups [b ])for b in bins }\n",
    "    deficit =0 \n",
    "    for b in bins :\n",
    "        if alloc [b ]>available [b ]:\n",
    "            deficit +=alloc [b ]-available [b ]\n",
    "            alloc [b ]=available [b ]\n",
    "    while deficit >0 :\n",
    "        progressed =False \n",
    "        for b in bins :\n",
    "            room =available [b ]-alloc [b ]\n",
    "            if room >0 and deficit >0 :\n",
    "                take =min (room ,deficit )\n",
    "                alloc [b ]+=take \n",
    "                deficit -=take \n",
    "                progressed =True \n",
    "        if not progressed :\n",
    "            break \n",
    "\n",
    "    parts =[]\n",
    "    for b in bins :\n",
    "        g =groups [b ]\n",
    "        if alloc [b ]<=0 :\n",
    "            continue \n",
    "        idx =rng .choice (g .index .to_numpy (),size =alloc [b ],replace =False )\n",
    "        parts .append (df .loc [idx ])\n",
    "\n",
    "    out =pd .concat (parts ,axis =0 ).sample (frac =1.0 ,random_state =seed ).reset_index (drop =True )\n",
    "    return out \n",
    "\n",
    "N_S =min (CONFIG [\"llm_subset_size\"],len (df_test ))\n",
    "if subset_path .exists ():\n",
    "    df_S =pd .read_parquet (subset_path )\n",
    "else :\n",
    "    df_S =balanced_stratified_sample (df_test ,n =N_S ,seed =SEED ,strata_col =\"rating_bin\")\n",
    "    df_S .to_parquet (subset_path ,index =False )\n",
    "\n",
    "subset_meta ={\n",
    "\"seed\":SEED ,\n",
    "\"n_requested\":int (N_S ),\n",
    "\"n_actual\":int (len (df_S )),\n",
    "\"source\":\"test\",\n",
    "\"balanced_bins\":BIN_LABELS ,\n",
    "\"path\":str (subset_path ),\n",
    "}\n",
    "with open (subset_meta_path ,\"w\",encoding =\"utf-8\")as f :\n",
    "    json .dump (subset_meta ,f ,indent =2 ,ensure_ascii =False )\n",
    "\n",
    "ids_all =set (df_all [\"row_id\"].tolist ())\n",
    "ids_train =set (df_train [\"row_id\"].tolist ())\n",
    "ids_val =set (df_val [\"row_id\"].tolist ())\n",
    "ids_test =set (df_test [\"row_id\"].tolist ())\n",
    "\n",
    "union_ids =ids_train |ids_val |ids_test \n",
    "\n",
    "def bin_dist (df_ ):\n",
    "    return df_ [\"rating_bin\"].astype (str ).value_counts (normalize =True ).reindex (BIN_LABELS ).fillna (0.0 )\n",
    "\n",
    "dist_all =bin_dist (df_all )\n",
    "dist_train =bin_dist (df_train )\n",
    "dist_val =bin_dist (df_val )\n",
    "dist_test =bin_dist (df_test )\n",
    "\n",
    "dist_table =pd .DataFrame ({\n",
    "\"all\":dist_all ,\n",
    "\"train\":dist_train ,\n",
    "\"val\":dist_val ,\n",
    "\"test\":dist_test ,\n",
    "}).fillna (0.0 )\n",
    "\n",
    "try :\n",
    "    from sklearn .pipeline import Pipeline \n",
    "    from sklearn .feature_extraction .text import TfidfVectorizer \n",
    "    from sklearn .linear_model import Ridge \n",
    "    from sklearn .preprocessing import StandardScaler ,Normalizer \n",
    "except Exception as e :\n",
    "    raise ImportError (\n",
    "    \"scikit-learn fehlt. Installiere lokal z.B.:\\n\"\n",
    "    \"  pip install scikit-learn joblib\\n\"\n",
    "    f\"Original error: {e}\"\n",
    "    )\n",
    "\n",
    "HAS_MPL =True \n",
    "try :\n",
    "    import matplotlib .pyplot as plt \n",
    "except Exception :\n",
    "    HAS_MPL =False \n",
    "    plt =None \n",
    "\n",
    "def savefig_with_runid (path :Path ,**kwargs )->Path :\n",
    "    \"\"\"Save figure to `path` AND to a run-specific filename prefixed with RUN_ID.\"\"\"\n",
    "    if not HAS_MPL :\n",
    "        return path \n",
    "    plt .savefig (path ,**kwargs )\n",
    "    run_path =path .with_name (f\"{RUN_ID}_{path.name}\")\n",
    "    if str (run_path )!=str (path ):\n",
    "        plt .savefig (run_path ,**kwargs )\n",
    "    return run_path \n",
    "\n",
    "split_dir =PATHS [\"data_processed\"]/\"splits\"\n",
    "df_train =pd .read_parquet (split_dir /\"train.parquet\")\n",
    "df_val =pd .read_parquet (split_dir /\"val.parquet\")\n",
    "df_test =pd .read_parquet (split_dir /\"test.parquet\")\n",
    "df_S =pd .read_parquet (split_dir /\"subset_S.parquet\")\n",
    "\n",
    "\n",
    "def mae (y_true ,y_pred )->float :\n",
    "    y_true =np .asarray (y_true ,dtype =float )\n",
    "    y_pred =np .asarray (y_pred ,dtype =float )\n",
    "    return float (np .mean (np .abs (y_true -y_pred )))\n",
    "\n",
    "def rmse (y_true ,y_pred )->float :\n",
    "    y_true =np .asarray (y_true ,dtype =float )\n",
    "    y_pred =np .asarray (y_pred ,dtype =float )\n",
    "    return float (np .sqrt (np .mean ((y_true -y_pred )**2 )))\n",
    "\n",
    "def spearman_corr (y_true ,y_pred )->float :\n",
    "    \"\"\"\n",
    "    Spearman robust ohne scipy:\n",
    "    - rank() mit average ties\n",
    "    - dann Pearson-Korrelation der Ranks\n",
    "    \"\"\"\n",
    "    a =pd .Series (np .asarray (y_true ,dtype =float )).rank (method =\"average\").to_numpy ()\n",
    "    b =pd .Series (np .asarray (y_pred ,dtype =float )).rank (method =\"average\").to_numpy ()\n",
    "    if np .std (a )==0 or np .std (b )==0 :\n",
    "        return float (\"nan\")\n",
    "    return float (np .corrcoef (a ,b )[0 ,1 ])\n",
    "\n",
    "RATING_MIN =1.0 \n",
    "RATING_MAX =10.0 \n",
    "\n",
    "def clip_rating_pred (y :np .ndarray )->np .ndarray :\n",
    "    y =np .asarray (y ,dtype =float )\n",
    "    return np .clip (y ,RATING_MIN ,RATING_MAX )\n",
    "\n",
    "def rounded_mae (y_true :np .ndarray ,y_pred :np .ndarray )->float :\n",
    "    yt =np .asarray (y_true ,dtype =float )\n",
    "    yp =np .rint (clip_rating_pred (y_pred ))\n",
    "    return float (np .mean (np .abs (yp -yt )))\n",
    "\n",
    "def evaluate_regression (y_true ,y_pred )->Dict [str ,float ]:\n",
    "    return {\n",
    "    \"mae\":mae (y_true ,y_pred ),\n",
    "    \"rmse\":rmse (y_true ,y_pred ),\n",
    "    \"spearman\":spearman_corr (y_true ,y_pred ),\n",
    "    }\n",
    "\n",
    "def runtime_s_per_100 (samples :int ,seconds :float )->float :\n",
    "    if samples <=0 :\n",
    "        return float (\"nan\")\n",
    "    return float (seconds *100.0 /samples )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56cc065-cbd4-4408-b8df-f7183f2ead76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =df_train [\"text\"].astype (str ).tolist ()\n",
    "y_train =df_train [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "X_val =df_val [\"text\"].astype (str ).tolist ()\n",
    "y_val =df_val [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "grid =[]\n",
    "for ngram in [(1 ,1 ),(1 ,2 )]:\n",
    "    for max_features in [20000 ,50000 ]:\n",
    "        for min_df in [2 ,5 ]:\n",
    "            for alpha in [1.0 ,10.0 ,50.0 ]:\n",
    "                grid .append ({\n",
    "                \"tfidf__ngram_range\":ngram ,\n",
    "                \"tfidf__max_features\":max_features ,\n",
    "                \"tfidf__min_df\":min_df ,\n",
    "                \"tfidf__max_df\":0.95 ,\n",
    "                \"ridge__alpha\":alpha ,\n",
    "                })\n",
    "\n",
    "def make_pipeline (params :Dict [str ,Any ])->Pipeline :\n",
    "    pipe =Pipeline (steps =[\n",
    "    (\"tfidf\",TfidfVectorizer (\n",
    "    lowercase =True ,\n",
    "    strip_accents =\"unicode\",\n",
    "    stop_words =None ,\n",
    "    sublinear_tf =True ,\n",
    "    dtype =np .float32 ,\n",
    "\n",
    "    )),\n",
    "    (\"ridge\",Ridge (\n",
    "    alpha =1.0 ,\n",
    "    random_state =SEED ,\n",
    "    solver =\"lsqr\",\n",
    "    )),\n",
    "    ])\n",
    "    pipe .set_params (**params )\n",
    "    return pipe \n",
    "\n",
    "records =[]\n",
    "best =None \n",
    "\n",
    "t0_all =time .perf_counter ()\n",
    "for i ,params in enumerate (grid ,start =1 ):\n",
    "    pipe =make_pipeline (params )\n",
    "\n",
    "    t0 =time .perf_counter ()\n",
    "    pipe .fit (X_train ,y_train )\n",
    "    fit_s =time .perf_counter ()-t0 \n",
    "\n",
    "    t1 =time .perf_counter ()\n",
    "    pred_val =pipe .predict (X_val )\n",
    "    pred_s =time .perf_counter ()-t1 \n",
    "\n",
    "    pred_min ,pred_max =float (np .min (pred_val )),float (np .max (pred_val ))\n",
    "    oor =float (np .mean ((pred_val <1 )|(pred_val >10 )))\n",
    "    print (f\"[tfidf+ridge grid] pred range: {pred_min:.3f}..{pred_max:.3f} | out_of_range_rate: {oor:.3f}\")\n",
    "\n",
    "    m =evaluate_regression (y_val ,pred_val )\n",
    "    rec ={\n",
    "    \"i\":i ,\n",
    "    **params ,\n",
    "    **m ,\n",
    "    \"fit_s\":float (fit_s ),\n",
    "    \"pred_val_s\":float (pred_s ),\n",
    "    \"pred_val_s_per_100\":runtime_s_per_100 (len (X_val ),pred_s ),\n",
    "    }\n",
    "    records .append (rec )\n",
    "\n",
    "    if (best is None )or (rec [\"mae\"]<best [\"mae\"]-1e-12 )or (abs (rec [\"mae\"]-best [\"mae\"])<=1e-12 and rec [\"rmse\"]<best [\"rmse\"]):\n",
    "        best =rec \n",
    "\n",
    "t_all =time .perf_counter ()-t0_all \n",
    "\n",
    "df_grid =pd .DataFrame (records ).sort_values ([\"mae\",\"rmse\"],ascending =True ).reset_index (drop =True )\n",
    "\n",
    "METHOD =\"tfidf_ridge\"\n",
    "\n",
    "X_trainval =pd .concat ([df_train [\"text\"],df_val [\"text\"]],axis =0 ).astype (str ).tolist ()\n",
    "y_trainval =pd .concat ([df_train [\"target\"],df_val [\"target\"]],axis =0 ).astype (float ).to_numpy ()\n",
    "\n",
    "X_test =df_test [\"text\"].astype (str ).tolist ()\n",
    "y_test =df_test [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "X_S =df_S [\"text\"].astype (str ).tolist ()\n",
    "y_S =df_S [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "best_params ={k :best [k ]for k in best .keys ()if k .startswith (\"tfidf__\")or k .startswith (\"ridge__\")}\n",
    "final_pipe =make_pipeline (best_params )\n",
    "\n",
    "t0 =time .perf_counter ()\n",
    "final_pipe .fit (X_trainval ,y_trainval )\n",
    "fit_trainval_s =time .perf_counter ()-t0 \n",
    "\n",
    "t1 =time .perf_counter ()\n",
    "pred_test =final_pipe .predict (X_test )\n",
    "pred_test_raw =pred_test .copy ()\n",
    "pred_test =clip_rating_pred (pred_test )\n",
    "pred_test_s =time .perf_counter ()-t1 \n",
    "\n",
    "t2 =time .perf_counter ()\n",
    "pred_S =final_pipe .predict (X_S )\n",
    "pred_S_raw =pred_S .copy ()\n",
    "pred_S =clip_rating_pred (pred_S )\n",
    "pred_S_s =time .perf_counter ()-t2 \n",
    "\n",
    "m_test =evaluate_regression (y_test ,pred_test )\n",
    "m_S =evaluate_regression (y_S ,pred_S )\n",
    "\n",
    "reliability ={\n",
    "\"parse_success_rate\":1.0 ,\n",
    "\"schema_adherence_rate\":1.0 ,\n",
    "\"out_of_range_rate\":0.0 ,\n",
    "\"empty_refusal_rate\":0.0 ,\n",
    "}\n",
    "coverage =1.0 \n",
    "\n",
    "model_path =PATHS [\"models\"]/f\"{METHOD}.joblib\"\n",
    "joblib .dump (final_pipe ,model_path )\n",
    "\n",
    "tuned_pipe =make_pipeline (best_params )\n",
    "tuned_pipe .fit (X_train ,y_train )\n",
    "pred_val_tuned =tuned_pipe .predict (X_val )\n",
    "\n",
    "pred_path =PATHS [\"reports\"]/f\"predictions_{METHOD}.parquet\"\n",
    "pred_df =pd .concat ([\n",
    "pd .DataFrame ({\n",
    "\"row_id\":df_val [\"row_id\"].to_numpy (),\n",
    "\"split\":\"val\",\n",
    "\"method\":METHOD ,\n",
    "\"y_true\":y_val ,\n",
    "\"y_pred\":pred_val_tuned ,\n",
    "}),\n",
    "pd .DataFrame ({\n",
    "\"row_id\":df_test [\"row_id\"].to_numpy (),\n",
    "\"split\":\"test\",\n",
    "\"method\":METHOD ,\n",
    "\"y_true\":y_test ,\n",
    "\"y_pred\":pred_test ,\n",
    "}),\n",
    "pd .DataFrame ({\n",
    "\"row_id\":df_S [\"row_id\"].to_numpy (),\n",
    "\"split\":\"S\",\n",
    "\"method\":METHOD ,\n",
    "\"y_true\":y_S ,\n",
    "\"y_pred\":pred_S ,\n",
    "}),\n",
    "],axis =0 ).reset_index (drop =True )\n",
    "\n",
    "pred_df .to_parquet (pred_path ,index =False )\n",
    "\n",
    "results_path =PATHS [\"reports\"]/\"results.csv\"\n",
    "\n",
    "def upsert_results (existing :Optional [pd .DataFrame ],new_rows :pd .DataFrame ,key_cols :List [str ])->pd .DataFrame :\n",
    "    if existing is None or len (existing )==0 :\n",
    "        out =new_rows .copy ()\n",
    "    else :\n",
    "        out =pd .concat ([existing ,new_rows ],axis =0 ,ignore_index =True )\n",
    "        out [\"_dupkey\"]=out [key_cols ].astype (str ).agg (\"||\".join ,axis =1 )\n",
    "        out =out .drop_duplicates (subset =\"_dupkey\",keep =\"last\").drop (columns =[\"_dupkey\"])\n",
    "    return out .sort_values (key_cols ).reset_index (drop =True )\n",
    "\n",
    "timestamp_utc =time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ())\n",
    "\n",
    "new_rows =pd .DataFrame ([\n",
    "{\n",
    "\"timestamp_utc\":timestamp_utc ,\n",
    "\"method\":METHOD ,\n",
    "\"split\":\"test\",\n",
    "**best_params ,\n",
    "**m_test ,\n",
    "**reliability ,\n",
    "\"coverage\":coverage ,\n",
    "\"risk_mae\":m_test [\"mae\"],\n",
    "\"risk_rmse\":m_test [\"rmse\"],\n",
    "\"fit_trainval_s\":float (fit_trainval_s ),\n",
    "\"inference_s\":float (pred_test_s ),\n",
    "\"sec_per_100\":runtime_s_per_100 (len (X_test ),pred_test_s ),\n",
    "\"n_samples\":int (len (X_test )),\n",
    "\"notes\":\"tuned_on=val; final_fit=train+val\",\n",
    "},\n",
    "{\n",
    "\"timestamp_utc\":timestamp_utc ,\n",
    "\"method\":METHOD ,\n",
    "\"split\":\"S\",\n",
    "**best_params ,\n",
    "**m_S ,\n",
    "**reliability ,\n",
    "\"coverage\":coverage ,\n",
    "\"risk_mae\":m_S [\"mae\"],\n",
    "\"risk_rmse\":m_S [\"rmse\"],\n",
    "\"fit_trainval_s\":float (fit_trainval_s ),\n",
    "\"inference_s\":float (pred_S_s ),\n",
    "\"sec_per_100\":runtime_s_per_100 (len (X_S ),pred_S_s ),\n",
    "\"n_samples\":int (len (X_S )),\n",
    "\"notes\":\"tuned_on=val; final_fit=train+val\",\n",
    "},\n",
    "])\n",
    "\n",
    "if results_path .exists ():\n",
    "    df_exist =pd .read_csv (results_path )\n",
    "else :\n",
    "    df_exist =pd .DataFrame ()\n",
    "\n",
    "df_results =upsert_results (df_exist ,new_rows ,key_cols =[\"method\",\"split\"])\n",
    "df_results .to_csv (results_path ,index =False )\n",
    "\n",
    "plot_path =PATHS [\"figs\"]/f\"{METHOD}_pred_vs_true_test.png\"\n",
    "if HAS_MPL :\n",
    "    plt .figure ()\n",
    "    plt .scatter (y_test ,pred_test ,alpha =0.5 )\n",
    "    plt .xlabel (\"y_true\")\n",
    "    plt .ylabel (\"y_pred\")\n",
    "    plt .title (\"TF-IDF + Ridge: Test y_true vs y_pred\")\n",
    "    plt .tight_layout ()\n",
    "    savefig_with_runid (plot_path ,dpi =150 )\n",
    "    plt .close ()\n",
    "\n",
    "METHOD =\"tfidf_ridge\"\n",
    "model_path =PATHS [\"models\"]/f\"{METHOD}.joblib\"\n",
    "pred_path =PATHS [\"reports\"]/f\"predictions_{METHOD}.parquet\"\n",
    "results_path =PATHS [\"reports\"]/\"results.csv\"\n",
    "\n",
    "pred_df_check =pd .read_parquet (pred_path )\n",
    "\n",
    "n_val =(pred_df_check [\"split\"]==\"val\").sum ()\n",
    "n_test =(pred_df_check [\"split\"]==\"test\").sum ()\n",
    "n_S =(pred_df_check [\"split\"]==\"S\").sum ()\n",
    "\n",
    "tmp =pred_df_check [pred_df_check [\"split\"]==\"test\"]\n",
    "m =evaluate_regression (tmp [\"y_true\"].to_numpy (),tmp [\"y_pred\"].to_numpy ())\n",
    "\n",
    "df_res =pd .read_csv (results_path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480eb89-2b3a-4e9a-a7c1-48a0c6faf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings .filterwarnings (\"ignore\",category =UserWarning )\n",
    "\n",
    "try :\n",
    "    import torch \n",
    "    from transformers import AutoTokenizer ,AutoModel \n",
    "except Exception as e :\n",
    "    raise ImportError (\n",
    "    \"Fehlende Dependencies für Embeddings.\\n\"\n",
    "    \"Installiere lokal (Terminal):\\n\"\n",
    "    \"  pip install torch transformers\\n\"\n",
    "    f\"Original error: {e}\"\n",
    "    )\n",
    "\n",
    "HAS_ST =True \n",
    "try :\n",
    "    from sentence_transformers import SentenceTransformer \n",
    "except Exception :\n",
    "    HAS_ST =False \n",
    "\n",
    "\n",
    "EMB_MODEL_NAME =\"all-MiniLM-L6-v2\"\n",
    "METHOD =\"minilm_ridge\"\n",
    "\n",
    "def get_device ()->str :\n",
    "    if torch .cuda .is_available ():\n",
    "        return \"cuda\"\n",
    "    if hasattr (torch .backends ,\"mps\")and torch .backends .mps .is_available ():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "DEVICE =get_device ()\n",
    "\n",
    "\n",
    "processed_parquet =PATHS [\"data_processed\"]/\"reviews_processed.parquet\"\n",
    "processed_csv =PATHS [\"data_processed\"]/\"reviews_processed.csv\"\n",
    "\n",
    "df_all =pd .read_parquet (processed_parquet ).copy ()\n",
    "\n",
    "\n",
    "df_all =df_all .reset_index (drop =True )\n",
    "\n",
    "if \"row_id\"not in df_all .columns :\n",
    "    df_all .insert (0 ,\"row_id\",np .arange (len (df_all ),dtype =np .int64 ))\n",
    "    df_all .to_parquet (processed_parquet ,index =False )\n",
    "    if processed_csv .exists ():\n",
    "        df_all .to_csv (processed_csv ,index =False )\n",
    "else :\n",
    "    df_all [\"row_id\"]=pd .to_numeric (df_all [\"row_id\"],errors =\"coerce\").astype (\"Int64\")\n",
    "    df_all [\"row_id\"]=df_all [\"row_id\"].astype (np .int64 )\n",
    "\n",
    "split_dir =PATHS [\"data_processed\"]/\"splits\"\n",
    "df_train =pd .read_parquet (split_dir /\"train.parquet\")\n",
    "df_val =pd .read_parquet (split_dir /\"val.parquet\")\n",
    "df_test =pd .read_parquet (split_dir /\"test.parquet\")\n",
    "\n",
    "\n",
    "df_all =df_all .sort_values (\"row_id\").reset_index (drop =True )\n",
    "\n",
    "features_dir =PATHS [\"data_features\"]\n",
    "emb_path =features_dir /f\"emb_{EMB_MODEL_NAME.replace('/','_')}.npz\"\n",
    "emb_meta_path =features_dir /f\"emb_{EMB_MODEL_NAME.replace('/','_')}_meta.json\"\n",
    "\n",
    "def mean_pooling (last_hidden_state :torch .Tensor ,attention_mask :torch .Tensor )->torch .Tensor :\n",
    "    mask =attention_mask .unsqueeze (-1 ).type_as (last_hidden_state )\n",
    "    summed =(last_hidden_state *mask ).sum (dim =1 )\n",
    "    counts =mask .sum (dim =1 ).clamp (min =1e-9 )\n",
    "    return summed /counts \n",
    "\n",
    "@torch .no_grad ()\n",
    "def embed_texts_transformers (texts :List [str ],batch_size :int =32 ,max_length :int =256 )->np .ndarray :\n",
    "    \"\"\"\n",
    "    Fallback Encoder: HF MiniLM + mean pooling.\n",
    "    (Wenn sentence-transformers fehlt.)\n",
    "    \"\"\"\n",
    "    tokenizer =AutoTokenizer .from_pretrained (EMB_MODEL_NAME )\n",
    "    model =AutoModel .from_pretrained (EMB_MODEL_NAME ).to (DEVICE )\n",
    "    model .eval ()\n",
    "\n",
    "    all_vecs =[]\n",
    "    for i in range (0 ,len (texts ),batch_size ):\n",
    "        batch =texts [i :i +batch_size ]\n",
    "        enc =tokenizer (\n",
    "        batch ,\n",
    "        padding =True ,\n",
    "        truncation =True ,\n",
    "        max_length =max_length ,\n",
    "        return_tensors =\"pt\",\n",
    "        )\n",
    "        enc ={k :v .to (DEVICE )for k ,v in enc .items ()}\n",
    "        out =model (**enc )\n",
    "        pooled =mean_pooling (out .last_hidden_state ,enc [\"attention_mask\"])\n",
    "        pooled =torch .nn .functional .normalize (pooled ,p =2 ,dim =1 )\n",
    "        all_vecs .append (pooled .cpu ().numpy ().astype (np .float32 ))\n",
    "    return np .vstack (all_vecs )\n",
    "\n",
    "def embed_texts_sentence_transformers (texts :List [str ],batch_size :int =32 )->np .ndarray :\n",
    "    \"\"\"\n",
    "    Exakter SBERT Encoder (wenn sentence-transformers verfügbar).\n",
    "    \"\"\"\n",
    "    st =SentenceTransformer (EMB_MODEL_NAME ,device =DEVICE )\n",
    "    vecs =st .encode (\n",
    "    texts ,\n",
    "    batch_size =batch_size ,\n",
    "    show_progress_bar =True ,\n",
    "    convert_to_numpy =True ,\n",
    "    normalize_embeddings =True ,\n",
    "    )\n",
    "    return vecs .astype (np .float32 )\n",
    "\n",
    "def load_embeddings_npz (path :Path )->Tuple [np .ndarray ,np .ndarray ]:\n",
    "    data =np .load (path ,allow_pickle =False )\n",
    "    row_ids =data [\"row_id\"].astype (np .int64 )\n",
    "    emb =data [\"emb\"].astype (np .float32 )\n",
    "    return row_ids ,emb \n",
    "\n",
    "def save_embeddings_npz (path :Path ,row_ids :np .ndarray ,emb :np .ndarray )->None :\n",
    "    np .savez_compressed (path ,row_id =row_ids .astype (np .int64 ),emb =emb .astype (np .float32 ))\n",
    "\n",
    "def embeddings_cache_valid (path :Path ,df :pd .DataFrame )->bool :\n",
    "    if not path .exists ():\n",
    "        return False \n",
    "    try :\n",
    "        row_ids ,emb =load_embeddings_npz (path )\n",
    "        ok =(len (row_ids )==len (df ))and (row_ids .min ()==df [\"row_id\"].min ())and (row_ids .max ()==df [\"row_id\"].max ())\n",
    "        ok =ok and np .array_equal (row_ids ,df [\"row_id\"].to_numpy (dtype =np .int64 ))\n",
    "        ok =ok and (emb .shape [0 ]==len (df ))and (emb .ndim ==2 )\n",
    "        return bool (ok )\n",
    "    except Exception :\n",
    "        return False \n",
    "\n",
    "texts_all =df_all [\"text\"].astype (str ).tolist ()\n",
    "row_ids_all =df_all [\"row_id\"].to_numpy (dtype =np .int64 )\n",
    "\n",
    "if embeddings_cache_valid (emb_path ,df_all ):\n",
    "    row_ids_cached ,emb_all =load_embeddings_npz (emb_path )\n",
    "    cached =True \n",
    "    embed_total_s =None \n",
    "else :\n",
    "    cached =False \n",
    "\n",
    "    MAX_LENGTH =256 \n",
    "    BATCH_SIZE =32 if DEVICE !=\"cpu\"else 16 \n",
    "\n",
    "    t0 =time .perf_counter ()\n",
    "    if HAS_ST :\n",
    "        emb_all =embed_texts_sentence_transformers (texts_all ,batch_size =BATCH_SIZE )\n",
    "        backend =\"sentence_transformers\"\n",
    "    else :\n",
    "        emb_all =embed_texts_transformers (texts_all ,batch_size =BATCH_SIZE ,max_length =MAX_LENGTH )\n",
    "        backend =\"hf_transformers_mean_pool\"\n",
    "    embed_total_s =float (time .perf_counter ()-t0 )\n",
    "\n",
    "    save_embeddings_npz (emb_path ,row_ids_all ,emb_all )\n",
    "\n",
    "    meta ={\n",
    "    \"created_utc\":time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ()),\n",
    "    \"model\":EMB_MODEL_NAME ,\n",
    "    \"backend\":backend ,\n",
    "    \"device\":DEVICE ,\n",
    "    \"batch_size\":int (BATCH_SIZE ),\n",
    "    \"max_length_if_hf_fallback\":int (MAX_LENGTH ),\n",
    "    \"n_samples\":int (len (df_all )),\n",
    "    \"emb_dim\":int (emb_all .shape [1 ]),\n",
    "    \"total_embed_s\":embed_total_s ,\n",
    "    }\n",
    "    with open (emb_meta_path ,\"w\",encoding =\"utf-8\")as f :\n",
    "        json .dump (meta ,f ,indent =2 ,ensure_ascii =False )\n",
    "\n",
    "    LOGGER .info (f\"Embeddings berechnet: n={len(df_all)} dim={emb_all.shape[1]} total_s={embed_total_s:.2f} backend={backend}\")\n",
    "\n",
    "\n",
    "split_dir =PATHS [\"data_processed\"]/\"splits\"\n",
    "df_train =pd .read_parquet (split_dir /\"train.parquet\").sort_values (\"row_id\").reset_index (drop =True )\n",
    "df_val =pd .read_parquet (split_dir /\"val.parquet\").sort_values (\"row_id\").reset_index (drop =True )\n",
    "df_test =pd .read_parquet (split_dir /\"test.parquet\").sort_values (\"row_id\").reset_index (drop =True )\n",
    "df_S =pd .read_parquet (split_dir /\"subset_S.parquet\").sort_values (\"row_id\").reset_index (drop =True )\n",
    "\n",
    "row_to_ix ={rid :i for i ,rid in enumerate (row_ids_all .tolist ())}\n",
    "\n",
    "def get_X_from_row_ids (df_split :pd .DataFrame )->np .ndarray :\n",
    "    idx =[row_to_ix [int (r )]for r in df_split [\"row_id\"].to_numpy ()]\n",
    "    return emb_all [np .array (idx ,dtype =np .int64 )]\n",
    "\n",
    "X_train =get_X_from_row_ids (df_train )\n",
    "y_train =df_train [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "X_val =get_X_from_row_ids (df_val )\n",
    "y_val =df_val [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "X_trainval =np .vstack ([X_train ,X_val ])\n",
    "y_trainval =np .concatenate ([y_train ,y_val ])\n",
    "\n",
    "X_test =get_X_from_row_ids (df_test )\n",
    "y_test =df_test [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "X_S =get_X_from_row_ids (df_S )\n",
    "y_S =df_S [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "\n",
    "preprocs ={\n",
    "\"none\":None ,\n",
    "\"scaler\":StandardScaler (with_mean =True ,with_std =True ),\n",
    "\"l2norm\":Normalizer (norm =\"l2\"),\n",
    "}\n",
    "\n",
    "def build_ridge_pipe (preproc_name :str ,alpha :float )->Pipeline :\n",
    "    steps =[]\n",
    "    if preprocs [preproc_name ]is not None :\n",
    "        steps .append ((\"pre\",preprocs [preproc_name ]))\n",
    "    steps .append ((\"ridge\",Ridge (alpha =float (alpha ),random_state =SEED )))\n",
    "    return Pipeline (steps )\n",
    "\n",
    "alphas =[0.1 ,1.0 ,10.0 ,50.0 ,100.0 ,300.0 ]\n",
    "preproc_names =[\"none\",\"scaler\",\"l2norm\"]\n",
    "\n",
    "best =None \n",
    "records =[]\n",
    "\n",
    "t0_grid =time .perf_counter ()\n",
    "for pp in preproc_names :\n",
    "    for a in alphas :\n",
    "        pipe =build_ridge_pipe (pp ,a )\n",
    "\n",
    "        t0 =time .perf_counter ()\n",
    "        pipe .fit (X_train ,y_train )\n",
    "        fit_s =time .perf_counter ()-t0 \n",
    "\n",
    "        t1 =time .perf_counter ()\n",
    "        pred_val =pipe .predict (X_val )\n",
    "        pred_val_raw =pred_val .copy ()\n",
    "        pred_val =clip_rating_pred (pred_val )\n",
    "        pred_s =time .perf_counter ()-t1 \n",
    "\n",
    "        print (\"[minilm ridge grid]\",\"preproc=\",pp ,\"alpha=\",a ,\n",
    "        \"| pred range:\",float (np .min (pred_val )),float (np .max (pred_val )),\n",
    "        \"| out_of_range_rate:\",float (np .mean ((pred_val <1 )|(pred_val >10 ))))\n",
    "\n",
    "        m =evaluate_regression (y_val ,pred_val )\n",
    "        rec ={\n",
    "        \"preproc\":pp ,\n",
    "        \"ridge__alpha\":float (a ),\n",
    "        **m ,\n",
    "        \"fit_s\":float (fit_s ),\n",
    "        \"pred_val_s\":float (pred_s ),\n",
    "        \"pred_val_s_per_100\":runtime_s_per_100 (len (X_val ),pred_s ),\n",
    "        }\n",
    "        records .append (rec )\n",
    "\n",
    "        if (best is None )or (rec [\"mae\"]<best [\"mae\"]-1e-12 )or (abs (rec [\"mae\"]-best [\"mae\"])<=1e-12 and rec [\"rmse\"]<best [\"rmse\"]):\n",
    "            best =rec \n",
    "\n",
    "grid_s =time .perf_counter ()-t0_grid \n",
    "df_grid =pd .DataFrame (records ).sort_values ([\"mae\",\"rmse\"],ascending =True ).reset_index (drop =True )\n",
    "\n",
    "final_pipe =build_ridge_pipe (best [\"preproc\"],best [\"ridge__alpha\"])\n",
    "t0 =time .perf_counter ()\n",
    "final_pipe .fit (X_trainval ,y_trainval )\n",
    "fit_trainval_s =time .perf_counter ()-t0 \n",
    "\n",
    "t1 =time .perf_counter ()\n",
    "pred_test =final_pipe .predict (X_test )\n",
    "pred_test_raw =pred_test .copy ()\n",
    "pred_test =clip_rating_pred (pred_test )\n",
    "pred_test_s =time .perf_counter ()-t1 \n",
    "\n",
    "t2 =time .perf_counter ()\n",
    "pred_S =final_pipe .predict (X_S )\n",
    "pred_S_raw =pred_S .copy ()\n",
    "pred_S =clip_rating_pred (pred_S )\n",
    "pred_S_s =time .perf_counter ()-t2 \n",
    "\n",
    "m_test =evaluate_regression (y_test ,pred_test )\n",
    "m_S =evaluate_regression (y_S ,pred_S )\n",
    "\n",
    "\n",
    "import joblib \n",
    "\n",
    "tuned_pipe =build_ridge_pipe (best [\"preproc\"],best [\"ridge__alpha\"])\n",
    "tuned_pipe .fit (X_train ,y_train )\n",
    "pred_val_tuned =tuned_pipe .predict (X_val )\n",
    "\n",
    "model_path =PATHS [\"models\"]/f\"{METHOD}.joblib\"\n",
    "joblib .dump (final_pipe ,model_path )\n",
    "\n",
    "pred_path =PATHS [\"reports\"]/f\"predictions_{METHOD}.parquet\"\n",
    "pred_df =pd .concat ([\n",
    "pd .DataFrame ({\n",
    "\"row_id\":df_val [\"row_id\"].to_numpy (),\n",
    "\"split\":\"val\",\n",
    "\"method\":METHOD ,\n",
    "\"y_true\":y_val ,\n",
    "\"y_pred\":pred_val_tuned ,\n",
    "}),\n",
    "pd .DataFrame ({\n",
    "\"row_id\":df_test [\"row_id\"].to_numpy (),\n",
    "\"split\":\"test\",\n",
    "\"method\":METHOD ,\n",
    "\"y_true\":y_test ,\n",
    "\"y_pred\":pred_test ,\n",
    "}),\n",
    "pd .DataFrame ({\n",
    "\"row_id\":df_S [\"row_id\"].to_numpy (),\n",
    "\"split\":\"S\",\n",
    "\"method\":METHOD ,\n",
    "\"y_true\":y_S ,\n",
    "\"y_pred\":pred_S ,\n",
    "}),\n",
    "],axis =0 ).reset_index (drop =True )\n",
    "pred_df .to_parquet (pred_path ,index =False )\n",
    "\n",
    "reliability ={\n",
    "\"parse_success_rate\":1.0 ,\n",
    "\"schema_adherence_rate\":1.0 ,\n",
    "\"out_of_range_rate\":0.0 ,\n",
    "\"empty_refusal_rate\":0.0 ,\n",
    "}\n",
    "coverage =1.0 \n",
    "\n",
    "embed_meta =None \n",
    "if emb_meta_path .exists ():\n",
    "    with open (emb_meta_path ,\"r\",encoding =\"utf-8\")as f :\n",
    "        embed_meta =json .load (f )\n",
    "\n",
    "def estimated_embed_s (n_split :int )->float :\n",
    "    if not embed_meta or not embed_meta .get (\"total_embed_s\"):\n",
    "        return float (\"nan\")\n",
    "    total_s =float (embed_meta [\"total_embed_s\"])\n",
    "    n_all =int (embed_meta [\"n_samples\"])\n",
    "    return float (total_s *(n_split /max (1 ,n_all )))\n",
    "\n",
    "timestamp_utc =time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ())\n",
    "feature_s_test =estimated_embed_s (len (df_test ))\n",
    "feature_s_S =estimated_embed_s (len (df_S ))\n",
    "\n",
    "sec_per_100_test =runtime_s_per_100 (len (df_test ),(0.0 if math .isnan (feature_s_test )else feature_s_test )+pred_test_s )\n",
    "sec_per_100_S =runtime_s_per_100 (len (df_S ),(0.0 if math .isnan (feature_s_S )else feature_s_S )+pred_S_s )\n",
    "\n",
    "new_rows =pd .DataFrame ([\n",
    "{\n",
    "\"timestamp_utc\":timestamp_utc ,\n",
    "\"method\":METHOD ,\n",
    "\"split\":\"test\",\n",
    "\"ridge__alpha\":float (best [\"ridge__alpha\"]),\n",
    "**m_test ,\n",
    "**reliability ,\n",
    "\"coverage\":coverage ,\n",
    "\"risk_mae\":m_test [\"mae\"],\n",
    "\"risk_rmse\":m_test [\"rmse\"],\n",
    "\"fit_trainval_s\":float (fit_trainval_s ),\n",
    "\"feature_s_est\":float (feature_s_test )if not math .isnan (feature_s_test )else np .nan ,\n",
    "\"inference_s\":float (pred_test_s ),\n",
    "\"sec_per_100\":float (sec_per_100_test ),\n",
    "\"n_samples\":int (len (df_test )),\n",
    "\"notes\":f\"emb_model={EMB_MODEL_NAME}; preproc={best.get('preproc')}; cached={cached}\",\n",
    "},\n",
    "{\n",
    "\"timestamp_utc\":timestamp_utc ,\n",
    "\"method\":METHOD ,\n",
    "\"split\":\"S\",\n",
    "\"ridge__alpha\":float (best [\"ridge__alpha\"]),\n",
    "**m_S ,\n",
    "**reliability ,\n",
    "\"coverage\":coverage ,\n",
    "\"risk_mae\":m_S [\"mae\"],\n",
    "\"risk_rmse\":m_S [\"rmse\"],\n",
    "\"fit_trainval_s\":float (fit_trainval_s ),\n",
    "\"feature_s_est\":float (feature_s_S )if not math .isnan (feature_s_S )else np .nan ,\n",
    "\"inference_s\":float (pred_S_s ),\n",
    "\"sec_per_100\":float (sec_per_100_S ),\n",
    "\"n_samples\":int (len (df_S )),\n",
    "\"notes\":f\"emb_model={EMB_MODEL_NAME}; preproc={best.get('preproc')}; cached={cached}\",\n",
    "},\n",
    "])\n",
    "\n",
    "results_path =PATHS [\"reports\"]/\"results.csv\"\n",
    "\n",
    "def upsert_results (existing :Optional [pd .DataFrame ],new_rows :pd .DataFrame ,key_cols :List [str ])->pd .DataFrame :\n",
    "    if existing is None or len (existing )==0 :\n",
    "        out =new_rows .copy ()\n",
    "    else :\n",
    "        out =pd .concat ([existing ,new_rows ],axis =0 ,ignore_index =True )\n",
    "        out [\"_dupkey\"]=out [key_cols ].astype (str ).agg (\"||\".join ,axis =1 )\n",
    "        out =out .drop_duplicates (subset =\"_dupkey\",keep =\"last\").drop (columns =[\"_dupkey\"])\n",
    "    return out .sort_values (key_cols ).reset_index (drop =True )\n",
    "\n",
    "df_exist =pd .read_csv (results_path )if results_path .exists ()else pd .DataFrame ()\n",
    "df_results =upsert_results (df_exist ,new_rows ,key_cols =[\"method\",\"split\"])\n",
    "df_results .to_csv (results_path ,index =False )\n",
    "\n",
    "plot_path =PATHS [\"figs\"]/f\"{METHOD}_pred_vs_true_test.png\"\n",
    "if HAS_MPL :\n",
    "    plt .figure ()\n",
    "    plt .scatter (y_test ,pred_test ,alpha =0.5 )\n",
    "    plt .xlabel (\"y_true\")\n",
    "    plt .ylabel (\"y_pred\")\n",
    "    plt .title (\"MiniLM Embeddings + Ridge: Test y_true vs y_pred\")\n",
    "    plt .tight_layout ()\n",
    "    savefig_with_runid (plot_path ,dpi =150 )\n",
    "    plt .close ()\n",
    "\n",
    "row_ids_chk ,emb_chk =load_embeddings_npz (emb_path )\n",
    "\n",
    "pred_df_check =pd .read_parquet (pred_path )\n",
    "\n",
    "tmp =pred_df_check [pred_df_check [\"split\"]==\"test\"]\n",
    "m =evaluate_regression (tmp [\"y_true\"].to_numpy (),tmp [\"y_pred\"].to_numpy ())\n",
    "\n",
    "df_res =pd .read_csv (results_path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92f2ba-263b-48bb-a570-68161a0dff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "from torch .utils .data import Dataset ,DataLoader \n",
    "\n",
    "from transformers import AutoTokenizer ,AutoModelForSequenceClassification \n",
    "\n",
    "try :\n",
    "    from transformers import set_seed as hf_set_seed \n",
    "    hf_set_seed (SEED )\n",
    "except Exception :\n",
    "    pass \n",
    "\n",
    "def get_device ()->str :\n",
    "    if torch .cuda .is_available ():\n",
    "        return \"cuda\"\n",
    "    if hasattr (torch .backends ,\"mps\")and torch .backends .mps .is_available ():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "DEVICE =get_device ()\n",
    "\n",
    "split_dir =PATHS [\"data_processed\"]/\"splits\"\n",
    "df_train =pd .read_parquet (split_dir /\"train.parquet\")\n",
    "df_val =pd .read_parquet (split_dir /\"val.parquet\")\n",
    "df_test =pd .read_parquet (split_dir /\"test.parquet\")\n",
    "df_S =pd .read_parquet (split_dir /\"subset_S.parquet\")\n",
    "\n",
    "\n",
    "MODEL_NAME =\"distilbert-base-uncased\"\n",
    "tokenizer =AutoTokenizer .from_pretrained (MODEL_NAME )\n",
    "\n",
    "def estimate_token_lengths (texts ,max_n :int =2000 ):\n",
    "    n =min (max_n ,len (texts ))\n",
    "    rng =np .random .default_rng (SEED )\n",
    "    idx =rng .choice (np .arange (len (texts )),size =n ,replace =False )\n",
    "    sample =[texts [i ]for i in idx ]\n",
    "    lens =[]\n",
    "    for t in sample :\n",
    "        ids =tokenizer (t ,add_special_tokens =True ,truncation =False )[\"input_ids\"]\n",
    "        lens .append (len (ids ))\n",
    "    return np .array (lens ,dtype =np .int32 )\n",
    "\n",
    "train_texts =df_train [\"text\"].astype (str ).tolist ()\n",
    "lens =estimate_token_lengths (train_texts ,max_n =2000 )\n",
    "\n",
    "q50 ,q90 ,q95 ,q99 =np .quantile (lens ,[0.50 ,0.90 ,0.95 ,0.99 ])\n",
    "max_len_raw =int (lens .max ())\n",
    "\n",
    "def choose_max_length (p95 :float ,cap :int =384 ,floor :int =128 )->int :\n",
    "    m =int (math .ceil (p95 /8 )*8 )\n",
    "    m =max (floor ,m )\n",
    "    m =min (cap ,m )\n",
    "    return m \n",
    "\n",
    "MAX_LENGTH =choose_max_length (q95 ,cap =384 ,floor =128 )\n",
    "\n",
    "METHOD =\"distilbert_reg\"\n",
    "\n",
    "class TextRegDataset (Dataset ):\n",
    "    def __init__ (self ,texts ,targets ,tokenizer ,max_length :int ):\n",
    "        self .texts =[str (t )for t in texts ]\n",
    "        self .targets =np .asarray (targets ,dtype =np .float32 )\n",
    "        self .tokenizer =tokenizer \n",
    "        self .max_length =int (max_length )\n",
    "\n",
    "    def __len__ (self ):\n",
    "        return len (self .texts )\n",
    "\n",
    "    def __getitem__ (self ,idx :int ):\n",
    "        enc =self .tokenizer (\n",
    "        self .texts [idx ],\n",
    "        padding =\"max_length\",\n",
    "        truncation =True ,\n",
    "        max_length =self .max_length ,\n",
    "        return_tensors =\"pt\",\n",
    "        )\n",
    "        item ={k :v .squeeze (0 )for k ,v in enc .items ()}\n",
    "        item [\"labels\"]=torch .tensor (self .targets [idx ],dtype =torch .float32 )\n",
    "        return item \n",
    "\n",
    "def build_model (model_name :str )->nn .Module :\n",
    "    m =AutoModelForSequenceClassification .from_pretrained (model_name ,num_labels =1 )\n",
    "    try :\n",
    "        m .config .problem_type =\"regression\"\n",
    "    except Exception :\n",
    "        pass \n",
    "    return m \n",
    "\n",
    "model =build_model (MODEL_NAME ).to (DEVICE )\n",
    "\n",
    "FREEZE_FIRST_N_LAYERS =4 \n",
    "\n",
    "def freeze_distilbert_layers (model :nn .Module ,n_freeze :int )->int :\n",
    "    frozen =0 \n",
    "    try :\n",
    "        layers =model .distilbert .transformer .layer \n",
    "        for i ,layer in enumerate (layers ):\n",
    "            if i <n_freeze :\n",
    "                for p in layer .parameters ():\n",
    "                    p .requires_grad =False \n",
    "                frozen +=1 \n",
    "    except Exception as e :\n",
    "        print (\"Konnte Layers nicht sauber freezen:\",repr (e ))\n",
    "    return frozen \n",
    "\n",
    "frozen_layers =freeze_distilbert_layers (model ,FREEZE_FIRST_N_LAYERS )\n",
    "\n",
    "EPOCHS =3 \n",
    "BATCH_SIZE =8 if DEVICE !=\"cpu\"else 4 \n",
    "LR =2e-5 \n",
    "WEIGHT_DECAY =0.01 \n",
    "PATIENCE =1 \n",
    "MAX_GRAD_NORM =1.0 \n",
    "\n",
    "train_ds =TextRegDataset (df_train [\"text\"].tolist (),df_train [\"target\"].to_numpy (),tokenizer ,MAX_LENGTH )\n",
    "val_ds =TextRegDataset (df_val [\"text\"].tolist (),df_val [\"target\"].to_numpy (),tokenizer ,MAX_LENGTH )\n",
    "\n",
    "train_loader =DataLoader (train_ds ,batch_size =BATCH_SIZE ,shuffle =True ,drop_last =False )\n",
    "val_loader =DataLoader (val_ds ,batch_size =BATCH_SIZE ,shuffle =False ,drop_last =False )\n",
    "\n",
    "optimizer =torch .optim .AdamW ([p for p in model .parameters ()if p .requires_grad ],lr =LR ,weight_decay =WEIGHT_DECAY )\n",
    "\n",
    "def forward_batch (model ,batch ):\n",
    "    batch ={k :v .to (DEVICE )for k ,v in batch .items ()}\n",
    "    out =model (**batch )\n",
    "    loss =out .loss \n",
    "    preds =out .logits .squeeze (-1 ).detach ()\n",
    "    return loss ,preds \n",
    "\n",
    "@torch .no_grad ()\n",
    "def eval_loader (model ,loader )->Tuple [np .ndarray ,np .ndarray ,float ]:\n",
    "    model .eval ()\n",
    "    preds_all ,y_all =[],[]\n",
    "    total_loss =0.0 \n",
    "    n =0 \n",
    "    for batch in loader :\n",
    "        loss ,preds =forward_batch (model ,batch )\n",
    "        bs =preds .shape [0 ]\n",
    "        total_loss +=float (loss .item ())*bs \n",
    "        n +=bs \n",
    "        preds_all .append (preds .cpu ().numpy ())\n",
    "        y_all .append (batch [\"labels\"].cpu ().numpy ())\n",
    "    preds_all =np .concatenate (preds_all ,axis =0 )\n",
    "    y_all =np .concatenate (y_all ,axis =0 )\n",
    "    avg_loss =total_loss /max (1 ,n )\n",
    "    return y_all ,preds_all ,avg_loss \n",
    "\n",
    "best_state =None \n",
    "best_val_mae =float (\"inf\")\n",
    "bad_epochs =0 \n",
    "history =[]\n",
    "\n",
    "t_train0 =time .perf_counter ()\n",
    "for epoch in range (1 ,EPOCHS +1 ):\n",
    "    model .train ()\n",
    "    running =0.0 \n",
    "    n_seen =0 \n",
    "\n",
    "    t0 =time .perf_counter ()\n",
    "    for batch in train_loader :\n",
    "        optimizer .zero_grad (set_to_none =True )\n",
    "        loss ,_ =forward_batch (model ,batch )\n",
    "        loss .backward ()\n",
    "        torch .nn .utils .clip_grad_norm_ (model .parameters (),MAX_GRAD_NORM )\n",
    "        optimizer .step ()\n",
    "\n",
    "        bs =batch [\"labels\"].shape [0 ]\n",
    "        running +=float (loss .item ())*bs \n",
    "        n_seen +=bs \n",
    "\n",
    "    train_loss =running /max (1 ,n_seen )\n",
    "    epoch_s =time .perf_counter ()-t0 \n",
    "\n",
    "    yv ,pv ,val_loss =eval_loader (model ,val_loader )\n",
    "    m_val =evaluate_regression (yv ,pv )\n",
    "\n",
    "    history .append ({\n",
    "    \"epoch\":epoch ,\n",
    "    \"train_loss\":float (train_loss ),\n",
    "    \"val_loss\":float (val_loss ),\n",
    "    **m_val ,\n",
    "    \"epoch_s\":float (epoch_s ),\n",
    "    })\n",
    "\n",
    "    print (f\"Epoch {epoch}/{EPOCHS} | train_loss={train_loss:.4f} | val_mae={m_val['mae']:.4f} val_rmse={m_val['rmse']:.4f} val_spearman={m_val['spearman']:.4f} | epoch_s={epoch_s:.1f}s\")\n",
    "\n",
    "    if m_val [\"mae\"]<best_val_mae -1e-6 :\n",
    "        best_val_mae =m_val [\"mae\"]\n",
    "        best_state ={k :v .detach ().cpu ().clone ()for k ,v in model .state_dict ().items ()}\n",
    "        bad_epochs =0 \n",
    "    else :\n",
    "        bad_epochs +=1 \n",
    "        if bad_epochs >PATIENCE :\n",
    "            print (\"Early stopping triggered.\")\n",
    "            break \n",
    "\n",
    "total_train_s =time .perf_counter ()-t_train0 \n",
    "hist_df =pd .DataFrame (history )\n",
    "\n",
    "model .load_state_dict (best_state )\n",
    "model .to (DEVICE )\n",
    "model .eval ()\n",
    "\n",
    "@torch .no_grad ()\n",
    "def predict_texts_e2e (model ,texts :List [str ],batch_size :int ,max_length :int )->Tuple [np .ndarray ,float ]:\n",
    "    \"\"\"\n",
    "    End-to-end: Tokenize + Forward. Gibt preds und seconds zurück.\n",
    "    \"\"\"\n",
    "    model .eval ()\n",
    "    t0 =time .perf_counter ()\n",
    "    preds_all =[]\n",
    "    for i in range (0 ,len (texts ),batch_size ):\n",
    "        batch_texts =[str (t )for t in texts [i :i +batch_size ]]\n",
    "        enc =tokenizer (\n",
    "        batch_texts ,\n",
    "        padding =True ,\n",
    "        truncation =True ,\n",
    "        max_length =max_length ,\n",
    "        return_tensors =\"pt\",\n",
    "        )\n",
    "        enc ={k :v .to (DEVICE )for k ,v in enc .items ()}\n",
    "        out =model (**enc )\n",
    "        preds =out .logits .squeeze (-1 ).detach ().cpu ().numpy ()\n",
    "        preds_all .append (preds )\n",
    "    secs =time .perf_counter ()-t0 \n",
    "    return np .concatenate (preds_all ,axis =0 ),float (secs )\n",
    "\n",
    "X_val_text =df_val [\"text\"].astype (str ).tolist ()\n",
    "y_val_true =df_val [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "X_test_text =df_test [\"text\"].astype (str ).tolist ()\n",
    "y_test_true =df_test [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "X_S_text =df_S [\"text\"].astype (str ).tolist ()\n",
    "y_S_true =df_S [\"target\"].astype (float ).to_numpy ()\n",
    "\n",
    "pred_val ,t_val =predict_texts_e2e (model ,X_val_text ,batch_size =BATCH_SIZE ,max_length =MAX_LENGTH )\n",
    "pred_test ,t_test =predict_texts_e2e (model ,X_test_text ,batch_size =BATCH_SIZE ,max_length =MAX_LENGTH )\n",
    "pred_S ,t_S =predict_texts_e2e (model ,X_S_text ,batch_size =BATCH_SIZE ,max_length =MAX_LENGTH )\n",
    "\n",
    "m_test =evaluate_regression (y_test_true ,pred_test )\n",
    "m_S =evaluate_regression (y_S_true ,pred_S )\n",
    "\n",
    "model_dir =PATHS [\"models\"]/f\"{METHOD}_{MODEL_NAME.replace('/','_')}\"\n",
    "model_dir .mkdir (parents =True ,exist_ok =True )\n",
    "model .save_pretrained (model_dir )\n",
    "tokenizer .save_pretrained (model_dir )\n",
    "\n",
    "meta_path =PATHS [\"reports\"]/f\"{METHOD}_meta.json\"\n",
    "meta ={\n",
    "\"timestamp_utc\":time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ()),\n",
    "\"method\":METHOD ,\n",
    "\"model_name\":MODEL_NAME ,\n",
    "\"device\":DEVICE ,\n",
    "\"seed\":SEED ,\n",
    "\"max_length\":int (MAX_LENGTH ),\n",
    "\"batch_size\":int (BATCH_SIZE ),\n",
    "\"epochs_ran\":int (len (history )),\n",
    "\"epochs_planned\":int (EPOCHS ),\n",
    "\"lr\":float (LR ),\n",
    "\"weight_decay\":float (WEIGHT_DECAY ),\n",
    "\"freeze_first_n_layers\":int (FREEZE_FIRST_N_LAYERS ),\n",
    "\"frozen_layers_effective\":int (frozen_layers ),\n",
    "\"total_train_s\":float (total_train_s ),\n",
    "\"val_history\":history ,\n",
    "}\n",
    "with open (meta_path ,\"w\",encoding =\"utf-8\")as f :\n",
    "    json .dump (meta ,f ,indent =2 ,ensure_ascii =False )\n",
    "\n",
    "pred_path =PATHS [\"reports\"]/f\"predictions_{METHOD}.parquet\"\n",
    "pred_df =pd .concat ([\n",
    "pd .DataFrame ({\n",
    "\"row_id\":df_val [\"row_id\"].to_numpy (),\n",
    "\"split\":\"val\",\n",
    "\"method\":METHOD ,\n",
    "\"y_true\":y_val_true ,\n",
    "\"y_pred\":pred_val ,\n",
    "}),\n",
    "pd .DataFrame ({\n",
    "\"row_id\":df_test [\"row_id\"].to_numpy (),\n",
    "\"split\":\"test\",\n",
    "\"method\":METHOD ,\n",
    "\"y_true\":y_test_true ,\n",
    "\"y_pred\":pred_test ,\n",
    "}),\n",
    "pd .DataFrame ({\n",
    "\"row_id\":df_S [\"row_id\"].to_numpy (),\n",
    "\"split\":\"S\",\n",
    "\"method\":METHOD ,\n",
    "\"y_true\":y_S_true ,\n",
    "\"y_pred\":pred_S ,\n",
    "}),\n",
    "],axis =0 ).reset_index (drop =True )\n",
    "pred_df .to_parquet (pred_path ,index =False )\n",
    "\n",
    "reliability ={\n",
    "\"parse_success_rate\":1.0 ,\n",
    "\"schema_adherence_rate\":1.0 ,\n",
    "\"out_of_range_rate\":float (np .mean ((pred_test <0 )|(pred_test >10 ))),\n",
    "\"empty_refusal_rate\":0.0 ,\n",
    "}\n",
    "coverage =1.0 \n",
    "\n",
    "results_path =PATHS [\"reports\"]/\"results.csv\"\n",
    "\n",
    "def upsert_results (existing :Optional [pd .DataFrame ],new_rows :pd .DataFrame ,key_cols :List [str ])->pd .DataFrame :\n",
    "    if existing is None or len (existing )==0 :\n",
    "        out =new_rows .copy ()\n",
    "    else :\n",
    "        out =pd .concat ([existing ,new_rows ],axis =0 ,ignore_index =True )\n",
    "        out [\"_dupkey\"]=out [key_cols ].astype (str ).agg (\"||\".join ,axis =1 )\n",
    "        out =out .drop_duplicates (subset =\"_dupkey\",keep =\"last\").drop (columns =[\"_dupkey\"])\n",
    "    return out .sort_values (key_cols ).reset_index (drop =True )\n",
    "\n",
    "timestamp_utc =time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ())\n",
    "\n",
    "new_rows =pd .DataFrame ([\n",
    "{\n",
    "\"timestamp_utc\":timestamp_utc ,\n",
    "\"method\":METHOD ,\n",
    "\"split\":\"test\",\n",
    "\"model_name\":MODEL_NAME ,\n",
    "\"max_length\":int (MAX_LENGTH ),\n",
    "\"batch_size\":int (BATCH_SIZE ),\n",
    "\"epochs\":int (len (history )),\n",
    "\"freeze_first_n_layers\":int (FREEZE_FIRST_N_LAYERS ),\n",
    "**m_test ,\n",
    "**reliability ,\n",
    "\"coverage\":coverage ,\n",
    "\"risk_mae\":m_test [\"mae\"],\n",
    "\"risk_rmse\":m_test [\"rmse\"],\n",
    "\"fit_trainval_s\":float (total_train_s ),\n",
    "\"inference_s\":float (t_test ),\n",
    "\"sec_per_100\":runtime_s_per_100 (len (df_test ),t_test ),\n",
    "\"n_samples\":int (len (df_test )),\n",
    "\"notes\":f\"hf_savedir={model_dir.name}\",\n",
    "},\n",
    "{\n",
    "\"timestamp_utc\":timestamp_utc ,\n",
    "\"method\":METHOD ,\n",
    "\"split\":\"S\",\n",
    "\"model_name\":MODEL_NAME ,\n",
    "\"max_length\":int (MAX_LENGTH ),\n",
    "\"batch_size\":int (BATCH_SIZE ),\n",
    "\"epochs\":int (len (history )),\n",
    "\"freeze_first_n_layers\":int (FREEZE_FIRST_N_LAYERS ),\n",
    "**m_S ,\n",
    "**reliability ,\n",
    "\"coverage\":coverage ,\n",
    "\"risk_mae\":m_S [\"mae\"],\n",
    "\"risk_rmse\":m_S [\"rmse\"],\n",
    "\"fit_trainval_s\":float (total_train_s ),\n",
    "\"inference_s\":float (t_S ),\n",
    "\"sec_per_100\":runtime_s_per_100 (len (df_S ),t_S ),\n",
    "\"n_samples\":int (len (df_S )),\n",
    "\"notes\":f\"hf_savedir={model_dir.name}\",\n",
    "},\n",
    "])\n",
    "\n",
    "df_exist =pd .read_csv (results_path )if results_path .exists ()else pd .DataFrame ()\n",
    "df_results =upsert_results (df_exist ,new_rows ,key_cols =[\"method\",\"split\"])\n",
    "df_results .to_csv (results_path ,index =False )\n",
    "\n",
    "plot_path =PATHS [\"figs\"]/f\"{METHOD}_pred_vs_true_test.png\"\n",
    "try :\n",
    "    import matplotlib .pyplot as plt \n",
    "    plt .figure ()\n",
    "    plt .scatter (y_test_true ,pred_test ,alpha =0.5 )\n",
    "    plt .xlabel (\"y_true\")\n",
    "    plt .ylabel (\"y_pred\")\n",
    "    plt .title (\"DistilBERT Regression: Test y_true vs y_pred\")\n",
    "    plt .tight_layout ()\n",
    "    savefig_with_runid (plot_path ,dpi =150 )\n",
    "    plt .close ()\n",
    "    plot_saved =True \n",
    "except Exception :\n",
    "    plot_saved =False \n",
    "\n",
    "pred_df_check =pd .read_parquet (pred_path )\n",
    "\n",
    "tmp =pred_df_check [pred_df_check [\"split\"]==\"test\"]\n",
    "m =evaluate_regression (tmp [\"y_true\"].to_numpy (),tmp [\"y_pred\"].to_numpy ())\n",
    "\n",
    "df_res =pd .read_csv (results_path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291452c-78f1-4faa-a67c-45dfe162469a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "OLLAMA_BASE_URL =CONFIG .get (\"ollama_base_url\",\"http://localhost:11434\")\n",
    "OLLAMA_MODEL =CONFIG .get (\"ollama_model\",\"phi3:mini\")\n",
    "\n",
    "def ollama_tags (base_url :str )->Dict [str ,Any ]:\n",
    "    r =requests .get (f\"{base_url}/api/tags\",timeout =3 )\n",
    "    r .raise_for_status ()\n",
    "    return r .json ()\n",
    "\n",
    "try :\n",
    "    tags =ollama_tags (OLLAMA_BASE_URL )\n",
    "    models =[m .get (\"name\")for m in tags .get (\"models\",[])]\n",
    "    print (\"Ollama reachable:\",OLLAMA_BASE_URL )\n",
    "    print (\"Models (first 20):\",models [:20 ])\n",
    "    print (\"Model available:\",OLLAMA_MODEL )\n",
    "except Exception as e :\n",
    "    print (\"Ollama hard check failed:\",repr (e ))\n",
    "    raise RuntimeError (\n",
    "    \"Ollama ist nicht erreichbar oder phi3:mini ist nicht installiert.\\n\"\n",
    "    \"Bitte starte Ollama lokal und installiere das Modell (siehe Terminal-Commands unterhalb dieses Schritts),\\n\"\n",
    "    \"dann Zelle erneut ausführen.\"\n",
    "    )\n",
    "\n",
    "import hashlib \n",
    "\n",
    "CACHE_PATH =PATHS [\"reports\"]/f\"llm_cache_{RUN_ID}.jsonl\"\n",
    "CACHE_PATH_LATEST =PATHS [\"reports\"]/\"llm_cache.jsonl\"\n",
    "CACHE_PATH .parent .mkdir (parents =True ,exist_ok =True )\n",
    "\n",
    "MODES =[\"M1_FREE\",\"M2_JSON_PROMPT\",\"M3_SCHEMA_PROMPT\",\"M3_SCHEMA_ENFORCED\",\"M4_REPAIR\"]\n",
    "\n",
    "SCHEMA_OBJ ={\n",
    "\"type\":\"object\",\n",
    "\"properties\":{\"rating\":{\"type\":\"integer\",\"minimum\":1 ,\"maximum\":10 }},\n",
    "\"required\":[\"rating\"],\n",
    "\"additionalProperties\":False ,\n",
    "}\n",
    "\n",
    "try :\n",
    "    import jsonschema \n",
    "except Exception as e :\n",
    "    raise ImportError (\n",
    "    \"Package 'jsonschema' fehlt (wird für M3_SCHEMA/M4_REPAIR benötigt).\\n\"\n",
    "    \"Installiere lokal (Terminal):\\n\"\n",
    "    \"  pip install jsonschema\\n\"\n",
    "    f\"Original error: {e}\"\n",
    "    )\n",
    "\n",
    "def prompt_hash (s :str )->str :\n",
    "    return hashlib .sha256 (s .encode (\"utf-8\")).hexdigest ()[:12 ]\n",
    "\n",
    "PROMPT_PROFILE ={\"max_chars\":4000 ,\"tail_chars\":500 ,\"marker\":\"\\n...\\n\"}\n",
    "\n",
    "def set_prompt_profile (max_chars :int =4000 ,tail_chars :int =500 ,marker :str =\"\\n...\\n\")->None :\n",
    "    \"\"\"Central, sweep-friendly prompt truncation profile.\"\"\"\n",
    "    global PROMPT_PROFILE \n",
    "    PROMPT_PROFILE ={\"max_chars\":int (max_chars ),\"tail_chars\":int (tail_chars ),\"marker\":str (marker )}\n",
    "\n",
    "def truncate_text (\n",
    "text :str ,\n",
    "max_chars :Optional [int ]=None ,\n",
    "tail_chars :Optional [int ]=None ,\n",
    "marker :Optional [str ]=None ,\n",
    ")->Tuple [str ,bool ]:\n",
    "    \"\"\"\n",
    "    Deterministic head+tail truncation that GUARANTEES len(out) <= max_chars,\n",
    "    counting head + marker + tail inside the budget (fixes >max_chars bug).\n",
    "    \"\"\"\n",
    "    t =str (text or \"\")\n",
    "    max_c =int (PROMPT_PROFILE [\"max_chars\"]if max_chars is None else max_chars )\n",
    "    tail_c =int (PROMPT_PROFILE [\"tail_chars\"]if tail_chars is None else tail_chars )\n",
    "    mark =PROMPT_PROFILE [\"marker\"]if marker is None else str (marker )\n",
    "\n",
    "    if max_c <=0 :\n",
    "        return (\"\",bool (t ))\n",
    "    if len (t )<=max_c :\n",
    "        return (t ,False )\n",
    "\n",
    "    tail_c =max (0 ,min (tail_c ,max_c ))\n",
    "    head_c =max (0 ,max_c -tail_c -len (mark ))\n",
    "\n",
    "    if head_c ==0 :\n",
    "        if tail_c >0 and (len (mark )+tail_c )<=max_c :\n",
    "            out =mark +t [-tail_c :]\n",
    "        else :\n",
    "            out =t [-max_c :]\n",
    "        return (out [:max_c ],True )\n",
    "\n",
    "    if tail_c >0 :\n",
    "        out =t [:head_c ]+mark +t [-tail_c :]\n",
    "    else :\n",
    "        out =t [:max_c ]\n",
    "\n",
    "    return (out [:max_c ],True )\n",
    "\n",
    "set_prompt_profile (max_chars =4000 ,tail_chars =500 ,marker =\"\\n...\\n\")\n",
    "\n",
    "def make_prompt (mode :str ,review_text :str )->str :\n",
    "    review_text ,_ =truncate_text (review_text )\n",
    "\n",
    "    if mode ==\"M1_FREE\":\n",
    "        return (\n",
    "        \"You are a strict regressor.\\n\"\n",
    "        \"Task: Predict the overall airline review rating as an INTEGER from 1 to 10.\\n\"\n",
    "        \"Output format: ONLY the number (e.g., 7) OR 'Rating: 7'. No other text.\\n\\n\"\n",
    "        f\"REVIEW:\\n{review_text}\\n\"\n",
    "        )\n",
    "\n",
    "    if mode ==\"M2_JSON_PROMPT\":\n",
    "        return (\n",
    "        \"You are a strict regressor.\\n\"\n",
    "        \"Task: Predict the overall airline review rating as an INTEGER from 1 to 10.\\n\"\n",
    "        \"Output format: ONLY valid JSON exactly like: {\\\"rating\\\": 7}\\n\"\n",
    "        \"No extra keys, no commentary, no code fences.\\n\\n\"\n",
    "        f\"REVIEW:\\n{review_text}\\n\"\n",
    "        )\n",
    "\n",
    "    if mode ==\"M3_SCHEMA_PROMPT\":\n",
    "        schema_str =json .dumps (SCHEMA_OBJ ,ensure_ascii =False )\n",
    "        return (\n",
    "        \"You are a strict regressor.\\n\"\n",
    "        \"Task: Predict the overall airline review rating as an INTEGER from 1 to 10.\\n\"\n",
    "        \"You MUST output ONLY JSON that validates against this JSON Schema:\\n\"\n",
    "        f\"{schema_str}\\n\"\n",
    "        \"No extra keys, no commentary, no code fences.\\n\\n\"\n",
    "        f\"REVIEW:\\n{review_text}\\n\"\n",
    "        )\n",
    "\n",
    "    if mode ==\"M3_SCHEMA_ENFORCED\":\n",
    "        return (\n",
    "        \"You are a strict regressor.\\n\"\n",
    "        \"Task: Predict the overall airline review rating as an INTEGER from 1 to 10.\\n\"\n",
    "        \"Return ONLY JSON with key 'rating' as integer 1..10. No extra keys, no commentary, no code fences.\\n\\n\"\n",
    "        f\"REVIEW:\\n{review_text}\\n\"\n",
    "        )\n",
    "\n",
    "    if mode ==\"M4_REPAIR\":\n",
    "        return (\n",
    "        \"You are a strict regressor.\\n\"\n",
    "        \"Task: Predict the overall airline review rating as an INTEGER from 1 to 10.\\n\"\n",
    "        \"Output format: ONLY valid JSON exactly like: {\\\"rating\\\": 7}\\n\"\n",
    "        \"No extra keys, no commentary, no code fences.\\n\\n\"\n",
    "        f\"REVIEW:\\n{review_text}\\n\"\n",
    "        )\n",
    "\n",
    "    raise ValueError (f\"Unknown mode: {mode}\")\n",
    "def is_refusal (text :str )->bool :\n",
    "    t =(text or \"\").strip ().lower ()\n",
    "    if not t :\n",
    "        return False \n",
    "\n",
    "    hard =[\n",
    "    \"i can't\",\"i cannot\",\"cannot\",\"can't\",\n",
    "    \"i’m sorry\",\"i am sorry\",\"sorry\",\n",
    "    \"unable to\",\"not able to\",\n",
    "    \"can't help\",\"cannot help\",\n",
    "    \"won't comply\",\"i won't\",\n",
    "    ]\n",
    "    if any (p in t for p in hard ):\n",
    "        return True \n",
    "\n",
    "    if \"as an ai\"in t or \"as a language model\"in t :\n",
    "        soft =[\"cannot\",\"can't\",\"unable\",\"not able\",\"won't\",\"sorry\"]\n",
    "        return any (p in t for p in soft )\n",
    "\n",
    "    return False \n",
    "\n",
    "def parse_m1_free (raw :str )->Tuple [Optional [int ],Optional [str ]]:\n",
    "    t =(raw or \"\").strip ()\n",
    "    if t ==\"\":\n",
    "        return None ,\"empty\"\n",
    "\n",
    "    m =re .search (r\"\\brating\\s*:\\s*(\\d+)\\b\",t ,flags =re .IGNORECASE )\n",
    "    candidates_int =[]\n",
    "    candidates_float =[]\n",
    "\n",
    "    if m :\n",
    "        candidates_int .append (m .group (1 ))\n",
    "\n",
    "    nums =re .findall (r\"(-?\\d+(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)\",t )\n",
    "    for s in nums :\n",
    "        if any (ch in s for ch in [\".\",\"e\",\"E\"]):\n",
    "            candidates_float .append (s )\n",
    "        else :\n",
    "            candidates_int .append (s )\n",
    "\n",
    "    for s in candidates_int :\n",
    "        try :\n",
    "            xi =int (s )\n",
    "        except Exception :\n",
    "            continue \n",
    "        if 1 <=xi <=10 :\n",
    "            return xi ,None \n",
    "\n",
    "    for s in candidates_float :\n",
    "        try :\n",
    "            x =float (s )\n",
    "        except Exception :\n",
    "            continue \n",
    "        if 1.0 <=x <=10.0 :\n",
    "            return None ,\"type\"\n",
    "\n",
    "    if is_refusal (t ):\n",
    "        return None ,\"refusal\"\n",
    "\n",
    "    if len (candidates_int )>0 :\n",
    "        return None ,\"out_of_range\"\n",
    "\n",
    "    return None ,\"parse_fail\"\n",
    "\n",
    "CODEFENCE_RE =re .compile (r\"^\\s*```(?:json)?\\s*([\\s\\S]*?)\\s*```\\s*$\",re .IGNORECASE )\n",
    "\n",
    "def strip_code_fences (text :str )->str :\n",
    "    t =(text or \"\").strip ()\n",
    "    m =CODEFENCE_RE .match (t )\n",
    "    if m :\n",
    "        return (m .group (1 )or \"\").strip ()\n",
    "    return t \n",
    "\n",
    "def extract_first_json_object (text :str )->Optional [str ]:\n",
    "    \"\"\"\n",
    "    Extract first top-level JSON object {...} from text using balanced braces.\n",
    "    Handles braces inside JSON strings correctly.\n",
    "    Returns substring or None.\n",
    "    \"\"\"\n",
    "    t =(text or \"\")\n",
    "    start =t .find (\"{\")\n",
    "    if start <0 :\n",
    "        return None \n",
    "\n",
    "    depth =0 \n",
    "    in_str =False \n",
    "    esc =False \n",
    "\n",
    "    for i in range (start ,len (t )):\n",
    "        ch =t [i ]\n",
    "\n",
    "        if in_str :\n",
    "            if esc :\n",
    "                esc =False \n",
    "            elif ch ==\"\\\\\":\n",
    "                esc =True \n",
    "            elif ch =='\"':\n",
    "                in_str =False \n",
    "            continue \n",
    "\n",
    "        if ch =='\"':\n",
    "            in_str =True \n",
    "            continue \n",
    "\n",
    "        if ch ==\"{\":\n",
    "            depth +=1 \n",
    "        elif ch ==\"}\":\n",
    "            depth -=1 \n",
    "            if depth ==0 :\n",
    "                return t [start :i +1 ]\n",
    "\n",
    "    return None \n",
    "\n",
    "def preprocess_relaxed_json (raw :str )->str :\n",
    "    \"\"\"\n",
    "    Relaxed preprocessing:\n",
    "    - strip code fences\n",
    "    - extract first JSON object if extra text exists\n",
    "    \"\"\"\n",
    "    t =strip_code_fences (raw )\n",
    "    if t .startswith (\"{\")and t .endswith (\"}\"):\n",
    "        return t \n",
    "    sub =extract_first_json_object (t )\n",
    "    return (sub or t ).strip ()\n",
    "\n",
    "def _coerce_rating_to_int (rating :Any )->Optional [int ]:\n",
    "    if isinstance (rating ,bool ):\n",
    "        return None \n",
    "    if isinstance (rating ,int ):\n",
    "        return rating \n",
    "    if isinstance (rating ,float ):\n",
    "        if abs (rating -round (rating ))<1e-9 :\n",
    "            return int (round (rating ))\n",
    "        return None \n",
    "    return None \n",
    "\n",
    "def parse_json_rating_strict (raw :str )->Tuple [Optional [int ],Optional [str ],Optional [Dict [str ,Any ]]]:\n",
    "    \"\"\"\n",
    "    Strict: raw must be valid JSON object (no fences, no extra text).\n",
    "    \"\"\"\n",
    "    t =(raw or \"\").strip ()\n",
    "    if t ==\"\":\n",
    "        return None ,\"empty\",None \n",
    "    if is_refusal (t ):\n",
    "        return None ,\"refusal\",None \n",
    "\n",
    "    try :\n",
    "        obj =json .loads (t )\n",
    "    except Exception :\n",
    "        return None ,\"json_decode\",None \n",
    "\n",
    "    if not isinstance (obj ,dict ):\n",
    "        return None ,\"type\",obj \n",
    "    if \"rating\"not in obj :\n",
    "        return None ,\"missing_key\",obj \n",
    "\n",
    "    ri =_coerce_rating_to_int (obj .get (\"rating\"))\n",
    "    if ri is None :\n",
    "        return None ,\"type\",obj \n",
    "    if not (1 <=ri <=10 ):\n",
    "        return None ,\"out_of_range\",obj \n",
    "\n",
    "    return int (ri ),None ,obj \n",
    "\n",
    "def parse_json_rating_relaxed (raw :str )->Tuple [Optional [int ],Optional [str ],Optional [Dict [str ,Any ]]]:\n",
    "    \"\"\"\n",
    "    Relaxed: allow code fences and extra text; extract first JSON object.\n",
    "    \"\"\"\n",
    "    t0 =(raw or \"\").strip ()\n",
    "    if t0 ==\"\":\n",
    "        return None ,\"empty\",None \n",
    "    if is_refusal (t0 ):\n",
    "        return None ,\"refusal\",None \n",
    "\n",
    "    t =preprocess_relaxed_json (t0 )\n",
    "    try :\n",
    "        obj =json .loads (t )\n",
    "    except Exception :\n",
    "        return None ,\"json_decode\",None \n",
    "\n",
    "    if not isinstance (obj ,dict ):\n",
    "        return None ,\"type\",obj \n",
    "    if \"rating\"not in obj :\n",
    "        return None ,\"missing_key\",obj \n",
    "\n",
    "    ri =_coerce_rating_to_int (obj .get (\"rating\"))\n",
    "    if ri is None :\n",
    "        return None ,\"type\",obj \n",
    "    if not (1 <=ri <=10 ):\n",
    "        return None ,\"out_of_range\",obj \n",
    "\n",
    "    return int (ri ),None ,obj \n",
    "\n",
    "def parse_json_rating (raw :str ,*,relaxed :bool =False )->Tuple [Optional [int ],Optional [str ],Optional [Dict [str ,Any ]]]:\n",
    "    return parse_json_rating_relaxed (raw )if relaxed else parse_json_rating_strict (raw )\n",
    "\n",
    "def validate_schema (obj :Dict [str ,Any ])->Optional [str ]:\n",
    "    try :\n",
    "        jsonschema .validate (instance =obj ,schema =SCHEMA_OBJ )\n",
    "        return None \n",
    "    except jsonschema .ValidationError as e :\n",
    "        msg =str (e ).lower ()\n",
    "        if \"minimum\"in msg or \"maximum\"in msg :\n",
    "            return \"out_of_range\"\n",
    "        return \"schema\"\n",
    "    except Exception :\n",
    "        return \"schema\"\n",
    "\n",
    "def ollama_generate (prompt :str ,model :str ,base_url :str ,temperature :float =0.0 ,timeout_s :int =120 )->str :\n",
    "    \"\"\"DEPRECATED (Patch 6.3a+): Use the streaming + format-capable ollama_generate defined in SCHRITT 6.3a.\"\"\"\n",
    "    raise RuntimeError (\"Deprecated: run SCHRITT 6.3a and use the patched streaming ollama_generate (supports format/stream/retry).\")\n",
    "\n",
    "def load_cache_index (path :Path )->Dict [Tuple [int ,str ],Dict [str ,Any ]]:\n",
    "    idx :Dict [Tuple [int ,str ],Dict [str ,Any ]]={}\n",
    "    if not path .exists ():\n",
    "        return idx \n",
    "    with open (path ,\"r\",encoding =\"utf-8\")as f :\n",
    "        for line in f :\n",
    "            line =line .strip ()\n",
    "            if not line :\n",
    "                continue \n",
    "            try :\n",
    "                rec =json .loads (line )\n",
    "                key =(int (rec [\"row_id\"]),str (rec [\"mode\"]))\n",
    "                idx [key ]=rec \n",
    "            except Exception :\n",
    "                continue \n",
    "    return idx \n",
    "\n",
    "def append_cache (path :Path ,rec :Dict [str ,Any ])->None :\n",
    "    \"\"\"Append cache record, but avoid logging an identical record twice.\"\"\"\n",
    "    key =(int (rec .get (\"row_id\")),str (rec .get (\"mode\")))\n",
    "    prev =cache_index .get (key )\n",
    "    if prev is not None :\n",
    "        same =(\n",
    "        prev .get (\"model\")==rec .get (\"model\")and \n",
    "        prev .get (\"prompt_hash\")==rec .get (\"prompt_hash\")and \n",
    "        prev .get (\"format_kind\")==rec .get (\"format_kind\")and \n",
    "        prev .get (\"format_fp\")==rec .get (\"format_fp\")and \n",
    "        prev .get (\"raw_output\")==rec .get (\"raw_output\")and \n",
    "        prev .get (\"error_type\")==rec .get (\"error_type\")\n",
    "        )\n",
    "        if same :\n",
    "            return \n",
    "    with open (path ,\"a\",encoding =\"utf-8\")as f :\n",
    "        f .write (json .dumps (rec ,ensure_ascii =False )+\"\\n\")\n",
    "\n",
    "cache_index =load_cache_index (CACHE_PATH )\n",
    "\n",
    "import requests \n",
    "from requests .exceptions import ReadTimeout ,ConnectionError \n",
    "\n",
    "OLLAMA_CONNECT_TIMEOUT_S =5 \n",
    "OLLAMA_READ_TIMEOUT_S =900 \n",
    "OLLAMA_NUM_PREDICT =32 \n",
    "OLLAMA_NUM_CTX =2048 \n",
    "\n",
    "PROMPT_MAX_CHARS =1800 \n",
    "PROMPT_TAIL_CHARS =350 \n",
    "\n",
    "set_prompt_profile (max_chars =PROMPT_MAX_CHARS ,tail_chars =PROMPT_TAIL_CHARS ,marker =\"\\n...\\n\")\n",
    "\n",
    "USE_OLLAMA_FORMAT =True \n",
    "\n",
    "M4_REPAIR_PROMPT_VERSION =\"patch4_review_context_v1\"\n",
    "\n",
    "def mode_to_format (mode :str ):\n",
    "    \"\"\"Return Ollama 'format' spec for this mode.\n",
    "    Prompt-only modes MUST return None to allow invalid outputs (for RQ1/M4).\n",
    "    Enforced mode uses SCHEMA_OBJ when USE_OLLAMA_FORMAT is True.\n",
    "    \"\"\"\n",
    "    if not USE_OLLAMA_FORMAT :\n",
    "        return None \n",
    "    if mode ==\"M3_SCHEMA_ENFORCED\":\n",
    "        return SCHEMA_OBJ \n",
    "    return None \n",
    "\n",
    "def format_fingerprint (fmt )->tuple [str ,str ]:\n",
    "    \"\"\"\n",
    "    Returns (kind, fp) to version cache.\n",
    "    kind in {'none','json','schema'}; fp is stable string.\n",
    "    \"\"\"\n",
    "    if fmt is None :\n",
    "        return (\"none\",\"\")\n",
    "    if fmt ==\"json\":\n",
    "        return (\"json\",\"json\")\n",
    "    try :\n",
    "        s =json .dumps (fmt ,sort_keys =True )\n",
    "    except Exception :\n",
    "        s =str (fmt )\n",
    "    return (\"schema\",hashlib .sha256 (s .encode (\"utf-8\")).hexdigest ()[:12 ])\n",
    "\n",
    "def ollama_generate_stream (\n",
    "prompt :str ,\n",
    "model :str ,\n",
    "base_url :str ,\n",
    "temperature :float =0.0 ,\n",
    "timeout_connect_s :int =OLLAMA_CONNECT_TIMEOUT_S ,\n",
    "timeout_read_s :int =OLLAMA_READ_TIMEOUT_S ,\n",
    "num_predict :int =OLLAMA_NUM_PREDICT ,\n",
    "num_ctx :int =OLLAMA_NUM_CTX ,\n",
    "stop :Optional [List [str ]]=None ,\n",
    "fmt =None ,\n",
    ")->str :\n",
    "    \"\"\"\n",
    "    Streaming call: sammelt 'response' aus JSONL-chunks bis done=True.\n",
    "    Zusätzlich: optional 'format' für strukturierte Outputs.\n",
    "    \"\"\"\n",
    "    payload ={\n",
    "    \"model\":model ,\n",
    "    \"prompt\":prompt ,\n",
    "    \"stream\":True ,\n",
    "    \"options\":{\n",
    "    \"temperature\":float (temperature ),\n",
    "    \"num_predict\":int (num_predict ),\n",
    "    \"num_ctx\":int (num_ctx ),\n",
    "    }\n",
    "    }\n",
    "    if stop :\n",
    "        payload [\"options\"][\"stop\"]=stop \n",
    "    if fmt is not None :\n",
    "        payload [\"format\"]=fmt \n",
    "\n",
    "    r =requests .post (\n",
    "    f\"{base_url}/api/generate\",\n",
    "    json =payload ,\n",
    "    stream =True ,\n",
    "    timeout =(timeout_connect_s ,timeout_read_s ),\n",
    "    )\n",
    "    r .raise_for_status ()\n",
    "\n",
    "    out =[]\n",
    "    for line in r .iter_lines (decode_unicode =True ):\n",
    "        if not line :\n",
    "            continue \n",
    "        try :\n",
    "            j =json .loads (line )\n",
    "        except Exception :\n",
    "            continue \n",
    "        out .append (j .get (\"response\",\"\"))\n",
    "        if j .get (\"done\",False ):\n",
    "            break \n",
    "    return \"\".join (out )\n",
    "\n",
    "def ollama_generate (prompt :str ,model :str ,base_url :str ,temperature :float =0.0 ,timeout_s :int =120 ,fmt =None )->str :\n",
    "    \"\"\"Wrapper: nutzt STREAM-Implementierung; fmt wird durchgereicht.\"\"\"\n",
    "    return ollama_generate_stream (\n",
    "    prompt =prompt ,\n",
    "    model =model ,\n",
    "    base_url =base_url ,\n",
    "    temperature =temperature ,\n",
    "    timeout_connect_s =OLLAMA_CONNECT_TIMEOUT_S ,\n",
    "    timeout_read_s =max (timeout_s ,300 ),\n",
    "    num_predict =OLLAMA_NUM_PREDICT ,\n",
    "    num_ctx =OLLAMA_NUM_CTX ,\n",
    "    stop =None ,\n",
    "    fmt =fmt ,\n",
    "    )\n",
    "\n",
    "def ollama_generate_with_transport_retry (\n",
    "prompt :str ,\n",
    "*,\n",
    "model :str ,\n",
    "base_url :str ,\n",
    "temperature :float =0.0 ,\n",
    "fmt =None ,\n",
    ")->Tuple [str ,Optional [str ]]:\n",
    "    try :\n",
    "        return (\n",
    "        ollama_generate (prompt ,model =model ,base_url =base_url ,temperature =temperature ,timeout_s =OLLAMA_READ_TIMEOUT_S ,fmt =fmt ),\n",
    "        None \n",
    "        )\n",
    "    except (ReadTimeout ,ConnectionError )as e :\n",
    "        shorter ,_ =truncate_text (prompt ,max_chars =1200 )\n",
    "        try :\n",
    "            return (\n",
    "            ollama_generate_stream (\n",
    "            prompt =shorter ,\n",
    "            model =model ,\n",
    "            base_url =base_url ,\n",
    "            temperature =temperature ,\n",
    "            timeout_connect_s =OLLAMA_CONNECT_TIMEOUT_S ,\n",
    "            timeout_read_s =1200 ,\n",
    "            num_predict =OLLAMA_NUM_PREDICT ,\n",
    "            num_ctx =OLLAMA_NUM_CTX ,\n",
    "            fmt =fmt ,\n",
    "            ),\n",
    "            \"transport_retry\"\n",
    "            )\n",
    "        except Exception as e2 :\n",
    "            return \"\",f\"transport_timeout:{type(e2).__name__}\"\n",
    "\n",
    "warmup_prompt ='Return ONLY JSON exactly like: {\"rating\": 7}'\n",
    "\n",
    "warmup_fmt =mode_to_format (\"M3_SCHEMA_ENFORCED\")\n",
    "\n",
    "t0 =time .perf_counter ()\n",
    "resp ,retry_flag =ollama_generate_with_transport_retry (\n",
    "warmup_prompt ,\n",
    "model =OLLAMA_MODEL ,\n",
    "base_url =OLLAMA_BASE_URL ,\n",
    "temperature =0.0 ,\n",
    "fmt =warmup_fmt ,\n",
    ")\n",
    "dt =time .perf_counter ()-t0 \n",
    "\n",
    "pr ,err ,obj =parse_json_rating (resp ,relaxed =False )\n",
    "\n",
    "if warmup_fmt not in (None ,\"json\"):\n",
    "    sch_err =validate_schema (obj )\n",
    "\n",
    "CHUNK_SIZE =25 \n",
    "RETRY_TIMEOUT_RECORDS =True \n",
    "\n",
    "def should_skip_cached (rec :Dict [str ,Any ])->bool :\n",
    "    if rec .get (\"parsed_rating\",None )is not None :\n",
    "        return True \n",
    "    err =rec .get (\"error_type\")\n",
    "    if err is None :\n",
    "        return True \n",
    "    if err .startswith (\"transport_timeout\")or err ==\"timeout\":\n",
    "        return not RETRY_TIMEOUT_RECORDS \n",
    "    return True \n",
    "\n",
    "def cache_hit_ok (rec :Dict [str ,Any ],*,model :str ,prompt_hash :str ,fmt_kind :str ,fmt_fp :str )->bool :\n",
    "    \"\"\"\n",
    "    True, wenn Cache-Record genau zu aktueller Konfiguration passt.\n",
    "    Alte Records ohne format_* gelten als 'none' und matchen nur, wenn wir aktuell auch 'none' haben.\n",
    "    \"\"\"\n",
    "    if rec .get (\"model\")!=model :\n",
    "        return False \n",
    "    if rec .get (\"prompt_hash\")!=prompt_hash :\n",
    "        return False \n",
    "\n",
    "    if rec .get (\"format_kind\",\"none\")!=fmt_kind :\n",
    "        return False \n",
    "    if rec .get (\"format_fp\",\"\")!=fmt_fp :\n",
    "        return False \n",
    "\n",
    "    err =rec .get (\"error_type\")\n",
    "    if err and (str (err ).startswith (\"transport_timeout\")or err in (\"timeout\",\"transport_timeout\")):\n",
    "        return not RETRY_TIMEOUT_RECORDS \n",
    "\n",
    "    return True \n",
    "\n",
    "def parse_dual_for_mode (raw :str ,*,mode :str )->Dict [str ,Any ]:\n",
    "    \"\"\"\n",
    "    mode in {\"M2_JSON_PROMPT\",\"M3_SCHEMA_PROMPT\",\"M3_SCHEMA_ENFORCED\",\"M4_REPAIR\"}.\n",
    "    Returns strict+relaxed fields + valid flags.\n",
    "    Primary (paper) is STRICT; relaxed is recoverability.\n",
    "    \"\"\"\n",
    "\n",
    "    pr_s ,er_s ,obj_s =parse_json_rating_strict (raw )\n",
    "\n",
    "    schema_ok_s =None \n",
    "    if er_s is None :\n",
    "        if mode ==\"M2_JSON_PROMPT\":\n",
    "            schema_ok_s =True \n",
    "        else :\n",
    "            sch_err =validate_schema (obj_s )\n",
    "            if sch_err is None :\n",
    "                schema_ok_s =True \n",
    "            else :\n",
    "                pr_s =None \n",
    "                er_s =sch_err \n",
    "                schema_ok_s =False \n",
    "    else :\n",
    "        schema_ok_s =None \n",
    "\n",
    "    valid_s =(er_s is None )\n",
    "\n",
    "    pr_r ,er_r ,obj_r =parse_json_rating_relaxed (raw )\n",
    "\n",
    "    schema_ok_r =None \n",
    "    if er_r is None :\n",
    "        if mode ==\"M2_JSON_PROMPT\":\n",
    "            schema_ok_r =True \n",
    "        else :\n",
    "            sch_err2 =validate_schema (obj_r )\n",
    "            if sch_err2 is None :\n",
    "                schema_ok_r =True \n",
    "            else :\n",
    "                pr_r =None \n",
    "                er_r =sch_err2 \n",
    "                schema_ok_r =False \n",
    "    else :\n",
    "        schema_ok_r =None \n",
    "\n",
    "    valid_r =(er_r is None )\n",
    "\n",
    "    return {\n",
    "    \"parsed_rating_strict\":pr_s if valid_s else None ,\n",
    "    \"error_type_strict\":None if valid_s else er_s ,\n",
    "    \"schema_ok_strict\":bool (schema_ok_s )if schema_ok_s is not None else None ,\n",
    "    \"valid_strict\":bool (valid_s ),\n",
    "\n",
    "    \"parsed_rating_relaxed\":pr_r if valid_r else None ,\n",
    "    \"error_type_relaxed\":None if valid_r else er_r ,\n",
    "    \"schema_ok_relaxed\":bool (schema_ok_r )if schema_ok_r is not None else None ,\n",
    "    \"valid_relaxed\":bool (valid_r ),\n",
    "    }\n",
    "\n",
    "def run_one (row_id :int ,text :str ,mode :str )->Dict [str ,Any ]:\n",
    "    t0 =time .perf_counter ()\n",
    "\n",
    "    base_prompt =make_prompt (mode if mode !=\"M4_REPAIR\"else \"M4_REPAIR\",text )\n",
    "    hash_in =base_prompt \n",
    "    if mode ==\"M4_REPAIR\":\n",
    "        hash_in =base_prompt +\"\\n__repair_prompt_version__:\"+M4_REPAIR_PROMPT_VERSION \n",
    "    p_hash =prompt_hash (hash_in )\n",
    "    fmt =mode_to_format (mode )\n",
    "    fmt_kind ,fmt_fp =format_fingerprint (fmt )\n",
    "\n",
    "    key =(int (row_id ),str (mode ))\n",
    "    if key in cache_index and cache_hit_ok (cache_index [key ],model =OLLAMA_MODEL ,prompt_hash =p_hash ,fmt_kind =fmt_kind ,fmt_fp =fmt_fp ):\n",
    "        rec =cache_index [key ].copy ()\n",
    "        rec [\"from_cache\"]=True \n",
    "\n",
    "        rec [\"runtime_ms_effective\"]=0 \n",
    "        rec [\"runtime_ms_cached\"]=rec .get (\"runtime_ms\")\n",
    "\n",
    "        if mode in (\"M2_JSON_PROMPT\",\"M3_SCHEMA_PROMPT\",\"M3_SCHEMA_ENFORCED\",\"M4_REPAIR\")and (\"parsed_rating_strict\"not in rec or \"valid_strict\"not in rec ):\n",
    "            dual =parse_dual_for_mode (rec .get (\"raw_output\",\"\"),mode =mode )\n",
    "            rec .update (dual )\n",
    "\n",
    "            rec [\"parsed_rating\"]=rec .get (\"parsed_rating_strict\")\n",
    "            rec [\"error_type\"]=rec .get (\"error_type_strict\")\n",
    "            rec [\"schema_ok\"]=rec .get (\"schema_ok_strict\")\n",
    "\n",
    "        return rec \n",
    "\n",
    "    t0 =time .perf_counter ()\n",
    "\n",
    "    base_prompt =make_prompt (mode if mode !=\"M4_REPAIR\"else \"M4_REPAIR\",text )\n",
    "    hash_in =base_prompt \n",
    "    if mode ==\"M4_REPAIR\":\n",
    "        hash_in =base_prompt +\"\\n__repair_prompt_version__:\"+M4_REPAIR_PROMPT_VERSION \n",
    "    p_hash =prompt_hash (hash_in )\n",
    "    raw1 ,transport_err =ollama_generate_with_transport_retry (\n",
    "    base_prompt ,\n",
    "    model =OLLAMA_MODEL ,\n",
    "    base_url =OLLAMA_BASE_URL ,\n",
    "    temperature =0.0 ,\n",
    "    fmt =fmt ,\n",
    "    )\n",
    "\n",
    "    raw1s =(raw1 or \"\").strip ()\n",
    "\n",
    "    parsed =None \n",
    "    error_type =None \n",
    "    schema_ok =None \n",
    "    repaired =False \n",
    "    raw_final =raw1s \n",
    "    raw_repair =None \n",
    "    raw_first =raw1s \n",
    "\n",
    "    dual_first_pref ={}\n",
    "    dual_final =None \n",
    "    if transport_err is not None and raw1s ==\"\":\n",
    "        error_type =transport_err \n",
    "        runtime_ms =int ((time .perf_counter ()-t0 )*1000 )\n",
    "        rec ={\n",
    "        \"timestamp_utc\":time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ()),\n",
    "        \"row_id\":int (row_id ),\n",
    "        \"mode\":mode ,\n",
    "        \"model\":OLLAMA_MODEL ,\n",
    "        \"temperature\":0.0 ,\n",
    "        \"prompt_hash\":p_hash ,\n",
    "        \"raw_output\":\"\",\n",
    "        \"raw_output_first\":None ,\n",
    "        \"raw_output_repair\":None ,\n",
    "        \"parsed_rating\":None ,\n",
    "        \"error_type\":error_type ,\n",
    "        \"schema_ok\":None ,\n",
    "        \"runtime_ms\":runtime_ms ,\n",
    "        \"repaired\":False ,\n",
    "        \"from_cache\":False ,\n",
    "        \"format_kind\":fmt_kind ,\n",
    "        \"format_fp\":fmt_fp ,\n",
    "        \"runtime_ms_effective\":runtime_ms ,\n",
    "        \"runtime_ms_cached\":None ,\n",
    "        }\n",
    "        append_cache (CACHE_PATH ,rec )\n",
    "        cache_index [(int (row_id ),mode )]=rec \n",
    "        return rec \n",
    "\n",
    "    if mode ==\"M1_FREE\":\n",
    "        parsed ,error_type =parse_m1_free (raw1s )\n",
    "        schema_ok =None \n",
    "\n",
    "    elif mode ==\"M2_JSON_PROMPT\":\n",
    "        dual =parse_dual_for_mode (raw1s ,mode =mode )\n",
    "        parsed =dual [\"parsed_rating_strict\"]\n",
    "        error_type =dual [\"error_type_strict\"]\n",
    "        schema_ok =dual [\"schema_ok_strict\"]\n",
    "\n",
    "    elif mode in (\"M3_SCHEMA_PROMPT\",\"M3_SCHEMA_ENFORCED\"):\n",
    "        dual =parse_dual_for_mode (raw1s ,mode =mode )\n",
    "\n",
    "        parsed =dual [\"parsed_rating_strict\"]\n",
    "        error_type =dual [\"error_type_strict\"]\n",
    "        schema_ok =dual [\"schema_ok_strict\"]\n",
    "\n",
    "    elif mode ==\"M4_REPAIR\":\n",
    "        dual_first =parse_dual_for_mode (raw1s ,mode =mode )\n",
    "\n",
    "        dual_first_pref ={f\"{k}_first\":v for k ,v in dual_first .items ()}\n",
    "        dual_final =dual_first \n",
    "        parsed =dual_first [\"parsed_rating_strict\"]\n",
    "        error_type =dual_first [\"error_type_strict\"]\n",
    "        schema_ok =dual_first [\"schema_ok_strict\"]\n",
    "\n",
    "        if not dual_first [\"valid_strict\"]:\n",
    "            repaired =True \n",
    "\n",
    "            review_text ,_ =truncate_text (text )\n",
    "\n",
    "            repair_prompt =(\n",
    "            \"You produced INVALID output for a rating prediction task.\\n\"\n",
    "            f\"Error type: {error_type}\\n\\n\"\n",
    "            \"Task: Predict the overall airline review rating as an INTEGER 1..10.\\n\"\n",
    "            \"Return ONLY JSON that matches the schema. No commentary, no code fences.\\n\"\n",
    "            f\"Schema: {json.dumps(SCHEMA_OBJ, ensure_ascii=False)}\\n\\n\"\n",
    "            \"REVIEW:\\n\"\n",
    "            f\"{review_text}\\n\\n\"\n",
    "            \"PREVIOUS_OUTPUT:\\n\"\n",
    "            f\"{raw1s}\\n\"\n",
    "            )\n",
    "\n",
    "            fmt_repair =mode_to_format (\"M4_REPAIR\")\n",
    "\n",
    "            raw2 ,transport_err2 =ollama_generate_with_transport_retry (\n",
    "            repair_prompt ,\n",
    "            model =OLLAMA_MODEL ,\n",
    "            base_url =OLLAMA_BASE_URL ,\n",
    "            temperature =0.0 ,\n",
    "            fmt =fmt_repair ,\n",
    "            )\n",
    "            raw2s =(raw2 or \"\").strip ()\n",
    "            raw_repair =raw2s \n",
    "            raw_final =raw2s \n",
    "            raw_first =raw1s \n",
    "\n",
    "            if transport_err2 is not None and raw2s ==\"\":\n",
    "                parsed =None \n",
    "                error_type =transport_err2 \n",
    "                schema_ok =False \n",
    "                dual_final =None \n",
    "            else :\n",
    "                dual_final =parse_dual_for_mode (raw2s ,mode =mode )\n",
    "                parsed =dual_final [\"parsed_rating_strict\"]\n",
    "                error_type =dual_final [\"error_type_strict\"]\n",
    "                schema_ok =dual_final [\"schema_ok_strict\"]\n",
    "\n",
    "    else :\n",
    "        raise ValueError (mode )\n",
    "\n",
    "    runtime_ms =int ((time .perf_counter ()-t0 )*1000 )\n",
    "\n",
    "    rec ={\n",
    "    \"timestamp_utc\":time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ()),\n",
    "    \"row_id\":int (row_id ),\n",
    "    \"mode\":mode ,\n",
    "    \"model\":OLLAMA_MODEL ,\n",
    "    \"temperature\":0.0 ,\n",
    "    \"prompt_hash\":p_hash ,\n",
    "\n",
    "    \"raw_output\":raw_final ,\n",
    "    \"raw_output_first\":raw_first if repaired else None ,\n",
    "    \"raw_output_repair\":raw_repair if repaired else None ,\n",
    "\n",
    "    \"parsed_rating\":parsed ,\n",
    "    \"error_type\":error_type ,\n",
    "    \"schema_ok\":schema_ok ,\n",
    "\n",
    "    \"transport_error_first\":transport_err ,\n",
    "    \"transport_error_repair\":(locals ().get (\"transport_err2\")if repaired else None ),\n",
    "    **(dual if mode in (\"M2_JSON_PROMPT\",\"M3_SCHEMA_PROMPT\",\"M3_SCHEMA_ENFORCED\")else {}),\n",
    "    **(dual_first_pref if mode ==\"M4_REPAIR\"else {}),\n",
    "    **(dual_final if (mode ==\"M4_REPAIR\"and 'dual_final'in locals ()and dual_final is not None )else {}),\n",
    "\n",
    "    \"runtime_ms\":runtime_ms ,\n",
    "    \"runtime_ms_effective\":runtime_ms ,\n",
    "    \"repaired\":bool (repaired ),\n",
    "    \"from_cache\":False ,\n",
    "\n",
    "    \"format_kind\":fmt_kind ,\n",
    "    \"format_fp\":fmt_fp ,\n",
    "    \"runtime_ms_cached\":None ,\n",
    "\n",
    "    }\n",
    "\n",
    "    append_cache (CACHE_PATH ,rec )\n",
    "    cache_index [(int (row_id ),mode )]=rec \n",
    "    return rec \n",
    "\n",
    "def run_mode_chunked (mode :str )->pd .DataFrame :\n",
    "    rows =[]\n",
    "    t0 =time .perf_counter ()\n",
    "    for start in range (0 ,len (df_S ),CHUNK_SIZE ):\n",
    "        end =min (len (df_S ),start +CHUNK_SIZE )\n",
    "        chunk =df_S .iloc [start :end ]\n",
    "        for r in chunk .itertuples (index =False ):\n",
    "            rows .append (run_one (int (r .row_id ),getattr (r ,\"text\"),mode ))\n",
    "        done =end \n",
    "        valid_now =pd .Series ([x .get (\"parsed_rating\")for x in rows ]).notna ().mean ()\n",
    "        print (f\"{mode} progress: {done}/{len(df_S)} | valid_rate_so_far={valid_now:.3f}\")\n",
    "    dt =time .perf_counter ()-t0 \n",
    "    rec_df =pd .DataFrame (rows )\n",
    "    valid =rec_df [\"parsed_rating\"].notna ().mean ()\n",
    "    print (f\"{mode}: done | seconds={dt:.1f} | valid_rate={valid:.3f} | repaired_rate={rec_df['repaired'].mean():.3f} | from_cache={rec_df['from_cache'].mean():.3f}\")\n",
    "    return rec_df \n",
    "\n",
    "mode_frames ={}\n",
    "for mode in MODES :\n",
    "    mode_frames [mode ]=run_mode_chunked (mode )\n",
    "\n",
    "for mode in [\"M1_FREE\",\"M2_JSON_PROMPT\",\"M3_SCHEMA_PROMPT\",\"M3_SCHEMA_ENFORCED\",\"M4_REPAIR\"]:\n",
    "    fmt =mode_to_format (mode )\n",
    "    resp ,err =ollama_generate_with_transport_retry (\n",
    "    'Return ONLY {\"rating\": 7}',model =OLLAMA_MODEL ,base_url =OLLAMA_BASE_URL ,temperature =0.0 ,fmt =fmt \n",
    "    )\n",
    "    print (mode ,\"| err=\",err ,\"| resp=\",resp [:80 ])\n",
    "\n",
    "try :\n",
    "    import shutil \n",
    "    shutil .copy2 (CACHE_PATH ,CACHE_PATH_LATEST )\n",
    "except Exception :\n",
    "    pass \n",
    "\n",
    "def compute_llm_metrics (df_rec :pd .DataFrame ,y_true_by_id :Dict [int ,float ],variant :str =\"strict\")->Dict [str ,Any ]:\n",
    "    \"\"\"\n",
    "    Computes metrics for LLM predictions.\n",
    "    variant=\"strict\" -> paper-primary fields\n",
    "    variant=\"relaxed\" -> recoverability diagnostics (if present)\n",
    "    \"\"\"\n",
    "\n",
    "    parsed_col =f\"parsed_rating_{variant}\"if f\"parsed_rating_{variant}\"in df_rec .columns else \"parsed_rating\"\n",
    "    err_col =f\"error_type_{variant}\"if f\"error_type_{variant}\"in df_rec .columns else \"error_type\"\n",
    "    schema_col =f\"schema_ok_{variant}\"if f\"schema_ok_{variant}\"in df_rec .columns else \"schema_ok\"\n",
    "    valid_col =f\"valid_{variant}\"if f\"valid_{variant}\"in df_rec .columns else None \n",
    "\n",
    "    y_true =df_rec [\"row_id\"].astype (int ).map (y_true_by_id ).astype (float ).to_numpy ()\n",
    "    y_pred =pd .to_numeric (df_rec .get (parsed_col ),errors =\"coerce\").to_numpy ()\n",
    "\n",
    "    if valid_col is not None :\n",
    "        valid_mask =df_rec [valid_col ].fillna (False ).astype (bool ).to_numpy ()\n",
    "    else :\n",
    "        valid_mask =pd .isna (df_rec .get (err_col )).to_numpy ()&~pd .isna (y_pred )\n",
    "\n",
    "    n =int (len (df_rec ))\n",
    "    coverage =float (valid_mask .mean ())if n else 0.0 \n",
    "\n",
    "    if valid_mask .sum ()>0 :\n",
    "        m =evaluate_regression (y_true [valid_mask ],y_pred [valid_mask ])\n",
    "        mae =float (m [\"mae\"])\n",
    "        rmse =float (m [\"rmse\"])\n",
    "        spearman =float (m [\"spearman\"])\n",
    "        risk_mae =mae \n",
    "        risk_rmse =rmse \n",
    "    else :\n",
    "        mae =rmse =spearman =risk_mae =risk_rmse =float (\"nan\")\n",
    "\n",
    "    parse_success =float (pd .isna (df_rec .get (err_col )).mean ())if err_col in df_rec .columns else float (\"nan\")\n",
    "    empty_refusal =float (df_rec .get (err_col ).isin ([\"empty\",\"refusal\"]).mean ())if err_col in df_rec .columns else 0.0 \n",
    "    out_of_range =float (df_rec .get (err_col ).eq (\"out_of_range\").mean ())if err_col in df_rec .columns else 0.0 \n",
    "\n",
    "    if schema_col in df_rec .columns and df_rec [schema_col ].notna ().any ():\n",
    "        schema_adherence =float (df_rec [schema_col ].fillna (False ).mean ())\n",
    "    else :\n",
    "        schema_adherence =parse_success \n",
    "\n",
    "    runtime_col =\"runtime_ms_effective\"if \"runtime_ms_effective\"in df_rec .columns else \"runtime_ms\"\n",
    "    total_runtime_s =float (df_rec [runtime_col ].fillna (0 ).sum ()/1000.0 )\n",
    "    sec_per_100 =float (runtime_s_per_100 (n ,total_runtime_s ))\n",
    "\n",
    "    invalid_final_n =int ((~valid_mask ).sum ())if n else 0 \n",
    "\n",
    "    valid_first_col =f\"valid_{variant}_first\"if f\"valid_{variant}_first\"in df_rec .columns else None \n",
    "    if valid_first_col is not None :\n",
    "        valid_first =df_rec [valid_first_col ].fillna (False ).astype (bool ).to_numpy ()\n",
    "        invalid_first_n =int ((~valid_first ).sum ())if n else 0 \n",
    "    else :\n",
    "        valid_first =valid_mask \n",
    "        invalid_first_n =invalid_final_n \n",
    "\n",
    "    repaired_mask =df_rec .get (\"repaired\",False )\n",
    "    if hasattr (repaired_mask ,\"fillna\"):\n",
    "        repaired_mask =repaired_mask .fillna (False ).astype (bool ).to_numpy ()\n",
    "    else :\n",
    "        repaired_mask =np .zeros (n ,dtype =bool )\n",
    "\n",
    "    repair_trigger_n =int (repaired_mask .sum ())if n else 0 \n",
    "    repair_success_n =int (((repaired_mask )&(~valid_first )&(valid_mask )).sum ())if n else 0 \n",
    "    repair_trigger_rate =(repair_trigger_n /n )if n else 0.0 \n",
    "    repair_success_rate =(repair_success_n /n )if n else 0.0 \n",
    "\n",
    "    return {\n",
    "    \"coverage\":coverage ,\n",
    "    \"mae\":mae ,\n",
    "    \"rmse\":rmse ,\n",
    "    \"spearman\":spearman ,\n",
    "    \"risk_mae\":risk_mae ,\n",
    "    \"risk_rmse\":risk_rmse ,\n",
    "    \"parse_success_rate\":parse_success ,\n",
    "    \"schema_adherence_rate\":schema_adherence ,\n",
    "    \"out_of_range_rate\":out_of_range ,\n",
    "    \"empty_refusal_rate\":empty_refusal ,\n",
    "    \"runtime_s_total\":total_runtime_s ,\n",
    "    \"sec_per_100\":sec_per_100 ,\n",
    "    \"n_samples\":n ,\n",
    "    \"repaired_rate\":float (df_rec [\"repaired\"].mean ())if \"repaired\"in df_rec .columns else 0.0 ,\n",
    "    \"cache_hit_rate\":float (df_rec [\"from_cache\"].mean ())if \"from_cache\"in df_rec .columns else 0.0 ,\n",
    "    \"invalid_first_n\":invalid_first_n ,\n",
    "    \"invalid_final_n\":invalid_final_n ,\n",
    "    \"repair_trigger_n\":repair_trigger_n ,\n",
    "    \"repair_trigger_rate\":float (repair_trigger_rate ),\n",
    "    \"repair_success_n\":repair_success_n ,\n",
    "    \"repair_success_rate\":float (repair_success_rate ),\n",
    "    }\n",
    "\n",
    "y_true_S ={int (r .row_id ):float (r .target )for r in df_S .itertuples (index =False )}\n",
    "y_true_test ={int (r .row_id ):float (r .target )for r in df_test .itertuples (index =False )}\n",
    "\n",
    "def predictions_table (df_rec :pd .DataFrame ,split_name :str ,y_true_map :Dict [int ,float ],method_name :str )->pd .DataFrame :\n",
    "    rid =df_rec [\"row_id\"].astype (int )\n",
    "\n",
    "    y_pred_strict =pd .to_numeric (df_rec .get (\"parsed_rating_strict\",df_rec .get (\"parsed_rating\")),errors =\"coerce\")\n",
    "    y_pred_relaxed =pd .to_numeric (df_rec .get (\"parsed_rating_relaxed\",df_rec .get (\"parsed_rating\")),errors =\"coerce\")\n",
    "\n",
    "    valid_strict =df_rec .get (\"valid_strict\",pd .isna (df_rec .get (\"error_type_strict\",df_rec .get (\"error_type\")))).fillna (False ).astype (bool )\n",
    "    valid_relaxed =df_rec .get (\"valid_relaxed\",pd .isna (df_rec .get (\"error_type_relaxed\",df_rec .get (\"error_type\")))).fillna (False ).astype (bool )\n",
    "\n",
    "    error_type_strict =df_rec .get (\"error_type_strict\",df_rec .get (\"error_type\"))\n",
    "    error_type_relaxed =df_rec .get (\"error_type_relaxed\",df_rec .get (\"error_type\"))\n",
    "\n",
    "    out =pd .DataFrame ({\n",
    "    \"row_id\":rid ,\n",
    "    \"split\":split_name ,\n",
    "    \"method\":method_name ,\n",
    "    \"y_true\":rid .map (y_true_map ).astype (float ),\n",
    "\n",
    "    \"y_pred\":y_pred_strict ,\n",
    "    \"valid\":valid_strict ,\n",
    "    \"error_type\":error_type_strict ,\n",
    "\n",
    "    \"y_pred_strict\":y_pred_strict ,\n",
    "    \"y_pred_relaxed\":y_pred_relaxed ,\n",
    "    \"valid_strict\":valid_strict ,\n",
    "    \"valid_relaxed\":valid_relaxed ,\n",
    "    \"error_type_strict\":error_type_strict ,\n",
    "    \"error_type_relaxed\":error_type_relaxed ,\n",
    "\n",
    "    \"runtime_ms\":pd .to_numeric (df_rec .get (\"runtime_ms\"),errors =\"coerce\"),\n",
    "    \"runtime_ms_effective\":pd .to_numeric (df_rec .get (\"runtime_ms_effective\",df_rec .get (\"runtime_ms\")),errors =\"coerce\"),\n",
    "\n",
    "    \"repaired\":df_rec .get (\"repaired\",False ).fillna (False ).astype (bool ),\n",
    "    \"from_cache\":df_rec .get (\"from_cache\",False ).fillna (False ).astype (bool ),\n",
    "    })\n",
    "    return out \n",
    "\n",
    "results_rows =[]\n",
    "pred_files =[]\n",
    "fig_paths =[]\n",
    "\n",
    "S_ids =set (df_S [\"row_id\"].astype (int ).tolist ())\n",
    "test_ids_set =set (df_test [\"row_id\"].astype (int ).tolist ())\n",
    "LLM_HAS_FULL_TEST =(S_ids ==test_ids_set )\n",
    "\n",
    "for mode in MODES :\n",
    "    df_rec =mode_frames [mode ].copy ()\n",
    "\n",
    "    method =f\"phi3mini_{mode.lower()}\"\n",
    "\n",
    "    metrics_S_strict =compute_llm_metrics (df_rec ,y_true_S ,variant =\"strict\")\n",
    "    metrics_S_relaxed =compute_llm_metrics (df_rec ,y_true_S ,variant =\"relaxed\")\n",
    "    pred_S =predictions_table (df_rec ,\"S\",y_true_S ,method )\n",
    "\n",
    "    pred_parts =[pred_S ]\n",
    "    results_splits =[(\"S\",metrics_S_strict ,metrics_S_relaxed )]\n",
    "\n",
    "    if LLM_HAS_FULL_TEST :\n",
    "        df_rec_by_id =df_rec .set_index (\"row_id\")\n",
    "        ordered =df_test [\"row_id\"].astype (int ).tolist ()\n",
    "        df_rec_test =df_rec_by_id .reindex (ordered ).reset_index ()\n",
    "\n",
    "        if \"mode\"in df_rec_test .columns and df_rec_test [\"mode\"].isna ().any ():\n",
    "            df_rec_test [\"mode\"]=mode \n",
    "            df_rec_test [\"model\"]=OLLAMA_MODEL \n",
    "            df_rec_test [\"temperature\"]=0.0 \n",
    "            df_rec_test [\"raw_output\"]=\"\"\n",
    "            df_rec_test [\"parsed_rating\"]=np .nan \n",
    "            df_rec_test [\"error_type\"]=\"missing_prediction\"\n",
    "            df_rec_test [\"schema_ok\"]=False \n",
    "            df_rec_test [\"runtime_ms\"]=0 \n",
    "            df_rec_test [\"repaired\"]=False \n",
    "            df_rec_test [\"from_cache\"]=True \n",
    "            df_rec_test [\"parsed_rating_strict\"]=np .nan \n",
    "            df_rec_test [\"error_type_strict\"]=\"missing_prediction\"\n",
    "            df_rec_test [\"schema_ok_strict\"]=False \n",
    "            df_rec_test [\"valid_strict\"]=False \n",
    "            df_rec_test [\"valid_strict_first\"]=False \n",
    "            df_rec_test [\"error_type_strict_first\"]=\"missing_prediction\"\n",
    "            df_rec_test [\"schema_ok_strict_first\"]=False \n",
    "            df_rec_test [\"parsed_rating_relaxed\"]=np .nan \n",
    "            df_rec_test [\"error_type_relaxed\"]=\"missing_prediction\"\n",
    "            df_rec_test [\"schema_ok_relaxed\"]=False \n",
    "            df_rec_test [\"valid_relaxed\"]=False \n",
    "            df_rec_test [\"valid_relaxed_first\"]=False \n",
    "            df_rec_test [\"error_type_relaxed_first\"]=\"missing_prediction\"\n",
    "            df_rec_test [\"schema_ok_relaxed_first\"]=False \n",
    "            df_rec_test [\"runtime_ms_effective\"]=0 \n",
    "\n",
    "        metrics_test_strict =compute_llm_metrics (df_rec_test ,y_true_test ,variant =\"strict\")\n",
    "        metrics_test_relaxed =compute_llm_metrics (df_rec_test ,y_true_test ,variant =\"relaxed\")\n",
    "        pred_test =predictions_table (df_rec_test ,\"test\",y_true_test ,method )\n",
    "\n",
    "        pred_parts .append (pred_test )\n",
    "        results_splits .append ((\"test\",metrics_test_strict ,metrics_test_relaxed ))\n",
    "\n",
    "    pred_path =PATHS [\"reports\"]/f\"predictions_{method}.parquet\"\n",
    "    pd .concat (pred_parts ,axis =0 ).reset_index (drop =True ).to_parquet (pred_path ,index =False )\n",
    "    pred_files .append (pred_path )\n",
    "\n",
    "    timestamp_utc =time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ())\n",
    "    for split_name ,met_strict ,met_relaxed in results_splits :\n",
    "        results_rows .append ({\n",
    "        \"timestamp_utc\":timestamp_utc ,\n",
    "        \"method\":method ,\n",
    "        \"split\":split_name ,\n",
    "        \"llm_mode\":mode ,\n",
    "        \"model_name\":OLLAMA_MODEL ,\n",
    "        \"temperature\":0.0 ,\n",
    "\n",
    "        **{k :met_strict [k ]for k in [\"mae\",\"rmse\",\"spearman\",\"parse_success_rate\",\"schema_adherence_rate\",\n",
    "        \"out_of_range_rate\",\"empty_refusal_rate\",\"coverage\",\"risk_mae\",\"risk_rmse\",\n",
    "        \"sec_per_100\",\"n_samples\",\n",
    "        \"repaired_rate\",\"cache_hit_rate\",\n",
    "        \"invalid_first_n\",\"invalid_final_n\",\"repair_trigger_n\",\"repair_trigger_rate\",\"repair_success_n\",\"repair_success_rate\"]},\n",
    "\n",
    "        \"coverage_relaxed\":met_relaxed [\"coverage\"],\n",
    "        \"parse_success_rate_relaxed\":met_relaxed [\"parse_success_rate\"],\n",
    "        \"schema_adherence_rate_relaxed\":met_relaxed [\"schema_adherence_rate\"],\n",
    "        \"mae_relaxed\":met_relaxed [\"mae\"],\n",
    "        \"rmse_relaxed\":met_relaxed [\"rmse\"],\n",
    "        \"spearman_relaxed\":met_relaxed [\"spearman\"],\n",
    "\n",
    "        \"invalid_first_n_relaxed\":met_relaxed .get (\"invalid_first_n\"),\n",
    "        \"invalid_final_n_relaxed\":met_relaxed .get (\"invalid_final_n\"),\n",
    "        \"repair_trigger_rate_relaxed\":met_relaxed .get (\"repair_trigger_rate\"),\n",
    "        \"repair_success_rate_relaxed\":met_relaxed .get (\"repair_success_rate\"),\n",
    "\n",
    "        \"inference_s\":met_strict [\"runtime_s_total\"],\n",
    "        \"notes\":(\"evaluated_on=S_only\"if not LLM_HAS_FULL_TEST else f\"cache={CACHE_PATH.name}\"),\n",
    "        })\n",
    "\n",
    "for _r in results_rows :\n",
    "    _r .setdefault (\"run_id\",RUN_ID )\n",
    "    _r .setdefault (\"run_tag\",RUN_TAG )\n",
    "\n",
    "results_path =PATHS [\"reports\"]/\"results.csv\"\n",
    "results_path_run =PATHS [\"reports\"]/f\"results_{RUN_ID}.csv\"\n",
    "\n",
    "def upsert_results (existing :Optional [pd .DataFrame ],new_rows :pd .DataFrame ,key_cols :List [str ])->pd .DataFrame :\n",
    "    if existing is None or len (existing )==0 :\n",
    "        out =new_rows .copy ()\n",
    "    else :\n",
    "        out =pd .concat ([existing ,new_rows ],axis =0 ,ignore_index =True )\n",
    "        out [\"_dupkey\"]=out [key_cols ].astype (str ).agg (\"||\".join ,axis =1 )\n",
    "        out =out .drop_duplicates (subset =\"_dupkey\",keep =\"last\").drop (columns =[\"_dupkey\"])\n",
    "    return out .sort_values (key_cols ).reset_index (drop =True )\n",
    "\n",
    "df_new =pd .DataFrame (results_rows )\n",
    "df_exist =pd .read_csv (results_path )if results_path .exists ()else pd .DataFrame ()\n",
    "df_results =upsert_results (df_exist ,df_new ,key_cols =[\"method\",\"split\",\"run_id\"])\n",
    "df_new .to_csv (results_path_run ,index =False )\n",
    "df_results .to_csv (results_path ,index =False )\n",
    "\n",
    "summary_cols =[\"method\",\"split\",\"mae\",\"rmse\",\"spearman\",\"coverage\",\"parse_success_rate\",\"schema_adherence_rate\",\"out_of_range_rate\",\"empty_refusal_rate\",\"sec_per_100\",\"n_samples\"]\n",
    "\n",
    "try :\n",
    "    import matplotlib .pyplot as plt \n",
    "\n",
    "    if (df_new [\"split\"]==\"test\").any ():\n",
    "        test_rows =df_new [df_new [\"split\"]==\"test\"].copy ()\n",
    "        test_rows [\"mode\"]=test_rows [\"llm_mode\"]\n",
    "        test_rows =test_rows .sort_values (\"mode\")\n",
    "\n",
    "        fig1 =PATHS [\"figs\"]/\"phi3mini_mae_by_mode_test.png\"\n",
    "        plt .figure ()\n",
    "        plt .bar (test_rows [\"mode\"].astype (str ),test_rows [\"mae\"].astype (float ))\n",
    "        plt .ylabel (\"MAE (lower is better)\")\n",
    "        plt .title (\"phi3:mini — MAE by Mode (Test)\")\n",
    "        plt .tight_layout ()\n",
    "        savefig_with_runid (fig1 ,dpi =150 )\n",
    "        plt .close ()\n",
    "\n",
    "        fig2 =PATHS [\"figs\"]/\"phi3mini_coverage_by_mode_test.png\"\n",
    "        plt .figure ()\n",
    "        plt .bar (test_rows [\"mode\"].astype (str ),test_rows [\"coverage\"].astype (float ))\n",
    "        plt .ylabel (\"Coverage / Valid Rate\")\n",
    "        plt .title (\"phi3:mini — Coverage by Mode (Test)\")\n",
    "        plt .ylim (0 ,1.05 )\n",
    "        plt .tight_layout ()\n",
    "        savefig_with_runid (fig2 ,dpi =150 )\n",
    "        plt .close ()\n",
    "\n",
    "        fig_paths =[fig1 ,fig2 ]\n",
    "        print (\"Saved figs:\",[str (p )for p in fig_paths ])\n",
    "    else :\n",
    "        print (\"No full LLM test predictions; skipping test plots.\")\n",
    "except Exception as e :\n",
    "    print (\"Plotting skipped:\",repr (e ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3237d54-9cad-4a5f-be9f-88da442d8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path =PATHS [\"reports\"]/\"results.csv\"\n",
    "\n",
    "df_res =pd .read_csv (results_path )\n",
    "\n",
    "df_res [\"timestamp_utc\"]=df_res [\"timestamp_utc\"].astype (str )\n",
    "df_res [\"_ts\"]=pd .to_datetime (df_res [\"timestamp_utc\"],errors =\"coerce\",utc =True )\n",
    "\n",
    "df_latest =(\n",
    "df_res .sort_values ([\"method\",\"split\",\"_ts\"])\n",
    ".groupby ([\"method\",\"split\"],as_index =False )\n",
    ".tail (1 )\n",
    ".drop (columns =[\"_ts\"])\n",
    ".reset_index (drop =True )\n",
    ")\n",
    "\n",
    "num_cols =[\"mae\",\"rmse\",\"spearman\",\"coverage\",\"parse_success_rate\",\"schema_adherence_rate\",\n",
    "\"out_of_range_rate\",\"empty_refusal_rate\",\"sec_per_100\",\"n_samples\",\"risk_mae\",\"risk_rmse\"]\n",
    "for c in num_cols :\n",
    "    if c in df_latest .columns :\n",
    "        df_latest [c ]=pd .to_numeric (df_latest [c ],errors =\"coerce\")\n",
    "\n",
    "keep_cols =[\n",
    "\"method\",\"split\",\"mae\",\"rmse\",\"spearman\",\"coverage\",\"risk_mae\",\"risk_rmse\",\n",
    "\"parse_success_rate\",\"schema_adherence_rate\",\"out_of_range_rate\",\"empty_refusal_rate\",\n",
    "\"sec_per_100\",\"n_samples\",\"timestamp_utc\"\n",
    "]\n",
    "keep_cols =[c for c in keep_cols if c in df_latest .columns ]\n",
    "\n",
    "lb_test =(df_latest [df_latest [\"split\"]==\"test\"][keep_cols ]\n",
    ".sort_values ([\"mae\",\"rmse\",\"sec_per_100\"],ascending =[True ,True ,True ])\n",
    ".reset_index (drop =True ))\n",
    "\n",
    "lb_S =(df_latest [df_latest [\"split\"]==\"S\"][keep_cols ]\n",
    ".sort_values ([\"mae\",\"rmse\",\"sec_per_100\"],ascending =[True ,True ,True ])\n",
    ".reset_index (drop =True ))\n",
    "\n",
    "lb_test_path =PATHS [\"reports\"]/\"leaderboard_test.csv\"\n",
    "lb_S_path =PATHS [\"reports\"]/\"leaderboard_S.csv\"\n",
    "df_latest_path =PATHS [\"reports\"]/\"results_latest.csv\"\n",
    "\n",
    "lb_test .to_csv (lb_test_path ,index =False )\n",
    "lb_S .to_csv (lb_S_path ,index =False )\n",
    "df_latest .to_csv (df_latest_path ,index =False )\n",
    "\n",
    "pred_files =sorted (glob .glob (str (PATHS [\"reports\"]/\"predictions_*.parquet\")))\n",
    "\n",
    "df_all =pd .read_parquet (PATHS [\"data_processed\"]/\"reviews_processed.parquet\")[[\"row_id\",\"target\"]].copy ()\n",
    "df_all [\"rating_bin\"]=pd .cut (df_all [\"target\"],bins =[-0.1 ,3 ,7 ,10.1 ],labels =[\"1-3\",\"4-7\",\"8-10\"],include_lowest =True )\n",
    "bin_map =df_all .set_index (\"row_id\")[\"rating_bin\"].astype (str ).to_dict ()\n",
    "\n",
    "def per_bin_metrics (dfp :pd .DataFrame )->pd .DataFrame :\n",
    "    \"\"\"\n",
    "    dfp schema:\n",
    "      row_id, split, method, y_true, y_pred, ...\n",
    "    For LLM: may include valid flag; if absent, valid = y_pred notna\n",
    "    \"\"\"\n",
    "    df =dfp .copy ()\n",
    "    df [\"row_id\"]=pd .to_numeric (df [\"row_id\"],errors =\"coerce\").astype (\"Int64\")\n",
    "    df =df [df [\"row_id\"].notna ()].copy ()\n",
    "    df [\"row_id\"]=df [\"row_id\"].astype (int )\n",
    "\n",
    "    df =df [df [\"split\"]==\"test\"].copy ()\n",
    "    if len (df )==0 :\n",
    "        return pd .DataFrame ()\n",
    "\n",
    "    if \"valid\"in df .columns :\n",
    "        df [\"valid\"]=df [\"valid\"].astype (bool )\n",
    "    else :\n",
    "        df [\"valid\"]=pd .to_numeric (df [\"y_pred\"],errors =\"coerce\").notna ()\n",
    "\n",
    "    df [\"y_true\"]=pd .to_numeric (df [\"y_true\"],errors =\"coerce\")\n",
    "    df [\"y_pred\"]=pd .to_numeric (df [\"y_pred\"],errors =\"coerce\")\n",
    "    df [\"rating_bin\"]=df [\"row_id\"].map (bin_map ).fillna (\"unknown\")\n",
    "\n",
    "    out =[]\n",
    "    for (method ,b ),g in df .groupby ([\"method\",\"rating_bin\"]):\n",
    "        valid =g [g [\"valid\"]&g [\"y_true\"].notna ()&g [\"y_pred\"].notna ()]\n",
    "        cov =float (len (valid )/max (1 ,len (g )))\n",
    "        if len (valid )>0 :\n",
    "            m =evaluate_regression (valid [\"y_true\"].to_numpy (),valid [\"y_pred\"].to_numpy ())\n",
    "        else :\n",
    "            m ={\"mae\":np .nan ,\"rmse\":np .nan ,\"spearman\":np .nan }\n",
    "        out .append ({\n",
    "        \"method\":method ,\n",
    "        \"rating_bin\":b ,\n",
    "        \"n_total\":int (len (g )),\n",
    "        \"n_valid\":int (len (valid )),\n",
    "        \"coverage\":cov ,\n",
    "        \"mae\":float (m [\"mae\"]),\n",
    "        \"rmse\":float (m [\"rmse\"]),\n",
    "        \"spearman\":float (m [\"spearman\"]),\n",
    "        })\n",
    "    return pd .DataFrame (out )\n",
    "\n",
    "all_bin_rows =[]\n",
    "for fp in pred_files :\n",
    "    dfp =pd .read_parquet (fp )\n",
    "    if not {\"row_id\",\"split\",\"method\",\"y_true\",\"y_pred\"}.issubset (dfp .columns ):\n",
    "        continue \n",
    "    all_bin_rows .append (per_bin_metrics (dfp ))\n",
    "\n",
    "df_bins =pd .concat (all_bin_rows ,axis =0 ,ignore_index =True )\n",
    "df_bins =df_bins [df_bins [\"rating_bin\"].isin ([\"1-3\",\"4-7\",\"8-10\"])].copy ()\n",
    "\n",
    "bins_path =PATHS [\"reports\"]/\"fairness_by_bin_test.csv\"\n",
    "df_bins .to_csv (bins_path ,index =False )\n",
    "\n",
    "try :\n",
    "    import matplotlib .pyplot as plt \n",
    "    HAS_MPL =True \n",
    "except Exception :\n",
    "    HAS_MPL =False \n",
    "\n",
    "dfp =lb_test .copy ()\n",
    "\n",
    "dfp =dfp .sort_values ([\"mae\",\"rmse\",\"sec_per_100\"],ascending =[True ,True ,True ]).reset_index (drop =True )\n",
    "\n",
    "fig_mae =PATHS [\"figs\"]/\"leaderboard_mae_test.png\"\n",
    "plt .figure ()\n",
    "plt .bar (dfp [\"method\"].astype (str ),dfp [\"mae\"].astype (float ))\n",
    "plt .ylabel (\"MAE (test)\")\n",
    "plt .title (\"All methods — MAE on Test (lower is better)\")\n",
    "plt .xticks (rotation =90 )\n",
    "plt .tight_layout ()\n",
    "savefig_with_runid (fig_mae ,dpi =150 )\n",
    "plt .close ()\n",
    "\n",
    "fig_cov =PATHS [\"figs\"]/\"leaderboard_coverage_test.png\"\n",
    "plt .figure ()\n",
    "plt .bar (dfp [\"method\"].astype (str ),dfp [\"coverage\"].astype (float ))\n",
    "plt .ylabel (\"Coverage / Valid rate (test)\")\n",
    "plt .title (\"All methods — Coverage on Test (higher is better)\")\n",
    "plt .ylim (0 ,1.05 )\n",
    "plt .xticks (rotation =90 )\n",
    "plt .tight_layout ()\n",
    "savefig_with_runid (fig_cov ,dpi =150 )\n",
    "plt .close ()\n",
    "\n",
    "fig_cov_mae =PATHS [\"figs\"]/\"coverage_vs_mae_test.png\"\n",
    "plt .figure ()\n",
    "x =dfp [\"coverage\"].astype (float ).to_numpy ()\n",
    "y =dfp [\"mae\"].astype (float ).to_numpy ()\n",
    "plt .scatter (x ,y ,alpha =0.8 )\n",
    "for i ,m in enumerate (dfp [\"method\"].astype (str ).tolist ()):\n",
    "    plt .annotate (m ,(x [i ],y [i ]),fontsize =8 )\n",
    "plt .xlabel (\"Coverage (higher better)\")\n",
    "plt .ylabel (\"MAE (lower better)\")\n",
    "plt .title (\"Test: Coverage vs MAE\")\n",
    "plt .tight_layout ()\n",
    "savefig_with_runid (fig_cov_mae ,dpi =150 )\n",
    "plt .close ()\n",
    "\n",
    "fig_eff_mae =PATHS [\"figs\"]/\"efficiency_vs_mae_test.png\"\n",
    "plt .figure ()\n",
    "x =dfp [\"sec_per_100\"].astype (float ).to_numpy ()\n",
    "y =dfp [\"mae\"].astype (float ).to_numpy ()\n",
    "plt .scatter (x ,y ,alpha =0.8 )\n",
    "for i ,m in enumerate (dfp [\"method\"].astype (str ).tolist ()):\n",
    "    plt .annotate (m ,(x [i ],y [i ]),fontsize =8 )\n",
    "plt .xlabel (\"Seconds per 100 samples (lower better)\")\n",
    "plt .ylabel (\"MAE (lower better)\")\n",
    "plt .title (\"Test: Efficiency vs MAE\")\n",
    "plt .tight_layout ()\n",
    "savefig_with_runid (fig_eff_mae ,dpi =150 )\n",
    "plt .close ()\n",
    "\n",
    "for p in [fig_mae ,fig_cov ,fig_cov_mae ,fig_eff_mae ]:\n",
    "    print (\" -\",p )\n",
    "\n",
    "\n",
    "lb =pd .read_csv (PATHS [\"reports\"]/\"leaderboard_test.csv\")\n",
    "\n",
    "bins =pd .read_csv (PATHS [\"reports\"]/\"fairness_by_bin_test.csv\")\n",
    "\n",
    "CACHE_PATH =PATHS [\"reports\"]/\"llm_cache.jsonl\"\n",
    "\n",
    "cache_index =load_cache_index (CACHE_PATH )\n",
    "\n",
    "df_S =pd .read_parquet (PATHS [\"data_processed\"]/\"splits\"/\"subset_S.parquet\").copy ()\n",
    "df_S =df_S .sample (n =min (30 ,len (df_S )),random_state =SEED ).reset_index (drop =True )\n",
    "\n",
    "def probe_cache_hits (df_probe :pd .DataFrame ,mode :str )->Dict [str ,Any ]:\n",
    "    t0 =time .perf_counter ()\n",
    "    hits =0 \n",
    "    for r in df_probe .itertuples (index =False ):\n",
    "        key =(int (r .row_id ),mode )\n",
    "        if key in cache_index :\n",
    "            hits +=1 \n",
    "        else :\n",
    "            _ =run_one (int (r .row_id ),getattr (r ,\"text\"),mode )\n",
    "            hits +=0 \n",
    "    dt =time .perf_counter ()-t0 \n",
    "    return {\n",
    "    \"mode\":mode ,\n",
    "    \"n_probe\":int (len (df_probe )),\n",
    "    \"cache_hits\":int (hits ),\n",
    "    \"cache_hit_rate\":float (hits /max (1 ,len (df_probe ))),\n",
    "    \"probe_seconds\":float (dt ),\n",
    "    \"probe_sec_per_100\":runtime_s_per_100 (len (df_probe ),dt ),\n",
    "    }\n",
    "\n",
    "rows =[]\n",
    "for mode in MODES :\n",
    "    rows .append (probe_cache_hits (df_S ,mode ))\n",
    "\n",
    "df_probe =pd .DataFrame (rows )\n",
    "\n",
    "\n",
    "def list_files (root :Path ,patterns :List [str ])->pd .DataFrame :\n",
    "    files =[]\n",
    "    for pat in patterns :\n",
    "        files .extend (root .rglob (pat ))\n",
    "    rows =[]\n",
    "    for p in sorted (set (files )):\n",
    "        if p .is_file ():\n",
    "            rows .append ({\n",
    "            \"path\":str (p ),\n",
    "            \"size_kb\":round (p .stat ().st_size /1024 ,2 ),\n",
    "            \"modified\":time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime (p .stat ().st_mtime )),\n",
    "            })\n",
    "    return pd .DataFrame (rows )\n",
    "\n",
    "idx_models =list_files (PATHS [\"models\"],[\"*.joblib\",\"*.bin\",\"*.safetensors\",\"config.json\",\"tokenizer.json\",\"vocab.txt\"])\n",
    "idx_reports =list_files (PATHS [\"reports\"],[\"*.csv\",\"*.json\",\"*.jsonl\",\"*.parquet\",\"*.md\"])\n",
    "idx_figs =list_files (PATHS [\"figs\"],[\"*.png\"])\n",
    "idx_data =list_files (PATHS [\"data_processed\"],[\"*.parquet\",\"*.csv\",\"*.json\"])\n",
    "idx_feat =list_files (PATHS [\"data_features\"],[\"*.npz\",\"*.json\"])\n",
    "\n",
    "artifact_index =pd .concat ([\n",
    "idx_models .assign (category =\"models\"),\n",
    "idx_reports .assign (category =\"reports\"),\n",
    "idx_figs .assign (category =\"figs\"),\n",
    "idx_data .assign (category =\"data_processed\"),\n",
    "idx_feat .assign (category =\"data_features\"),\n",
    "],axis =0 ).reset_index (drop =True )\n",
    "\n",
    "artifact_index_path =PATHS [\"reports\"]/\"artifact_index.csv\"\n",
    "artifact_index .to_csv (artifact_index_path ,index =False )\n",
    "\n",
    "splits_meta_path =PATHS [\"reports\"]/\"splits_meta.json\"\n",
    "subset_meta_path =PATHS [\"reports\"]/\"subset_S_meta.json\"\n",
    "schema_path =PATHS [\"reports\"]/\"data_schema.json\"\n",
    "\n",
    "splits_meta =json .load (open (splits_meta_path ,\"r\",encoding =\"utf-8\"))if splits_meta_path .exists ()else {}\n",
    "subset_meta =json .load (open (subset_meta_path ,\"r\",encoding =\"utf-8\"))if subset_meta_path .exists ()else {}\n",
    "data_schema =json .load (open (schema_path ,\"r\",encoding =\"utf-8\"))if schema_path .exists ()else {}\n",
    "\n",
    "must_have =[\n",
    "PATHS [\"data_processed\"]/\"reviews_processed.parquet\",\n",
    "PATHS [\"data_processed\"]/\"splits\"/\"train.parquet\",\n",
    "PATHS [\"data_processed\"]/\"splits\"/\"val.parquet\",\n",
    "PATHS [\"data_processed\"]/\"splits\"/\"test.parquet\",\n",
    "PATHS [\"reports\"]/\"results.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "BOOT_B =5000 \n",
    "BOOT_SEED =SEED \n",
    "\n",
    "pred_paths =sorted (glob .glob (str (PATHS [\"reports\"]/\"predictions_*.parquet\")))\n",
    "\n",
    "df_test =pd .read_parquet (PATHS [\"data_processed\"]/\"splits\"/\"test.parquet\")[[\"row_id\",\"target\",\"text\"]].copy ()\n",
    "df_test [\"row_id\"]=df_test [\"row_id\"].astype (int )\n",
    "df_test =df_test .rename (columns ={\"target\":\"y_true\"})\n",
    "df_test [\"text_len_chars\"]=df_test [\"text\"].astype (str ).str .len ()\n",
    "\n",
    "df_test [\"rating_bin\"]=pd .cut (df_test [\"y_true\"],bins =[-0.1 ,3 ,7 ,10.1 ],labels =[\"1-3\",\"4-7\",\"8-10\"],include_lowest =True ).astype (str )\n",
    "\n",
    "def load_method_predictions (path :str )->pd .DataFrame :\n",
    "    dfp =pd .read_parquet (path )\n",
    "    dfp =dfp [dfp [\"split\"]==\"test\"].copy ()\n",
    "    dfp [\"row_id\"]=pd .to_numeric (dfp [\"row_id\"],errors =\"coerce\").astype (\"Int64\")\n",
    "    dfp =dfp [dfp [\"row_id\"].notna ()].copy ()\n",
    "    dfp [\"row_id\"]=dfp [\"row_id\"].astype (int )\n",
    "\n",
    "    method =str (dfp [\"method\"].iloc [0 ])if len (dfp )else Path (path ).stem .replace (\"predictions_\",\"\")\n",
    "    stem =Path (path ).stem .replace (\"predictions_\",\"\")\n",
    "    if \"__\"in stem :\n",
    "        base ,tag =stem .rsplit (\"__\",1 )\n",
    "        method =f\"{base}__{tag}\"\n",
    "    dfp [\"method\"]=method \n",
    "\n",
    "    if \"y_pred_strict\"in dfp .columns :\n",
    "        y_pred =pd .to_numeric (dfp [\"y_pred_strict\"],errors =\"coerce\")\n",
    "        valid =dfp [\"valid_strict\"].astype (bool )if \"valid_strict\"in dfp .columns else y_pred .notna ()\n",
    "        err_type =dfp [\"error_type_strict\"]if \"error_type_strict\"in dfp .columns else dfp .get (\"error_type\",None )\n",
    "    elif \"y_pred\"in dfp .columns :\n",
    "        y_pred =pd .to_numeric (dfp [\"y_pred\"],errors =\"coerce\")\n",
    "        valid =dfp [\"valid\"].astype (bool )if \"valid\"in dfp .columns else y_pred .notna ()\n",
    "        err_type =dfp .get (\"error_type\",None )\n",
    "    else :\n",
    "        raise ValueError (f\"Keine y_pred Spalte in {path}\")\n",
    "\n",
    "    out =dfp [[\"row_id\",\"method\"]].copy ()\n",
    "    out [\"y_pred\"]=y_pred \n",
    "    out [\"valid\"]=valid \n",
    "    if err_type is not None :\n",
    "        out [\"error_type\"]=err_type \n",
    "    else :\n",
    "        out [\"error_type\"]=None \n",
    "\n",
    "    for c in [\"runtime_ms\",\"repaired\",\"from_cache\"]:\n",
    "        if c in dfp .columns :\n",
    "            out [c ]=dfp [c ]\n",
    "    return out \n",
    "\n",
    "method_tables =[]\n",
    "for p in pred_paths :\n",
    "    try :\n",
    "        method_tables .append (load_method_predictions (p ))\n",
    "    except Exception as e :\n",
    "        print (\"Skip (could not load):\",p ,\"|\",repr (e ))\n",
    "\n",
    "df_methods =pd .concat (method_tables ,axis =0 ,ignore_index =True )\n",
    "\n",
    "methods =sorted (df_methods [\"method\"].unique ().tolist ())\n",
    "\n",
    "joined ={}\n",
    "for m in methods :\n",
    "    d =df_methods [df_methods [\"method\"]==m ].copy ()\n",
    "    d =df_test .merge (d ,on =[\"row_id\"],how =\"left\")\n",
    "    d [\"valid\"]=d [\"valid\"].fillna (False )\n",
    "    joined [m ]=d \n",
    "\n",
    "for m ,d in list (joined .items ())[:5 ]:\n",
    "    print (m ,\"| n=\",len (d ),\"| coverage=\",float (d [\"valid\"].mean ()))\n",
    "\n",
    "def mae_rmse (y_true :np .ndarray ,y_pred :np .ndarray )->tuple [float ,float ]:\n",
    "    err =y_pred -y_true \n",
    "    mae =float (np .mean (np .abs (err )))\n",
    "    rmse =float (np .sqrt (np .mean (err **2 )))\n",
    "    return mae ,rmse \n",
    "\n",
    "def bootstrap_ci_metric (y_true :np .ndarray ,y_pred :np .ndarray ,B :int ,seed :int )->dict :\n",
    "    rng =np .random .default_rng (seed )\n",
    "    n =len (y_true )\n",
    "    idx =rng .integers (0 ,n ,size =(B ,n ))\n",
    "    yt =y_true [idx ]\n",
    "    yp =y_pred [idx ]\n",
    "    err =yp -yt \n",
    "    mae_b =np .mean (np .abs (err ),axis =1 )\n",
    "    rmse_b =np .sqrt (np .mean (err **2 ,axis =1 ))\n",
    "    return {\n",
    "    \"mae_mean\":float (np .mean (mae_b )),\n",
    "    \"mae_p025\":float (np .quantile (mae_b ,0.025 )),\n",
    "    \"mae_p975\":float (np .quantile (mae_b ,0.975 )),\n",
    "    \"rmse_mean\":float (np .mean (rmse_b )),\n",
    "    \"rmse_p025\":float (np .quantile (rmse_b ,0.025 )),\n",
    "    \"rmse_p975\":float (np .quantile (rmse_b ,0.975 )),\n",
    "    }\n",
    "\n",
    "rows =[]\n",
    "for m ,d in joined .items ():\n",
    "    valid =d [\"valid\"].to_numpy (dtype =bool )\n",
    "    y_true =d .loc [valid ,\"y_true\"].to_numpy (dtype =float )\n",
    "    y_pred =d .loc [valid ,\"y_pred\"].to_numpy (dtype =float )\n",
    "\n",
    "    coverage =float (valid .mean ())\n",
    "    n_valid =int (valid .sum ())\n",
    "\n",
    "    if n_valid ==0 :\n",
    "        rows .append ({\"method\":m ,\"coverage\":coverage ,\"n_valid\":n_valid ,\n",
    "        \"mae_point\":np .nan ,\"rmse_point\":np .nan ,\n",
    "        \"mae_mean\":np .nan ,\"mae_p025\":np .nan ,\"mae_p975\":np .nan ,\n",
    "        \"rmse_mean\":np .nan ,\"rmse_p025\":np .nan ,\"rmse_p975\":np .nan })\n",
    "        continue \n",
    "\n",
    "    mae0 ,rmse0 =mae_rmse (y_true ,y_pred )\n",
    "    ci =bootstrap_ci_metric (y_true ,y_pred ,B =BOOT_B ,seed =BOOT_SEED )\n",
    "\n",
    "    rows .append ({\n",
    "    \"method\":m ,\n",
    "    \"coverage\":coverage ,\n",
    "    \"n_valid\":n_valid ,\n",
    "    \"mae_point\":mae0 ,\n",
    "    \"rmse_point\":rmse0 ,\n",
    "    **ci \n",
    "    })\n",
    "\n",
    "df_ci =pd .DataFrame (rows ).sort_values ([\"mae_point\",\"rmse_point\"],ascending =[True ,True ])\n",
    "ci_path =PATHS [\"reports\"]/\"bootstrap_ci_test_strict.csv\"\n",
    "df_ci .to_csv (ci_path ,index =False )\n",
    "\n",
    "def paired_bootstrap_delta_mae (dA :pd .DataFrame ,dB :pd .DataFrame ,B :int ,seed :int )->dict :\n",
    "    \"\"\"\n",
    "    Delta = MAE(A) - MAE(B) on matched rows where both valid.\n",
    "    \"\"\"\n",
    "    m =dA [[\"row_id\",\"y_true\",\"y_pred\",\"valid\"]].merge (\n",
    "    dB [[\"row_id\",\"y_pred\",\"valid\"]].rename (columns ={\"y_pred\":\"y_pred_B\",\"valid\":\"valid_B\"}),\n",
    "    on =\"row_id\",\n",
    "    how =\"inner\"\n",
    "    )\n",
    "    mask =m [\"valid\"].to_numpy (bool )&m [\"valid_B\"].to_numpy (bool )\n",
    "    m =m .loc [mask ].copy ()\n",
    "\n",
    "    if len (m )==0 :\n",
    "        return {\"n_overlap\":0 ,\"delta_mae_mean\":np .nan ,\"p025\":np .nan ,\"p975\":np .nan }\n",
    "\n",
    "    y_true =m [\"y_true\"].to_numpy (float )\n",
    "    yA =m [\"y_pred\"].to_numpy (float )\n",
    "    yB =m [\"y_pred_B\"].to_numpy (float )\n",
    "\n",
    "    rng =np .random .default_rng (seed )\n",
    "    n =len (y_true )\n",
    "    idx =rng .integers (0 ,n ,size =(B ,n ))\n",
    "\n",
    "    yt =y_true [idx ]\n",
    "    yA_b =yA [idx ]\n",
    "    yB_b =yB [idx ]\n",
    "\n",
    "    maeA =np .mean (np .abs (yA_b -yt ),axis =1 )\n",
    "    maeB =np .mean (np .abs (yB_b -yt ),axis =1 )\n",
    "    delta =maeA -maeB \n",
    "\n",
    "    return {\n",
    "    \"n_overlap\":int (n ),\n",
    "    \"delta_mae_mean\":float (np .mean (delta )),\n",
    "    \"p025\":float (np .quantile (delta ,0.025 )),\n",
    "    \"p975\":float (np .quantile (delta ,0.975 )),\n",
    "    }\n",
    "\n",
    "refs =[]\n",
    "if \"distilbert_reg\"in joined :\n",
    "    refs .append (\"distilbert_reg\")\n",
    "if \"tfidf_ridge\"in joined :\n",
    "    refs .append (\"tfidf_ridge\")\n",
    "if not refs :\n",
    "    refs =[df_ci .dropna (subset =[\"mae_point\"]).iloc [0 ][\"method\"]]\n",
    "\n",
    "delta_rows =[]\n",
    "for ref in refs :\n",
    "    for m in methods :\n",
    "        if m ==ref :\n",
    "            continue \n",
    "        out =paired_bootstrap_delta_mae (joined [m ],joined [ref ],B =BOOT_B ,seed =BOOT_SEED )\n",
    "        delta_rows .append ({\n",
    "        \"method_A\":m ,\n",
    "        \"method_B_ref\":ref ,\n",
    "        **out \n",
    "        })\n",
    "\n",
    "df_delta =pd .DataFrame (delta_rows ).sort_values ([\"method_B_ref\",\"delta_mae_mean\"])\n",
    "delta_path =PATHS [\"reports\"]/\"bootstrap_delta_mae_test_strict.csv\"\n",
    "df_delta .to_csv (delta_path ,index =False )\n",
    "\n",
    "def safe_method_filename (s :str )->str :\n",
    "    return re .sub (r\"[^a-zA-Z0-9_\\-]+\",\"_\",s )[:120 ]\n",
    "\n",
    "summary_rows =[]\n",
    "\n",
    "for m ,d in joined .items ():\n",
    "    dd =d .copy ()\n",
    "    dd [\"error\"]=dd [\"y_pred\"]-dd [\"y_true\"]\n",
    "    dd [\"abs_error\"]=np .abs (dd [\"error\"])\n",
    "    dd [\"method\"]=m \n",
    "\n",
    "    v =dd [dd [\"valid\"]&dd [\"y_pred\"].notna ()].copy ()\n",
    "\n",
    "    if len (v )>0 :\n",
    "        mae0 =float (np .mean (v [\"abs_error\"]))\n",
    "        rmse0 =float (np .sqrt (np .mean ((v [\"error\"])**2 )))\n",
    "    else :\n",
    "        mae0 =np .nan \n",
    "        rmse0 =np .nan \n",
    "\n",
    "    summary_rows .append ({\n",
    "    \"method\":m ,\n",
    "    \"coverage\":float (dd [\"valid\"].mean ()),\n",
    "    \"n_valid\":int (dd [\"valid\"].sum ()),\n",
    "    \"mae_valid\":mae0 ,\n",
    "    \"rmse_valid\":rmse0 ,\n",
    "    })\n",
    "\n",
    "    top =v .sort_values (\"abs_error\",ascending =False ).head (50 )\n",
    "\n",
    "    cols =[\"row_id\",\"y_true\",\"y_pred\",\"error\",\"abs_error\",\"rating_bin\",\"text_len_chars\"]\n",
    "    for extra in [\"error_type\",\"repaired\",\"runtime_ms\",\"from_cache\"]:\n",
    "        if extra in dd .columns :\n",
    "            cols .append (extra )\n",
    "\n",
    "    out_path =PATHS [\"reports\"]/f\"error_analysis_{safe_method_filename(m)}.csv\"\n",
    "    top [cols ].to_csv (out_path ,index =False )\n",
    "\n",
    "df_errsum =pd .DataFrame (summary_rows ).sort_values ([\"mae_valid\",\"coverage\"],ascending =[True ,False ])\n",
    "errsum_path =PATHS [\"reports\"]/\"error_analysis_summary.csv\"\n",
    "df_errsum .to_csv (errsum_path ,index =False )\n",
    "\n",
    "must =[\n",
    "PATHS [\"reports\"]/\"bootstrap_ci_test_strict.csv\",\n",
    "PATHS [\"reports\"]/\"bootstrap_delta_mae_test_strict.csv\",\n",
    "PATHS [\"reports\"]/\"error_analysis_summary.csv\",\n",
    "]\n",
    "\n",
    "ea_files =list (PATHS [\"reports\"].glob (\"error_analysis_*.csv\"))\n",
    "\n",
    "def add_efficiency_columns (df :pd .DataFrame )->pd .DataFrame :\n",
    "    \"\"\"\n",
    "    Adds:\n",
    "      - sec_per_100_total: existing sec_per_100 (if present) else derived from inference_s/n_samples\n",
    "      - sec_per_100_online: inference-only for methods with precompute (e.g., MiniLM with feature_s_est)\n",
    "    Expected columns (if available):\n",
    "      - sec_per_100\n",
    "      - inference_s, n_samples\n",
    "      - feature_s_est (MiniLM)\n",
    "    \"\"\"\n",
    "    out =df .copy ()\n",
    "\n",
    "    if \"sec_per_100\"in out .columns :\n",
    "        out [\"sec_per_100_total\"]=pd .to_numeric (out [\"sec_per_100\"],errors =\"coerce\")\n",
    "    else :\n",
    "        if {\"inference_s\",\"n_samples\"}.issubset (out .columns ):\n",
    "            out [\"sec_per_100_total\"]=out .apply (\n",
    "            lambda r :runtime_s_per_100 (int (r [\"n_samples\"]),float (r [\"inference_s\"]))\n",
    "            if pd .notna (r .get (\"inference_s\"))and pd .notna (r .get (\"n_samples\"))else np .nan ,\n",
    "            axis =1 \n",
    "            )\n",
    "        else :\n",
    "            out [\"sec_per_100_total\"]=np .nan \n",
    "\n",
    "    out [\"sec_per_100_online\"]=out [\"sec_per_100_total\"]\n",
    "\n",
    "    if \"feature_s_est\"in out .columns and {\"inference_s\",\"n_samples\"}.issubset (out .columns ):\n",
    "        f =pd .to_numeric (out [\"feature_s_est\"],errors =\"coerce\")\n",
    "        n =pd .to_numeric (out [\"n_samples\"],errors =\"coerce\")\n",
    "        inf =pd .to_numeric (out [\"inference_s\"],errors =\"coerce\")\n",
    "\n",
    "        mask =f .notna ()&n .notna ()&inf .notna ()\n",
    "        if mask .any ():\n",
    "            out .loc [mask ,\"sec_per_100_online\"]=out .loc [mask ].apply (\n",
    "            lambda r :runtime_s_per_100 (int (r [\"n_samples\"]),float (r [\"inference_s\"])),\n",
    "            axis =1 \n",
    "            )\n",
    "            out .loc [mask ,\"sec_per_100_total\"]=out .loc [mask ].apply (\n",
    "            lambda r :runtime_s_per_100 (int (r [\"n_samples\"]),float (r [\"inference_s\"])+float (r [\"feature_s_est\"])),\n",
    "            axis =1 \n",
    "            )\n",
    "    return out \n",
    "\n",
    "results_path =PATHS [\"reports\"]/\"results.csv\"\n",
    "if results_path .exists ():\n",
    "    df_res =pd .read_csv (results_path )\n",
    "    df_res2 =add_efficiency_columns (df_res )\n",
    "    df_res2 .to_csv (results_path ,index =False )\n",
    "    print (\"Updated results with efficiency columns:\",results_path )\n",
    "else :\n",
    "    print (\"results.csv not found at:\",results_path )\n",
    "    df_res2 =None \n",
    "\n",
    "if df_res2 is not None and len (df_res2 ):\n",
    "    df_res2 [\"timestamp_utc\"]=df_res2 [\"timestamp_utc\"].astype (str )\n",
    "    df_res2 [\"_ts\"]=pd .to_datetime (df_res2 [\"timestamp_utc\"],errors =\"coerce\",utc =True )\n",
    "    df_latest =(\n",
    "    df_res2 .sort_values ([\"method\",\"split\",\"_ts\"])\n",
    "    .groupby ([\"method\",\"split\"],as_index =False )\n",
    "    .tail (1 )\n",
    "    .drop (columns =[\"_ts\"])\n",
    "    .reset_index (drop =True )\n",
    "    )\n",
    "    latest_path =PATHS [\"reports\"]/\"results_latest.csv\"\n",
    "    df_latest .to_csv (latest_path ,index =False )\n",
    "    print (\"Updated:\",latest_path )\n",
    "\n",
    "    snap_path =PATHS [\"reports\"]/f\"results_latest__{RUN_ID}.csv\"\n",
    "    df_latest .to_csv (snap_path ,index =False )\n",
    "    print (\"Saved snapshot:\",snap_path )\n",
    "\n",
    "    import json \n",
    "    import platform \n",
    "    from datetime import datetime \n",
    "    meta ={\n",
    "    \"run_id\":RUN_ID ,\n",
    "    \"run_tag\":RUN_TAG ,\n",
    "    \"time_utc\":datetime .utcnow ().isoformat ()+\"Z\",\n",
    "    \"seed\":SEED ,\n",
    "    \"use_ollama_format\":bool (globals ().get (\"USE_OLLAMA_FORMAT\",False )),\n",
    "    \"ollama_model\":globals ().get (\"OLLAMA_MODEL\",None ),\n",
    "    \"ollama_base_url\":globals ().get (\"OLLAMA_BASE_URL\",None ),\n",
    "    \"cache_path\":str (globals ().get (\"CACHE_PATH\",\"\")),\n",
    "    \"python_version\":platform .python_version (),\n",
    "    \"platform\":platform .platform (),\n",
    "    }\n",
    "    meta_path =PATHS [\"reports\"]/f\"run_meta__{RUN_ID}.json\"\n",
    "    with open (meta_path ,\"w\",encoding =\"utf-8\")as f :\n",
    "        json .dump (meta ,f ,indent =2 ,ensure_ascii =False )\n",
    "    print (\"Saved meta:\",meta_path )\n",
    "else :\n",
    "    df_latest =None \n",
    "\n",
    "import matplotlib .pyplot as plt \n",
    "\n",
    "latest_path =PATHS [\"reports\"]/\"results_latest.csv\"\n",
    "if latest_path .exists ():\n",
    "    df_latest =pd .read_csv (latest_path )\n",
    "    df_latest =add_efficiency_columns (df_latest )\n",
    "\n",
    "    df_test_rows =df_latest [df_latest [\"split\"]==\"test\"].copy ()\n",
    "    if len (df_test_rows ):\n",
    "        df_test_rows [\"mae\"]=pd .to_numeric (df_test_rows [\"mae\"],errors =\"coerce\")\n",
    "        df_test_rows [\"coverage\"]=pd .to_numeric (df_test_rows [\"coverage\"],errors =\"coerce\")\n",
    "        df_test_rows [\"sec_per_100_online\"]=pd .to_numeric (df_test_rows [\"sec_per_100_online\"],errors =\"coerce\")\n",
    "        df_test_rows [\"sec_per_100_total\"]=pd .to_numeric (df_test_rows [\"sec_per_100_total\"],errors =\"coerce\")\n",
    "\n",
    "        fig1 =PATHS [\"figs\"]/\"efficiency_online_vs_mae_test.png\"\n",
    "        plt .figure ()\n",
    "        plt .scatter (df_test_rows [\"sec_per_100_online\"],df_test_rows [\"mae\"],alpha =0.8 )\n",
    "        for _ ,r in df_test_rows .iterrows ():\n",
    "            if pd .notna (r [\"sec_per_100_online\"])and pd .notna (r [\"mae\"]):\n",
    "                plt .annotate (str (r [\"method\"]),(r [\"sec_per_100_online\"],r [\"mae\"]),fontsize =8 )\n",
    "        plt .xlabel (\"sec_per_100_online (lower better)\")\n",
    "        plt .ylabel (\"MAE (lower better)\")\n",
    "        plt .title (\"Test: Online Efficiency vs MAE\")\n",
    "        plt .tight_layout ()\n",
    "        savefig_with_runid (fig1 ,dpi =150 )\n",
    "        plt .close ()\n",
    "\n",
    "        fig2 =PATHS [\"figs\"]/\"efficiency_total_vs_mae_test.png\"\n",
    "        plt .figure ()\n",
    "        plt .scatter (df_test_rows [\"sec_per_100_total\"],df_test_rows [\"mae\"],alpha =0.8 )\n",
    "        for _ ,r in df_test_rows .iterrows ():\n",
    "            if pd .notna (r [\"sec_per_100_total\"])and pd .notna (r [\"mae\"]):\n",
    "                plt .annotate (str (r [\"method\"]),(r [\"sec_per_100_total\"],r [\"mae\"]),fontsize =8 )\n",
    "        plt .xlabel (\"sec_per_100_total (lower better)\")\n",
    "        plt .ylabel (\"MAE (lower better)\")\n",
    "        plt .title (\"Test: Total Efficiency vs MAE\")\n",
    "        plt .tight_layout ()\n",
    "        savefig_with_runid (fig2 ,dpi =150 )\n",
    "        plt .close ()\n",
    "\n",
    "        print (\"Saved:\",fig1 )\n",
    "        print (\"Saved:\",fig2 )\n",
    "    else :\n",
    "        print (\"No test rows in results_latest.csv; skipping efficiency plots.\")\n",
    "else :\n",
    "    print (\"results_latest.csv not found at:\",latest_path )\n",
    "\n",
    "latest_path =PATHS [\"reports\"]/\"results_latest.csv\"\n",
    "if latest_path .exists ():\n",
    "    df_latest =pd .read_csv (latest_path )\n",
    "    df_latest =add_efficiency_columns (df_latest )\n",
    "\n",
    "    llm =df_latest [df_latest [\"method\"].astype (str ).str .startswith (\"phi3mini_\")].copy ()\n",
    "    if len (llm ):\n",
    "        diff =(pd .to_numeric (llm [\"sec_per_100_online\"],errors =\"coerce\")-pd .to_numeric (llm [\"sec_per_100_total\"],errors =\"coerce\")).abs ().max ()\n",
    "        print (\"LLM max |online-total|:\",diff )\n",
    "\n",
    "    print (\"VALIDIERUNG OK\")\n",
    "else :\n",
    "    print (\"results_latest.csv not found; cannot validate PATCH 9.\")\n",
    "\n",
    "\n",
    "out_md =PATHS [\"reports\"]/\"error_examples.md\"\n",
    "\n",
    "df_test =pd .read_parquet (PATHS [\"data_processed\"]/\"splits\"/\"test.parquet\")[[\"row_id\",\"target\",\"text\"]].copy ()\n",
    "df_test [\"row_id\"]=df_test [\"row_id\"].astype (int )\n",
    "df_test =df_test .rename (columns ={\"target\":\"y_true\"})\n",
    "df_test [\"text_len_chars\"]=df_test [\"text\"].astype (str ).str .len ()\n",
    "\n",
    "pred_paths =sorted (glob .glob (str (PATHS [\"reports\"]/\"predictions_*.parquet\")))\n",
    "\n",
    "def load_method_predictions (path :str )->pd .DataFrame :\n",
    "    dfp =pd .read_parquet (path )\n",
    "    dfp =dfp [dfp [\"split\"]==\"test\"].copy ()\n",
    "    if len (dfp )==0 :\n",
    "        return pd .DataFrame (columns =[\"row_id\",\"method\",\"y_pred\",\"valid\",\"error_type\"])\n",
    "    dfp [\"row_id\"]=pd .to_numeric (dfp [\"row_id\"],errors =\"coerce\").astype (\"Int64\")\n",
    "    dfp =dfp [dfp [\"row_id\"].notna ()].copy ()\n",
    "    dfp [\"row_id\"]=dfp [\"row_id\"].astype (int )\n",
    "\n",
    "    method =str (dfp [\"method\"].iloc [0 ])if \"method\"in dfp .columns else Path (path ).stem .replace (\"predictions_\",\"\")\n",
    "    stem =Path (path ).stem .replace (\"predictions_\",\"\")\n",
    "    if \"__\"in stem :\n",
    "        base ,tag =stem .rsplit (\"__\",1 )\n",
    "        method =f\"{base}__{tag}\"\n",
    "    dfp [\"method\"]=method \n",
    "\n",
    "    if \"y_pred_strict\"in dfp .columns :\n",
    "        y_pred =pd .to_numeric (dfp [\"y_pred_strict\"],errors =\"coerce\")\n",
    "        valid =dfp [\"valid_strict\"].astype (bool )if \"valid_strict\"in dfp .columns else y_pred .notna ()\n",
    "        err_type =dfp [\"error_type_strict\"]if \"error_type_strict\"in dfp .columns else dfp .get (\"error_type\",None )\n",
    "    elif \"y_pred\"in dfp .columns :\n",
    "        y_pred =pd .to_numeric (dfp [\"y_pred\"],errors =\"coerce\")\n",
    "        valid =dfp [\"valid\"].astype (bool )if \"valid\"in dfp .columns else y_pred .notna ()\n",
    "        err_type =dfp .get (\"error_type\",None )\n",
    "    else :\n",
    "        raise ValueError (f\"Keine y_pred Spalte in {path}\")\n",
    "\n",
    "    out =dfp [[\"row_id\",\"method\"]].copy ()\n",
    "    out [\"y_pred\"]=y_pred \n",
    "    out [\"valid\"]=valid .fillna (False )\n",
    "    out [\"error_type\"]=err_type if err_type is not None else None \n",
    "    return out \n",
    "\n",
    "method_tables =[]\n",
    "for p in pred_paths :\n",
    "    try :\n",
    "        method_tables .append (load_method_predictions (p ))\n",
    "    except Exception as e :\n",
    "        print (\"Skip (could not load):\",p ,\"|\",repr (e ))\n",
    "\n",
    "df_methods =pd .concat (method_tables ,axis =0 ,ignore_index =True )\n",
    "methods =sorted (df_methods [\"method\"].unique ().tolist ())\n",
    "\n",
    "joined ={}\n",
    "for m in methods :\n",
    "    d =df_methods [df_methods [\"method\"]==m ].copy ()\n",
    "    d =df_test .merge (d ,on =\"row_id\",how =\"left\")\n",
    "    d [\"valid\"]=d [\"valid\"].fillna (False )\n",
    "    joined [m ]=d \n",
    "\n",
    "best_ref =None \n",
    "ci_path =PATHS [\"reports\"]/\"bootstrap_ci_test_strict.csv\"\n",
    "if ci_path .exists ():\n",
    "    df_ci =pd .read_csv (ci_path )\n",
    "    if \"mae_point\"in df_ci .columns :\n",
    "        best_ref =str (df_ci .sort_values (\"mae_point\").iloc [0 ][\"method\"])\n",
    "if best_ref is None and len (methods ):\n",
    "    best_ref =methods [0 ]\n",
    "\n",
    "llm_methods =[m for m in methods if str (m ).startswith (\"phi3mini_\")]\n",
    "show_methods =[]\n",
    "if best_ref :\n",
    "    show_methods .append (best_ref )\n",
    "for pref in [\"phi3mini_m3_schema_decoding\",\"phi3mini_m4_repair\",\"phi3mini_m3_schema_prompt\",\"phi3mini_m2_json\",\"phi3mini_m1_free\"]:\n",
    "    if pref in llm_methods and pref not in show_methods :\n",
    "        show_methods .append (pref )\n",
    "show_methods =show_methods [:3 ]\n",
    "\n",
    "def short_text (s :str ,n :int =220 )->str :\n",
    "    t =(s or \"\").replace (\"\\n\",\" \").strip ()\n",
    "    t =re .sub (r\"\\s+\",\" \",t )\n",
    "    return (t [:n ]+\"…\")if len (t )>n else t \n",
    "\n",
    "lines =[]\n",
    "lines .append (\"# Error Examples (Step 10)\\n\\n\")\n",
    "lines .append (f\"Generated: {pd.Timestamp.utcnow().isoformat()}Z\\n\\n\")\n",
    "lines .append (\"This file summarizes common failure modes and shows concrete examples (strict evaluation).\\n\\n\")\n",
    "\n",
    "for m in show_methods :\n",
    "    d =joined [m ].copy ()\n",
    "    d [\"error\"]=d [\"y_pred\"]-d [\"y_true\"]\n",
    "    d [\"abs_error\"]=np .abs (d [\"error\"])\n",
    "    coverage =float (d [\"valid\"].mean ())\n",
    "    n_valid =int (d [\"valid\"].sum ())\n",
    "\n",
    "    lines .append (f\"## Method: `{m}`\\n\\n\")\n",
    "    lines .append (f\"- Coverage (strict): **{coverage:.3f}** ({n_valid}/{len(d)})\\n\\n\")\n",
    "\n",
    "    inv =d [~d [\"valid\"]].copy ()\n",
    "    lines .append (\"### Failure modes (invalid outputs)\\n\\n\")\n",
    "    if len (inv )>0 :\n",
    "        vc =inv [\"error_type\"].value_counts (dropna =False ).head (10 )\n",
    "        for k ,v in vc .items ():\n",
    "            lines .append (f\"- `{k}`: {int(v)}\\n\")\n",
    "        lines .append (\"\\n### Invalid examples\\n\\n\")\n",
    "        samp =inv .head (2 )\n",
    "        for _ ,r in samp .iterrows ():\n",
    "            lines .append (f\"- row_id={int(r['row_id'])} | error_type={r.get('error_type')} | text_len={int(r['text_len_chars'])}\\n\")\n",
    "            lines .append (f\"  - text: \\\"{short_text(r['text'])}\\\"\\n\")\n",
    "    else :\n",
    "        lines .append (\"- (none)\\n\")\n",
    "\n",
    "    v =d [d [\"valid\"]&d [\"y_pred\"].notna ()].copy ()\n",
    "    lines .append (\"\\n### Largest errors (valid predictions)\\n\\n\")\n",
    "    if len (v )==0 :\n",
    "        lines .append (\"- (no valid predictions)\\n\")\n",
    "    else :\n",
    "        top =v .sort_values (\"abs_error\",ascending =False ).head (5 )\n",
    "        for _ ,r in top .iterrows ():\n",
    "            lines .append (\n",
    "            f\"- row_id={int(r['row_id'])} | y_true={float(r['y_true']):.1f} | y_pred={float(r['y_pred']):.1f} | abs_err={float(r['abs_error']):.1f} | text_len={int(r['text_len_chars'])}\\n\"\n",
    "            )\n",
    "            lines .append (f\"  - text: \\\"{short_text(r['text'])}\\\"\\n\")\n",
    "    lines .append (\"\\n\")\n",
    "\n",
    "out_md .write_text (\"\".join (lines ),encoding =\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f58e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_SWEEP =True \n",
    "\n",
    "RUN_SWEEP_CONFIGS =[\n",
    "dict (run_tag =\"prompt_1k8\",use_format =True ,num_predict =32 ,prompt_max_chars =1800 ),\n",
    "dict (run_tag =\"format_off\",use_format =False ,num_predict =32 ,prompt_max_chars =1800 ),\n",
    "dict (run_tag =\"fast_predict8\",use_format =True ,num_predict =8 ,prompt_max_chars =1800 ),\n",
    "dict (run_tag =\"prompt_4k\",use_format =True ,num_predict =32 ,prompt_max_chars =4000 ),\n",
    "]\n",
    "\n",
    "def _set_prompt_truncation (max_chars :int )->None :\n",
    "    \"\"\"\n",
    "    Setzt das zentrale Prompt-Profil (Sweep-sicher).\n",
    "    make_prompt() und Repair-Prompts nutzen automatisch truncate_text() -> PROMPT_PROFILE.\n",
    "    \"\"\"\n",
    "    global PROMPT_MAX_CHARS \n",
    "    PROMPT_MAX_CHARS =int (max_chars )\n",
    "    set_prompt_profile (max_chars =PROMPT_MAX_CHARS ,tail_chars =350 ,marker =\"\\n...\\n\")\n",
    "def _reset_llm_cache (run_id :str ,run_tag :str )->Path :\n",
    "    \"\"\"Isolierter Cache pro Run (wichtig für saubere Vergleiche).\"\"\"\n",
    "    global CACHE_PATH ,cache_index \n",
    "    cache_path =PATHS [\"reports\"]/f\"llm_cache__{run_id}__{run_tag}.jsonl\"\n",
    "    cache_path .parent .mkdir (parents =True ,exist_ok =True )\n",
    "    CACHE_PATH =cache_path \n",
    "    cache_index =load_cache_index (CACHE_PATH )if CACHE_PATH .exists ()else {}\n",
    "    print (\"CACHE_PATH:\",CACHE_PATH ,\"| cached rows:\",len (cache_index ))\n",
    "    return CACHE_PATH \n",
    "\n",
    "def _ensure_run_dir (run_id :str ,run_tag :str )->Path :\n",
    "    run_dir =PATHS [\"reports\"]/\"runs\"/f\"{run_id}__{run_tag}\"\n",
    "    run_dir .mkdir (parents =True ,exist_ok =True )\n",
    "    return run_dir \n",
    "\n",
    "def _evaluate_llm_modes (mode_frames :Dict [str ,pd .DataFrame ],*,run_id :str ,run_tag :str )->pd .DataFrame :\n",
    "    \"\"\"\n",
    "    Rechnet Metrics (strict+relaxed) und speichert Predictions pro Mode in einem Run-Ordner.\n",
    "    Nutzt Patch-6 Logik: test nur wenn S==test.\n",
    "    \"\"\"\n",
    "    S_ids =set (df_S [\"row_id\"].astype (int ).tolist ())\n",
    "    test_ids =set (df_test [\"row_id\"].astype (int ).tolist ())\n",
    "    LLM_HAS_FULL_TEST =(S_ids ==test_ids )\n",
    "    print (\"LLM_HAS_FULL_TEST:\",LLM_HAS_FULL_TEST ,\"| nS:\",len (S_ids ),\"| nTest:\",len (test_ids ))\n",
    "\n",
    "    rows =[]\n",
    "    run_dir =_ensure_run_dir (run_id ,run_tag )\n",
    "\n",
    "    timestamp_utc =time .strftime (\"%Y-%m-%dT%H:%M:%SZ\",time .gmtime ())\n",
    "\n",
    "    for mode in MODES :\n",
    "        df_rec =mode_frames [mode ].copy ()\n",
    "        method =f\"{OLLAMA_MODEL}_{mode.lower()}\"\n",
    "\n",
    "        metS_strict =compute_llm_metrics (df_rec ,y_true_S ,variant =\"strict\")\n",
    "        metS_relaxed =compute_llm_metrics (df_rec ,y_true_S ,variant =\"relaxed\")\n",
    "        pred_S =predictions_table (df_rec ,\"S\",y_true_S ,method )\n",
    "\n",
    "        pred_parts =[pred_S ]\n",
    "        splits =[(\"S\",metS_strict ,metS_relaxed ,len (df_rec ))]\n",
    "\n",
    "        if LLM_HAS_FULL_TEST :\n",
    "            df_rec_by_id =df_rec .set_index (\"row_id\")\n",
    "            ordered =df_test [\"row_id\"].astype (int ).tolist ()\n",
    "            df_rec_test =df_rec_by_id .reindex (ordered ).reset_index ()\n",
    "\n",
    "            metT_strict =compute_llm_metrics (df_rec_test ,y_true_test ,variant =\"strict\")\n",
    "            metT_relaxed =compute_llm_metrics (df_rec_test ,y_true_test ,variant =\"relaxed\")\n",
    "            pred_test =predictions_table (df_rec_test ,\"test\",y_true_test ,method )\n",
    "\n",
    "            pred_parts .append (pred_test )\n",
    "            splits .append ((\"test\",metT_strict ,metT_relaxed ,len (df_rec_test )))\n",
    "\n",
    "        pred_df =pd .concat (pred_parts ,axis =0 ).reset_index (drop =True )\n",
    "        pred_path =run_dir /f\"predictions_{method}__{run_tag}.parquet\"\n",
    "        pred_df .to_parquet (pred_path ,index =False )\n",
    "\n",
    "        pred_path_root =PATHS [\"reports\"]/f\"predictions_{method}__{run_tag}.parquet\"\n",
    "        try :\n",
    "            shutil .copy2 (pred_path ,pred_path_root )\n",
    "        except Exception as e :\n",
    "            print (\"WARN: could not copy predictions to reports root:\",e )\n",
    "\n",
    "        for split_name ,met_strict ,met_relaxed ,n_samples in splits :\n",
    "            rows .append ({\n",
    "            \"timestamp_utc\":timestamp_utc ,\n",
    "            \"run_id\":run_id ,\n",
    "            \"run_tag\":run_tag ,\n",
    "\n",
    "            \"method\":method ,\n",
    "            \"split\":split_name ,\n",
    "            \"llm_mode\":mode ,\n",
    "            \"model_name\":OLLAMA_MODEL ,\n",
    "            \"temperature\":0.0 ,\n",
    "\n",
    "            **{k :met_strict [k ]for k in [\"mae\",\"rmse\",\"spearman\",\"parse_success_rate\",\"schema_adherence_rate\",\n",
    "            \"out_of_range_rate\",\"empty_refusal_rate\",\"coverage\",\"risk_mae\",\"risk_rmse\",\n",
    "            \"sec_per_100\",\"n_samples\"]},\n",
    "\n",
    "            \"coverage_relaxed\":met_relaxed [\"coverage\"],\n",
    "            \"parse_success_rate_relaxed\":met_relaxed [\"parse_success_rate\"],\n",
    "            \"schema_adherence_rate_relaxed\":met_relaxed [\"schema_adherence_rate\"],\n",
    "            \"mae_relaxed\":met_relaxed [\"mae\"],\n",
    "            \"rmse_relaxed\":met_relaxed [\"rmse\"],\n",
    "            \"spearman_relaxed\":met_relaxed [\"spearman\"],\n",
    "\n",
    "            \"inference_s\":met_strict [\"runtime_s_total\"],\n",
    "\n",
    "            \"notes\":f\"cache={CACHE_PATH.name}\",\n",
    "            })\n",
    "\n",
    "    df_run =pd .DataFrame (rows )\n",
    "    df_run_path =run_dir /f\"results_llm__{run_tag}.csv\"\n",
    "    df_run .to_csv (df_run_path ,index =False )\n",
    "    print (\"Saved:\",df_run_path )\n",
    "\n",
    "    return df_run \n",
    "\n",
    "def _run_one_llm_config (cfg :Dict [str ,Any ])->pd .DataFrame :\n",
    "    \"\"\"\n",
    "    Ein kompletter LLM-Run (M1..M4) mit separatem Cache + separaten Artefakten.\n",
    "    \"\"\"\n",
    "    global RUN_ID ,RUN_TAG ,USE_OLLAMA_FORMAT ,OLLAMA_NUM_PREDICT \n",
    "\n",
    "    base =RUN_ID \n",
    "    run_tag =str (cfg [\"run_tag\"])\n",
    "    run_id =f\"{base}__{run_tag}__{uuid.uuid4().hex[:6]}\"\n",
    "    RUN_ID =run_id \n",
    "    RUN_TAG =run_tag \n",
    "\n",
    "    USE_OLLAMA_FORMAT =bool (cfg [\"use_format\"])\n",
    "    OLLAMA_NUM_PREDICT =int (cfg [\"num_predict\"])\n",
    "    _set_prompt_truncation (int (cfg [\"prompt_max_chars\"]))\n",
    "\n",
    "    print (\"\\n==============================\")\n",
    "    print (\"RUN:\",RUN_ID ,\"| tag:\",RUN_TAG )\n",
    "    print (\"USE_OLLAMA_FORMAT:\",USE_OLLAMA_FORMAT ,\"| OLLAMA_NUM_PREDICT:\",OLLAMA_NUM_PREDICT ,\"| PROMPT_MAX_CHARS:\",PROMPT_MAX_CHARS )\n",
    "\n",
    "    _reset_llm_cache (RUN_ID ,RUN_TAG )\n",
    "\n",
    "    warmup_prompt ='Return ONLY JSON exactly like: {\"rating\": 7}. No markdown, no code fences, no extra text.'\n",
    "\n",
    "    warmup_fmt =mode_to_format (\"M3_SCHEMA_ENFORCED\")if USE_OLLAMA_FORMAT else None \n",
    "\n",
    "    resp ,err =ollama_generate_with_transport_retry (\n",
    "    warmup_prompt ,\n",
    "    model =OLLAMA_MODEL ,\n",
    "    base_url =OLLAMA_BASE_URL ,\n",
    "    temperature =0.0 ,\n",
    "    fmt =warmup_fmt ,\n",
    "    )\n",
    "\n",
    "    pr ,perr ,pobj =parse_json_rating (resp ,relaxed =(not USE_OLLAMA_FORMAT ))\n",
    "    if perr is not None :\n",
    "        raise RuntimeError (f\"Warmup parse failed: {perr} | resp={repr((resp or '')[:200])}\")\n",
    "\n",
    "    if USE_OLLAMA_FORMAT and warmup_fmt not in (None ,\"json\"):\n",
    "        sch_err =validate_schema (pobj )\n",
    "        if sch_err is not None :\n",
    "            raise RuntimeError (f\"Warmup schema failed: {sch_err} | obj={pobj}\")\n",
    "\n",
    "    if pr !=7 :\n",
    "        raise RuntimeError (f\"Warmup rating != 7: {pr} | obj={pobj}\")\n",
    "\n",
    "    print (\"Warmup OK\")\n",
    "\n",
    "    mode_frames_local ={}\n",
    "    for mode in MODES :\n",
    "        mode_frames_local [mode ]=run_mode_chunked (mode )\n",
    "\n",
    "    df_run =_evaluate_llm_modes (mode_frames_local ,run_id =RUN_ID ,run_tag =RUN_TAG )\n",
    "\n",
    "    return df_run \n",
    "\n",
    "if RUN_SWEEP :\n",
    "    _orig_run_id =RUN_ID \n",
    "    _orig_run_tag =RUN_TAG \n",
    "    _orig_cache_path =CACHE_PATH \n",
    "    _orig_use_format =USE_OLLAMA_FORMAT \n",
    "    _orig_num_predict =OLLAMA_NUM_PREDICT \n",
    "    _orig_prompt_max =PROMPT_MAX_CHARS \n",
    "\n",
    "    all_runs =[]\n",
    "    try :\n",
    "        for cfg in RUN_SWEEP_CONFIGS :\n",
    "            df_run =_run_one_llm_config (cfg )\n",
    "            all_runs .append (df_run )\n",
    "    finally :\n",
    "        RUN_ID =_orig_run_id \n",
    "        RUN_TAG =_orig_run_tag \n",
    "        CACHE_PATH =_orig_cache_path \n",
    "        USE_OLLAMA_FORMAT =_orig_use_format \n",
    "        OLLAMA_NUM_PREDICT =_orig_num_predict \n",
    "        _set_prompt_truncation (_orig_prompt_max )\n",
    "\n",
    "    df_all =pd .concat (all_runs ,axis =0 ,ignore_index =True )\n",
    "    out_all =PATHS [\"reports\"]/\"run_sweep_llm_results.csv\"\n",
    "    df_all .to_csv (out_all ,index =False )\n",
    "    print (\"\\nSaved sweep summary:\",out_all )\n",
    "\n",
    "    def _pairwise (df :pd .DataFrame ,a :str ,b :str ,split_pref :str =\"test\")->pd .DataFrame :\n",
    "        split_use =split_pref if (df [\"split\"]==split_pref ).any ()else \"S\"\n",
    "        da =df [(df [\"run_tag\"]==a )&(df [\"split\"]==split_use )].copy ()\n",
    "        db =df [(df [\"run_tag\"]==b )&(df [\"split\"]==split_use )].copy ()\n",
    "        m =da .merge (db ,on =[\"method\",\"llm_mode\",\"split\"],suffixes =(f\"__{a}\",f\"__{b}\"))\n",
    "        for k in [\"mae\",\"coverage\",\"parse_success_rate\",\"schema_adherence_rate\",\"sec_per_100\"]:\n",
    "            m [f\"delta_{k}\"]=pd .to_numeric (m [f\"{k}__{a}\"],errors =\"coerce\")-pd .to_numeric (m [f\"{k}__{b}\"],errors =\"coerce\")\n",
    "        m [\"comparison\"]=f\"{a} vs {b} (split={split_use})\"\n",
    "        keep =[\"comparison\",\"method\",\"llm_mode\",\"split\",\n",
    "        f\"mae__{a}\",f\"mae__{b}\",\"delta_mae\",\n",
    "        f\"coverage__{a}\",f\"coverage__{b}\",\"delta_coverage\",\n",
    "        f\"sec_per_100__{a}\",f\"sec_per_100__{b}\",\"delta_sec_per_100\",\n",
    "        f\"parse_success_rate__{a}\",f\"parse_success_rate__{b}\",\"delta_parse_success_rate\",\n",
    "        f\"schema_adherence_rate__{a}\",f\"schema_adherence_rate__{b}\",\"delta_schema_adherence_rate\",\n",
    "        ]\n",
    "        return m [keep ].sort_values ([\"llm_mode\",\"method\"])\n",
    "    comps =[]\n",
    "    comps .append (_pairwise (df_all ,\"prompt_1k8\",\"format_off\"))\n",
    "    comps .append (_pairwise (df_all ,\"prompt_1k8\",\"fast_predict8\"))\n",
    "    comps .append (_pairwise (df_all ,\"prompt_1k8\",\"prompt_4k\"))\n",
    "\n",
    "    df_comp =pd .concat (comps ,axis =0 ,ignore_index =True )\n",
    "    comp_path =PATHS [\"reports\"]/\"run_sweep_llm_pairwise.csv\"\n",
    "    df_comp .to_csv (comp_path ,index =False )\n",
    "    print (\"Saved pairwise comparisons:\",comp_path )\n",
    "\n",
    "else :\n",
    "    print (\"RUN_SWEEP=False — kein Run-Sweep ausgeführt.\")\n",
    "\n",
    "import matplotlib .pyplot as plt \n",
    "\n",
    "RUN_ID_LOCAL =globals ().get (\"RUN_ID\",None )\n",
    "if RUN_ID_LOCAL is None :\n",
    "    candidates =sorted (PATHS [\"reports\"].glob (\"results_*.csv\"),key =lambda p :p .stat ().st_mtime ,reverse =True )\n",
    "    RUN_ID_LOCAL =candidates [0 ].stem .replace (\"results_\",\"\")if candidates else \"run_unknown\"\n",
    "\n",
    "PATCHSET_TAG =\"PATCHSET1\"\n",
    "export_dir =PATHS [\"reports\"]/f\"paper_exports_{RUN_ID_LOCAL}_{PATCHSET_TAG}\"\n",
    "export_dir .mkdir (parents =True ,exist_ok =True )\n",
    "\n",
    "def _load_first_existing (paths ):\n",
    "    for p in paths :\n",
    "        if p .exists ():\n",
    "            return p ,pd .read_csv (p )\n",
    "    return None ,None \n",
    "\n",
    "results_latest_paths =[\n",
    "PATHS [\"reports\"]/f\"results_latest__{RUN_ID_LOCAL}.csv\",\n",
    "PATHS [\"reports\"]/f\"results_latest_{RUN_ID_LOCAL}.csv\",\n",
    "PATHS [\"reports\"]/\"results_latest.csv\",\n",
    "]\n",
    "results_paths =[\n",
    "PATHS [\"reports\"]/f\"results_{RUN_ID_LOCAL}.csv\",\n",
    "PATHS [\"reports\"]/\"results.csv\",\n",
    "]\n",
    "\n",
    "p_latest ,df_latest =_load_first_existing (results_latest_paths )\n",
    "p_all ,df_all =_load_first_existing (results_paths )\n",
    "\n",
    "if df_all is not None :\n",
    "    print (\"Loaded results from:\",p_all )\n",
    "\n",
    "for c in [\"mae\",\"rmse\",\"spearman\",\"coverage\",\"sec_per_100_online\",\"sec_per_100_total\",\n",
    "\"parse_success_rate\",\"schema_adherence_rate\",\"coverage_relaxed\",\"mae_relaxed\",\"rmse_relaxed\",\"spearman_relaxed\"]:\n",
    "    if c in df_latest .columns :\n",
    "        df_latest [c ]=pd .to_numeric (df_latest [c ],errors =\"coerce\")\n",
    "\n",
    "def build_paper_table (df :pd .DataFrame ,split_name :str )->pd .DataFrame :\n",
    "    d =df [df [\"split\"].astype (str )==split_name ].copy ()\n",
    "    if len (d )==0 :\n",
    "        return d \n",
    "\n",
    "    keep =[\n",
    "    \"method\",\n",
    "    \"mae\",\"rmse\",\"spearman\",\"coverage\",\n",
    "    \"parse_success_rate\",\"schema_adherence_rate\",\n",
    "    \"sec_per_100_online\",\"sec_per_100_total\",\n",
    "    ]\n",
    "    for c in [\"coverage_relaxed\",\"mae_relaxed\",\"rmse_relaxed\",\"spearman_relaxed\",\n",
    "    \"parse_success_rate_relaxed\",\"schema_adherence_rate_relaxed\"]:\n",
    "        if c in d .columns :\n",
    "            keep .append (c )\n",
    "\n",
    "    if \"notes\"in d .columns :\n",
    "        keep .append (\"notes\")\n",
    "\n",
    "    d =d [[c for c in keep if c in d .columns ]].copy ()\n",
    "\n",
    "    is_llm =d [\"method\"].astype (str ).str .startswith (\"phi3mini_\")\n",
    "    mask_cols =[\n",
    "    \"parse_success_rate\",\"schema_adherence_rate\",\n",
    "    \"parse_success_rate_relaxed\",\"schema_adherence_rate_relaxed\",\n",
    "    ]\n",
    "    for mc in mask_cols :\n",
    "        if mc in d .columns :\n",
    "            d .loc [~is_llm ,mc ]=np .nan \n",
    "\n",
    "    d =d .sort_values ([\"mae\",\"rmse\"],ascending =[True ,True ]).reset_index (drop =True )\n",
    "    return d \n",
    "\n",
    "def save_table (df :pd .DataFrame ,base_name :str )->None :\n",
    "    base_name =f\"{base_name}_{PATCHSET_TAG}\"\n",
    "    csv_path =export_dir /f\"{base_name}.csv\"\n",
    "    tex_path =export_dir /f\"{base_name}.tex\"\n",
    "    df .to_csv (csv_path ,index =False )\n",
    "    try :\n",
    "        df .to_latex (tex_path ,index =False ,float_format =\"%.3f\",na_rep =\"--\")\n",
    "    except Exception :\n",
    "        tex_path .write_text (df .to_csv (index =False ),encoding =\"utf-8\")\n",
    "    print (\"Saved:\",csv_path )\n",
    "    print (\"Saved:\",tex_path )\n",
    "\n",
    "splits_present =sorted (df_latest [\"split\"].astype (str ).unique ().tolist ())\n",
    "\n",
    "preferred_splits =[]\n",
    "for s in [\"test\",\"S\",\"test_full\",\"test_subsetS\"]:\n",
    "    if s in splits_present :\n",
    "        preferred_splits .append (s )\n",
    "if not preferred_splits :\n",
    "    preferred_splits =splits_present \n",
    "\n",
    "tables ={}\n",
    "for s in preferred_splits :\n",
    "    t =build_paper_table (df_latest ,s )\n",
    "    if len (t ):\n",
    "        tables [s ]=t \n",
    "        save_table (t ,f\"table_main_{s}\")\n",
    "\n",
    "ci_path =PATHS [\"reports\"]/\"bootstrap_ci_test_strict.csv\"\n",
    "if ci_path .exists ()and \"test\"in tables :\n",
    "    df_ci =pd .read_csv (ci_path )\n",
    "    if {\"method\",\"mae_p025\",\"mae_p975\",\"rmse_p025\",\"rmse_p975\"}.issubset (df_ci .columns ):\n",
    "        t =tables [\"test\"].merge (df_ci [[\"method\",\"mae_p025\",\"mae_p975\",\"rmse_p025\",\"rmse_p975\"]],on =\"method\",how =\"left\")\n",
    "        t [\"mae_ci95\"]=t .apply (lambda r :f\"{r['mae']:.3f} [{r['mae_p025']:.3f},{r['mae_p975']:.3f}]\"if pd .notna (r [\"mae_p025\"])else f\"{r['mae']:.3f}\",axis =1 )\n",
    "        t [\"rmse_ci95\"]=t .apply (lambda r :f\"{r['rmse']:.3f} [{r['rmse_p025']:.3f},{r['rmse_p975']:.3f}]\"if pd .notna (r [\"rmse_p025\"])else f\"{r['rmse']:.3f}\",axis =1 )\n",
    "        t2 =t .drop (columns =[\"mae_p025\",\"mae_p975\",\"rmse_p025\",\"rmse_p975\"])\n",
    "        save_table (t2 ,\"table_main_test_with_ci\")\n",
    "        tables [\"test_ci\"]=t2 \n",
    "\n",
    "if \"test\"in splits_present and \"coverage\"in df_latest .columns and \"mae\"in df_latest .columns :\n",
    "    d =df_latest [df_latest [\"split\"].astype (str )==\"test\"].copy ()\n",
    "    d =d .dropna (subset =[\"coverage\",\"mae\"])\n",
    "    fig_path =export_dir /\"fig_coverage_vs_mae_test.png\"\n",
    "    plt .figure ()\n",
    "    plt .scatter (d [\"coverage\"],d [\"mae\"],alpha =0.8 )\n",
    "    for _ ,r in d .iterrows ():\n",
    "        plt .annotate (str (r [\"method\"]),(float (r [\"coverage\"]),float (r [\"mae\"])),fontsize =8 )\n",
    "    plt .xlabel (\"Coverage (strict)\")\n",
    "    plt .ylabel (\"MAE (strict)\")\n",
    "    plt .title (\"Test: Coverage vs MAE\")\n",
    "    plt .tight_layout ()\n",
    "    plt .savefig (fig_path ,dpi =150 )\n",
    "    plt .close ()\n",
    "    print (\"Saved:\",fig_path )\n",
    "\n",
    "for fname in [\"efficiency_online_vs_mae_test.png\",\"efficiency_total_vs_mae_test.png\"]:\n",
    "    src =PATHS [\"figs\"]/fname \n",
    "    if src .exists ():\n",
    "        dst =export_dir /fname \n",
    "        shutil .copy2 (src ,dst )\n",
    "        print (\"Copied:\",dst )\n",
    "\n",
    "summary_lines =[]\n",
    "summary_lines .append (f\"# Paper export summary ({RUN_ID_LOCAL})\")\n",
    "summary_lines .append (\"\")\n",
    "summary_lines .append (f\"- Generated: {datetime.utcnow().isoformat()}Z\")\n",
    "summary_lines .append (f\"- results_latest source: {p_latest}\")\n",
    "summary_lines .append (f\"- Export dir: {export_dir}\")\n",
    "summary_lines .append (\"\")\n",
    "\n",
    "def _best_row (df :pd .DataFrame ):\n",
    "    if df is None or len (df )==0 or \"mae\"not in df .columns :\n",
    "        return None \n",
    "    d =df .dropna (subset =[\"mae\"]).sort_values (\"mae\",ascending =True ).head (1 )\n",
    "    return d .iloc [0 ].to_dict ()if len (d )else None \n",
    "\n",
    "for s ,t in tables .items ():\n",
    "    if s .endswith (\"_ci\"):\n",
    "        continue \n",
    "    best =_best_row (t )\n",
    "    if best :\n",
    "        summary_lines .append (f\"## Best method on split={s}\")\n",
    "        summary_lines .append (f\"- method: `{best.get('method')}`\")\n",
    "        summary_lines .append (f\"- MAE: {best.get('mae'):.3f}\"if pd .notna (best .get (\"mae\"))else \"- MAE: n/a\")\n",
    "        if \"coverage\"in best and pd .notna (best [\"coverage\"]):\n",
    "            summary_lines .append (f\"- coverage: {best['coverage']:.3f}\")\n",
    "        if \"sec_per_100_total\"in best and pd .notna (best [\"sec_per_100_total\"]):\n",
    "            summary_lines .append (f\"- sec_per_100_total: {best['sec_per_100_total']:.2f}\")\n",
    "        if \"sec_per_100_online\"in best and pd .notna (best [\"sec_per_100_online\"]):\n",
    "            summary_lines .append (f\"- sec_per_100_online: {best['sec_per_100_online']:.2f}\")\n",
    "        summary_lines .append (\"\")\n",
    "\n",
    "summary_lines .append (\"## Files\")\n",
    "for p in sorted (export_dir .glob (\"*\")):\n",
    "    summary_lines .append (f\"- {p.name}\")\n",
    "\n",
    "md_path =export_dir /\"paper_summary.md\"\n",
    "md_path .write_text (\"\\n\".join (summary_lines )+\"\\n\",encoding =\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
